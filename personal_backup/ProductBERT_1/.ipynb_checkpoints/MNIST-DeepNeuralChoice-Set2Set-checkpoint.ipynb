{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 50
    },
    "colab_type": "code",
    "id": "LorELVXBcR4z",
    "outputId": "c64d0955-7aa4-4141-fb29-efb7b81f08f4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3 GPU(s) available.\n",
      "We will use the GPU:\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "if torch.cuda.is_available():    \n",
    "\n",
    "    device = torch.device(\"cuda\")\n",
    "\n",
    "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
    "\n",
    "    print('We will use the GPU:')\n",
    "\n",
    "else:\n",
    "    print('No GPU available, using the CPU instead.')\n",
    "    device = torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroes=[x_train[i].astype(float) for i in range(len(x_train)) if y_train[i]==0]\n",
    "# zeroes_test=[x_test[i] for i in range(len(x_test)) if y_test[i]==0]\n",
    "# zeroes.extend(zeroes_test)\n",
    "\n",
    "ones=[x_train[i].astype(float) for i in range(len(x_train)) if y_train[i]==1]\n",
    "# ones_test=[x_test[i] for i in range(len(x_test)) if y_test[i]==1]\n",
    "# ones.extend(ones_test)\n",
    "\n",
    "nines=[x_train[i].astype(float) for i in range(len(x_train)) if y_train[i]==9]\n",
    "# nines_test=[x_test[i] for i in range(len(x_test)) if y_test[i]==9]\n",
    "# nines.extend(nines_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroes_test=[x_test[i].astype(float) for i in range(len(x_test)) if y_test[i]==0]\n",
    "ones_test=[x_test[i].astype(float) for i in range(len(x_test)) if y_test[i]==1]\n",
    "nines_test=[x_test[i].astype(float) for i in range(len(x_test)) if y_test[i]==9]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "zeroes1= list(random.choices(zeroes, k=100))\n",
    "ones1= list(random.choices(ones, k=100))\n",
    "nines1= list(random.choices(nines, k=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroes1_test= list(random.choices(zeroes_test, k=100))\n",
    "ones1_test= list(random.choices(ones_test, k=100))\n",
    "nines1_test= list(random.choices(nines_test, k=100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroes1= list([zeroes1[i].ravel().tolist() for i in range(len(zeroes1))])\n",
    "ones1= list([ones1[i].ravel().tolist() for i in range(len(ones1))])\n",
    "nines1= list([nines1[i].ravel().tolist() for i in range(len(nines1))])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "zeroes1_test= list([zeroes1_test[i].ravel().tolist() for i in range(len(zeroes1_test))])\n",
    "ones1_test= list([ones1_test[i].ravel().tolist() for i in range(len(ones1_test))])\n",
    "nines1_test= list([nines1_test[i].ravel().tolist() for i in range(len(nines1_test))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs=[[random.choice(zeroes1),random.choice(ones1)] for i in range(1000)]\n",
    "train_inputs=train_inputs+[[random.choice(zeroes1),random.choice(ones1),random.choice(nines1)] for i in range(1000)]\n",
    "train_inputs=train_inputs+[[random.choice(ones1),random.choice(nines1)] for i in range(1000)]\n",
    "\n",
    "\n",
    "train_labels=[[float(9),float(1)] for i in range(1000)]+[[float(1),float(8),float(1)] for i in range(1000)]+[[float(1),float(9)] for i in range(1000)]\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_inputs=[[random.choice(zeroes1_test),random.choice(ones1_test)] for i in range(1000)]\n",
    "validation_inputs=validation_inputs+[[random.choice(zeroes1_test),random.choice(ones1_test),random.choice(nines1_test)] for i in range(1000)]\n",
    "validation_inputs=validation_inputs+[[random.choice(ones1_test),random.choice(nines1_test)] for i in range(1000)]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Padding/truncating all assortments to 3 values...\n",
      "\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "MAX_LEN = 3\n",
    "\n",
    "print('\\nPadding/truncating all assortments to %d values...' % MAX_LEN)\n",
    "train_inputs= pad_sequences(train_inputs, maxlen=MAX_LEN, dtype=\"float\", truncating=\"post\", padding=\"post\").tolist()\n",
    "train_labels= pad_sequences(train_labels, maxlen=MAX_LEN, dtype=\"float\", truncating=\"post\", padding=\"post\").tolist()\n",
    "\n",
    "print('\\nDone.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "validation_inputs= pad_sequences(validation_inputs, maxlen=MAX_LEN, dtype=\"float\", truncating=\"post\", padding=\"post\").tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "attention_masks = []\n",
    "\n",
    "# For each assortment...\n",
    "for num in train_inputs:\n",
    "    \n",
    "    # Create the attention mask.\n",
    "    #   - If a token ID is 0, then it's padding, set the mask to 0.\n",
    "    #   - If a token ID is > 0, then it's a real token, set the mask to 1.\n",
    "    att_mask = [int(sum(number) > 0) for number  in num]\n",
    "    \n",
    "    # Store the attention mask for this sentence.\n",
    "    attention_masks.append(att_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " [1, 1, 0],\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "B-2L2T05Uiuo"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "train_inputs = torch.tensor(train_inputs)\n",
    "# validation_inputs = torch.tensor(validation_inputs)\n",
    "\n",
    "train_labels = torch.tensor(train_labels)\n",
    "# validation_labels = torch.tensor(validation_labels)\n",
    "\n",
    "train_masks = torch.tensor(attention_masks)\n",
    "# validation_masks = torch.tensor(validation_masks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation_inputs = torch.tensor(validation_inputs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "nSKuy8Q8Us4U"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
    "batch_size =32\n",
    "\n",
    "train_data = TensorDataset(train_inputs,train_masks,train_labels)\n",
    "train_sampler = SequentialSampler(train_data)\n",
    "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size =1\n",
    "validation_data = TensorDataset(validation_inputs,train_labels)\n",
    "validation_sampler = SequentialSampler(validation_data)\n",
    "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 784])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data[0][0].size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 487
    },
    "colab_type": "code",
    "id": "aui6PC16eDRT",
    "outputId": "a1b91e8d-8104-48fa-854a-0a7c7e3a5511"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.insert(1, 'pro-bert')\n",
    "    \n",
    "from modeling_bert import ProductBert,BertConfig\n",
    "\n",
    "import torch\n",
    "\n",
    "configuration = BertConfig()\n",
    "\n",
    "\n",
    "model = ProductBert(configuration)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "jlkoT1tQ-qoG",
    "outputId": "fda59a02-0aac-41a6-d76e-3edb6434061e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ProductBert(\n",
       "  (bert): BertModel(\n",
       "    (embeddings): BertEmbeddings(\n",
       "      (word_embeddings): Embedding(92354, 784, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 784)\n",
       "      (token_type_embeddings): Embedding(2, 784)\n",
       "      (LayerNorm): LayerNorm((784,), eps=1e-08, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): BertEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=784, out_features=784, bias=True)\n",
       "              (key): Linear(in_features=784, out_features=784, bias=True)\n",
       "              (value): Linear(in_features=784, out_features=784, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=784, out_features=784, bias=True)\n",
       "              (LayerNorm): LayerNorm((784,), eps=1e-08, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=784, out_features=64, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=64, out_features=784, bias=True)\n",
       "            (LayerNorm): LayerNorm((784,), eps=1e-08, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (1): BertLayer(\n",
       "          (attention): BertAttention(\n",
       "            (self): BertSelfAttention(\n",
       "              (query): Linear(in_features=784, out_features=784, bias=True)\n",
       "              (key): Linear(in_features=784, out_features=784, bias=True)\n",
       "              (value): Linear(in_features=784, out_features=784, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): BertSelfOutput(\n",
       "              (dense): Linear(in_features=784, out_features=784, bias=True)\n",
       "              (LayerNorm): LayerNorm((784,), eps=1e-08, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): BertIntermediate(\n",
       "            (dense): Linear(in_features=784, out_features=64, bias=True)\n",
       "          )\n",
       "          (output): BertOutput(\n",
       "            (dense): Linear(in_features=64, out_features=784, bias=True)\n",
       "            (LayerNorm): LayerNorm((784,), eps=1e-08, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pooler): BertPooler(\n",
       "      (dense): Linear(in_features=784, out_features=784, bias=True)\n",
       "      (activation): Tanh()\n",
       "    )\n",
       "  )\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       "  (classifier): Linear(in_features=784, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Module.parameters at 0x2b41669e36d0>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "model.parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 605
    },
    "colab_type": "code",
    "id": "V2wstGWDWWts",
    "outputId": "6ffd7fe3-3216-4d0d-f978-a4bf57a6f1bc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The BERT model has 41 different named parameters.\n",
      "\n",
      "==== Embedding Layer ====\n",
      "\n",
      "bert.embeddings.word_embeddings.weight                  (92354, 784)\n",
      "bert.embeddings.position_embeddings.weight                (512, 784)\n",
      "bert.embeddings.token_type_embeddings.weight                (2, 784)\n",
      "bert.embeddings.LayerNorm.weight                              (784,)\n",
      "bert.embeddings.LayerNorm.bias                                (784,)\n",
      "\n",
      "==== First Transformer ====\n",
      "\n",
      "bert.encoder.layer.0.attention.self.query.weight          (784, 784)\n",
      "bert.encoder.layer.0.attention.self.query.bias                (784,)\n",
      "bert.encoder.layer.0.attention.self.key.weight            (784, 784)\n",
      "bert.encoder.layer.0.attention.self.key.bias                  (784,)\n",
      "bert.encoder.layer.0.attention.self.value.weight          (784, 784)\n",
      "bert.encoder.layer.0.attention.self.value.bias                (784,)\n",
      "bert.encoder.layer.0.attention.output.dense.weight        (784, 784)\n",
      "bert.encoder.layer.0.attention.output.dense.bias              (784,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.weight        (784,)\n",
      "bert.encoder.layer.0.attention.output.LayerNorm.bias          (784,)\n",
      "bert.encoder.layer.0.intermediate.dense.weight             (64, 784)\n",
      "bert.encoder.layer.0.intermediate.dense.bias                   (64,)\n",
      "bert.encoder.layer.0.output.dense.weight                   (784, 64)\n",
      "bert.encoder.layer.0.output.dense.bias                        (784,)\n",
      "bert.encoder.layer.0.output.LayerNorm.weight                  (784,)\n",
      "bert.encoder.layer.0.output.LayerNorm.bias                    (784,)\n",
      "\n",
      "==== Output Layer ====\n",
      "\n",
      "bert.pooler.dense.weight                                  (784, 784)\n",
      "bert.pooler.dense.bias                                        (784,)\n",
      "classifier.weight                                           (1, 784)\n",
      "classifier.bias                                                 (1,)\n"
     ]
    }
   ],
   "source": [
    "params = list(model.named_parameters())\n",
    "params = list(model.named_parameters())\n",
    "\n",
    "print('The BERT model has {:} different named parameters.\\n'.format(len(params)))\n",
    "\n",
    "print('==== Embedding Layer ====\\n')\n",
    "\n",
    "for p in params[0:5]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== First Transformer ====\\n')\n",
    "\n",
    "for p in params[5:21]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n",
    "\n",
    "print('\\n==== Output Layer ====\\n')\n",
    "\n",
    "for p in params[-4:]:\n",
    "    print(\"{:<55} {:>12}\".format(p[0], str(tuple(p[1].size()))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "yjFxDXGgY94m"
   },
   "outputs": [],
   "source": [
    "from transformers import  AdamW\n",
    "import torch.optim\n",
    "optimizer=torch.optim.SGD(model.parameters(), lr=5e-3)\n",
    "# optimizer = AdamW(model.parameters(),\n",
    "#                   lr = 5e-3, # args.learning_rate - default is 5e-5, our notebook had 2e-5\n",
    "#                   eps = 1e-6 # args.adam_epsilon  - default is 1e-8.\n",
    "#                 )\n",
    "optimizer=torch.optim.Adam(model.parameters(),lr=0.0001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0, amsgrad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "m1qru2H6Zt1g"
   },
   "outputs": [],
   "source": [
    "\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "\n",
    "# Number of training epochs \n",
    "epochs = 50\n",
    "\n",
    "# Total number of training steps is number of batches * number of epochs.\n",
    "total_steps = len(train_dataloader) * epochs\n",
    "\n",
    "# Create the learning rate scheduler.\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
    "                                            num_warmup_steps = 0, # Default value in run_glue.py\n",
    "                                            num_training_steps = total_steps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0GMtbvVAaNoy"
   },
   "outputs": [],
   "source": [
    "import time\n",
    "import datetime\n",
    "\n",
    "def format_time(elapsed):\n",
    "\n",
    "    elapsed_rounded = int(round((elapsed)))\n",
    "    \n",
    "    # Format as hh:mm:ss\n",
    "    return str(datetime.timedelta(seconds=elapsed_rounded))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 27.82468605041504 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 22.131803512573242 with total_loss: 27.82468605041504\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 17.78702163696289 with total_loss: 49.95648956298828\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 15.476485252380371 with total_loss: 67.74351119995117\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 12.905777931213379 with total_loss: 83.21999645233154\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 12.113822937011719 with total_loss: 96.12577438354492\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 10.35581111907959 with total_loss: 108.23959732055664\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 8.35155200958252 with total_loss: 118.59540843963623\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 6.644205570220947 with total_loss: 126.94696044921875\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 4.145850658416748 with total_loss: 133.5911660194397\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 2.713191270828247 with total_loss: 137.73701667785645\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 1.2840205430984497 with total_loss: 140.4502079486847\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 1.0510759353637695 with total_loss: 141.73422849178314\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 1.4672126770019531 with total_loss: 142.7853044271469\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 2.0871500968933105 with total_loss: 144.25251710414886\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 2.4979851245880127 with total_loss: 146.33966720104218\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 2.605360269546509 with total_loss: 148.8376523256302\n",
      "  Batch    17  of     94.    Elapsed: 0:00:01. with Loss: 1.2372081279754639 with total_loss: 151.4430125951767\n",
      "  Batch    18  of     94.    Elapsed: 0:00:01. with Loss: 1.040726661682129 with total_loss: 152.68022072315216\n",
      "  Batch    19  of     94.    Elapsed: 0:00:01. with Loss: 0.836972177028656 with total_loss: 153.7209473848343\n",
      "  Batch    20  of     94.    Elapsed: 0:00:01. with Loss: 0.8008274435997009 with total_loss: 154.55791956186295\n",
      "  Batch    21  of     94.    Elapsed: 0:00:01. with Loss: 0.657772421836853 with total_loss: 155.35874700546265\n",
      "  Batch    22  of     94.    Elapsed: 0:00:01. with Loss: 0.8560790419578552 with total_loss: 156.0165194272995\n",
      "  Batch    23  of     94.    Elapsed: 0:00:01. with Loss: 1.1739431619644165 with total_loss: 156.87259846925735\n",
      "  Batch    24  of     94.    Elapsed: 0:00:01. with Loss: 1.0864168405532837 with total_loss: 158.04654163122177\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.913231372833252 with total_loss: 159.13295847177505\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.7706174850463867 with total_loss: 160.0461898446083\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.31082674860954285 with total_loss: 160.8168073296547\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.6070884466171265 with total_loss: 161.12763407826424\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.4727069139480591 with total_loss: 161.73472252488136\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.7352873682975769 with total_loss: 162.20742943882942\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 12.417452812194824 with total_loss: 162.942716807127\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 16.207496643066406 with total_loss: 175.36016961932182\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 16.00145721435547 with total_loss: 191.56766626238823\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 14.890144348144531 with total_loss: 207.5691234767437\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 14.562893867492676 with total_loss: 222.45926782488823\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 14.018421173095703 with total_loss: 237.0221616923809\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 13.980042457580566 with total_loss: 251.0405828654766\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 12.599703788757324 with total_loss: 265.0206253230572\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 12.471150398254395 with total_loss: 277.6203291118145\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 11.358055114746094 with total_loss: 290.0914795100689\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 11.333523750305176 with total_loss: 301.449534624815\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 9.572945594787598 with total_loss: 312.78305837512016\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 8.706751823425293 with total_loss: 322.35600396990776\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 8.344647407531738 with total_loss: 331.06275579333305\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 6.658597469329834 with total_loss: 339.4074032008648\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 6.745950222015381 with total_loss: 346.0660006701946\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 4.842153072357178 with total_loss: 352.81195089221\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 4.163210391998291 with total_loss: 357.6541039645672\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 2.7174603939056396 with total_loss: 361.8173143565655\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 2.510451555252075 with total_loss: 364.5347747504711\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 2.9151718616485596 with total_loss: 367.0452263057232\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 2.6080703735351562 with total_loss: 369.96039816737175\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 2.8756134510040283 with total_loss: 372.5684685409069\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 2.4404313564300537 with total_loss: 375.44408199191093\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 2.0172901153564453 with total_loss: 377.884513348341\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 1.9853349924087524 with total_loss: 379.90180346369743\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 2.214254140853882 with total_loss: 381.8871384561062\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 1.5708717107772827 with total_loss: 384.10139259696007\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 2.2495052814483643 with total_loss: 385.67226430773735\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 1.317728877067566 with total_loss: 387.9217695891857\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 1.4066540002822876 with total_loss: 389.2394984662533\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 7.128041744232178 with total_loss: 390.64615246653557\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 10.740856170654297 with total_loss: 397.77419421076775\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 5.392890930175781 with total_loss: 408.51505038142204\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 3.681295156478882 with total_loss: 413.9079413115978\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 1.6927388906478882 with total_loss: 417.5892364680767\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 1.7762393951416016 with total_loss: 419.2819753587246\n",
      "  Batch    68  of     94.    Elapsed: 0:00:02. with Loss: 2.615145444869995 with total_loss: 421.0582147538662\n",
      "  Batch    69  of     94.    Elapsed: 0:00:02. with Loss: 2.6689510345458984 with total_loss: 423.6733601987362\n",
      "  Batch    70  of     94.    Elapsed: 0:00:02. with Loss: 1.881770133972168 with total_loss: 426.3423112332821\n",
      "  Batch    71  of     94.    Elapsed: 0:00:02. with Loss: 1.921285629272461 with total_loss: 428.22408136725426\n",
      "  Batch    72  of     94.    Elapsed: 0:00:02. with Loss: 1.729103922843933 with total_loss: 430.1453669965267\n",
      "  Batch    73  of     94.    Elapsed: 0:00:02. with Loss: 1.756177306175232 with total_loss: 431.87447091937065\n",
      "  Batch    74  of     94.    Elapsed: 0:00:02. with Loss: 0.5241044163703918 with total_loss: 433.6306482255459\n",
      "  Batch    75  of     94.    Elapsed: 0:00:02. with Loss: 1.4438995122909546 with total_loss: 434.1547526419163\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.9162635207176208 with total_loss: 435.59865215420723\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.6659935116767883 with total_loss: 436.51491567492485\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 1.0912325382232666 with total_loss: 437.18090918660164\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.5355896353721619 with total_loss: 438.2721417248249\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.48587027192115784 with total_loss: 438.80773136019707\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.44436773657798767 with total_loss: 439.2936016321182\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.4418048560619354 with total_loss: 439.7379693686962\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.5139521360397339 with total_loss: 440.17977422475815\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.5766659379005432 with total_loss: 440.6937263607979\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.7098891139030457 with total_loss: 441.2703922986984\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.43236061930656433 with total_loss: 441.98028141260147\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.5576223731040955 with total_loss: 442.41264203190804\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.24455706775188446 with total_loss: 442.97026440501213\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.17905445396900177 with total_loss: 443.214821472764\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.26412975788116455 with total_loss: 443.393875926733\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.23543427884578705 with total_loss: 443.6580056846142\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.24145710468292236 with total_loss: 443.89343996345997\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.5058708190917969 with total_loss: 444.1348970681429\n",
      "\n",
      "  Average training loss: 4.73\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 2 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.3235222101211548 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.2620409429073334 with total_loss: 0.3235222101211548\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.4884253442287445 with total_loss: 0.5855631530284882\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.32387277483940125 with total_loss: 1.0739884972572327\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.4670112431049347 with total_loss: 1.397861272096634\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.20012696087360382 with total_loss: 1.8648725152015686\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.3354372978210449 with total_loss: 2.0649994760751724\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.18362538516521454 with total_loss: 2.4004367738962173\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.22640876471996307 with total_loss: 2.584062159061432\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.25589102506637573 with total_loss: 2.810470923781395\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.17203156650066376 with total_loss: 3.0663619488477707\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.3737250864505768 with total_loss: 3.2383935153484344\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.2339993715286255 with total_loss: 3.6121186017990112\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.12966030836105347 with total_loss: 3.8461179733276367\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.1287660002708435 with total_loss: 3.97577828168869\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.15667660534381866 with total_loss: 4.104544281959534\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.23469112813472748 with total_loss: 4.261220887303352\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.12930338084697723 with total_loss: 4.49591201543808\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.20963211357593536 with total_loss: 4.625215396285057\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.12527741491794586 with total_loss: 4.834847509860992\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.12736527621746063 with total_loss: 4.960124924778938\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.13049425184726715 with total_loss: 5.087490200996399\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.13449792563915253 with total_loss: 5.217984452843666\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.13568034768104553 with total_loss: 5.352482378482819\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.13198350369930267 with total_loss: 5.488162726163864\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.08629784733057022 with total_loss: 5.620146229863167\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.1251741498708725 with total_loss: 5.706444077193737\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.16128569841384888 with total_loss: 5.8316182270646095\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.12184187024831772 with total_loss: 5.992903925478458\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.1036389172077179 with total_loss: 6.114745795726776\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.11205718666315079 with total_loss: 6.218384712934494\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 5.173890590667725 with total_loss: 6.330441899597645\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 6.219377040863037 with total_loss: 11.50433249026537\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 4.217217922210693 with total_loss: 17.723709531128407\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 3.4056501388549805 with total_loss: 21.9409274533391\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 2.7215774059295654 with total_loss: 25.34657759219408\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 3.025710344314575 with total_loss: 28.068154998123646\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 2.53839373588562 with total_loss: 31.09386534243822\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 1.8018478155136108 with total_loss: 33.63225907832384\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 1.088523507118225 with total_loss: 35.43410689383745\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 1.552726149559021 with total_loss: 36.52263040095568\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 1.1428178548812866 with total_loss: 38.0753565505147\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 1.6038352251052856 with total_loss: 39.218174405395985\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 1.3918222188949585 with total_loss: 40.82200963050127\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 1.8845415115356445 with total_loss: 42.21383184939623\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 1.0031651258468628 with total_loss: 44.09837336093187\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.8969731330871582 with total_loss: 45.101538486778736\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.8367096781730652 with total_loss: 45.998511619865894\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 1.0068367719650269 with total_loss: 46.83522129803896\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.7964518666267395 with total_loss: 47.842058070003986\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 1.0589420795440674 with total_loss: 48.638509936630726\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 1.0486130714416504 with total_loss: 49.69745201617479\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.7047982215881348 with total_loss: 50.746065087616444\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 1.3547288179397583 with total_loss: 51.45086330920458\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.8112311363220215 with total_loss: 52.80559212714434\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.7939691543579102 with total_loss: 53.61682326346636\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.7333168983459473 with total_loss: 54.41079241782427\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 1.0777539014816284 with total_loss: 55.144109316170216\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.8207287788391113 with total_loss: 56.221863217651844\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.8494653105735779 with total_loss: 57.042591996490955\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.5333496928215027 with total_loss: 57.89205730706453\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.7548472285270691 with total_loss: 58.425406999886036\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 2.2331655025482178 with total_loss: 59.180254228413105\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 3.3405377864837646 with total_loss: 61.41341973096132\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 2.5197126865386963 with total_loss: 64.75395751744509\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 1.3672460317611694 with total_loss: 67.27367020398378\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.5081349611282349 with total_loss: 68.64091623574495\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.4937942922115326 with total_loss: 69.14905119687319\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.6232630014419556 with total_loss: 69.64284548908472\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 1.8669935464859009 with total_loss: 70.26610849052668\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 1.418116569519043 with total_loss: 72.13310203701258\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 1.4277235269546509 with total_loss: 73.55121860653162\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 1.1538563966751099 with total_loss: 74.97894213348627\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.9390694499015808 with total_loss: 76.13279853016138\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.7941338419914246 with total_loss: 77.07186798006296\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.3968141973018646 with total_loss: 77.86600182205439\n",
      "  Batch    76  of     94.    Elapsed: 0:00:01. with Loss: 0.3774508237838745 with total_loss: 78.26281601935625\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.505208432674408 with total_loss: 78.64026684314013\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.7471032738685608 with total_loss: 79.14547527581453\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.5837933421134949 with total_loss: 79.8925785496831\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.583549976348877 with total_loss: 80.47637189179659\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.538792073726654 with total_loss: 81.05992186814547\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.29907694458961487 with total_loss: 81.59871394187212\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.3310568332672119 with total_loss: 81.89779088646173\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.27520355582237244 with total_loss: 82.22884771972895\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.2076350897550583 with total_loss: 82.50405127555132\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.23042647540569305 with total_loss: 82.71168636530638\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.2561326324939728 with total_loss: 82.94211284071207\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.3580087125301361 with total_loss: 83.19824547320604\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.34982016682624817 with total_loss: 83.55625418573618\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.2014489769935608 with total_loss: 83.90607435256243\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.2002144306898117 with total_loss: 84.10752332955599\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.12300083786249161 with total_loss: 84.3077377602458\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.09277216345071793 with total_loss: 84.43073859810829\n",
      "\n",
      "  Average training loss: 0.90\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 3 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.15426529943943024 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.15508173406124115 with total_loss: 0.15426529943943024\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.13956108689308167 with total_loss: 0.3093470335006714\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.19439463317394257 with total_loss: 0.44890812039375305\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.164528951048851 with total_loss: 0.6433027535676956\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.13742129504680634 with total_loss: 0.8078317046165466\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.14267559349536896 with total_loss: 0.945252999663353\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.1442197561264038 with total_loss: 1.087928593158722\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.1499473750591278 with total_loss: 1.2321483492851257\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.11685776710510254 with total_loss: 1.3820957243442535\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.10209199786186218 with total_loss: 1.498953491449356\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.1716705560684204 with total_loss: 1.6010454893112183\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.12434040755033493 with total_loss: 1.7727160453796387\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.07470238208770752 with total_loss: 1.8970564529299736\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.132329061627388 with total_loss: 1.9717588350176811\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.12445181608200073 with total_loss: 2.104087896645069\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.12657412886619568 with total_loss: 2.22853971272707\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.09817016869783401 with total_loss: 2.3551138415932655\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.14516781270503998 with total_loss: 2.4532840102910995\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.07598493248224258 with total_loss: 2.5984518229961395\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.10313407331705093 with total_loss: 2.674436755478382\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.07267134636640549 with total_loss: 2.777570828795433\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.08620954304933548 with total_loss: 2.8502421751618385\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.10275894403457642 with total_loss: 2.936451718211174\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.11557120084762573 with total_loss: 3.0392106622457504\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.08542998880147934 with total_loss: 3.154781863093376\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.07755950838327408 with total_loss: 3.2402118518948555\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.08155135065317154 with total_loss: 3.3177713602781296\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.0675959512591362 with total_loss: 3.399322710931301\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.12139961868524551 with total_loss: 3.4669186621904373\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.08281106501817703 with total_loss: 3.588318280875683\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.9993926882743835 with total_loss: 3.67112934589386\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 1.7812366485595703 with total_loss: 4.670522034168243\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 1.4429235458374023 with total_loss: 6.451758682727814\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 1.1365894079208374 with total_loss: 7.894682228565216\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.95295649766922 with total_loss: 9.031271636486053\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.9054160118103027 with total_loss: 9.984228134155273\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.5860148668289185 with total_loss: 10.889644145965576\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.752322256565094 with total_loss: 11.475659012794495\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.6397227644920349 with total_loss: 12.227981269359589\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 1.053469181060791 with total_loss: 12.867704033851624\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.9001135230064392 with total_loss: 13.921173214912415\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.8397572040557861 with total_loss: 14.821286737918854\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.5754690766334534 with total_loss: 15.66104394197464\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.9570948481559753 with total_loss: 16.236513018608093\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.6602616310119629 with total_loss: 17.19360786676407\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.6678983569145203 with total_loss: 17.85386949777603\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.792180061340332 with total_loss: 18.52176785469055\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.4530004560947418 with total_loss: 19.313947916030884\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.39382800459861755 with total_loss: 19.766948372125626\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.5614931583404541 with total_loss: 20.160776376724243\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.4099667966365814 with total_loss: 20.722269535064697\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.5063597559928894 with total_loss: 21.13223633170128\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.801069438457489 with total_loss: 21.638596087694168\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.661512017250061 with total_loss: 22.439665526151657\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.48419809341430664 with total_loss: 23.101177543401718\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.443505197763443 with total_loss: 23.585375636816025\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.7166492938995361 with total_loss: 24.028880834579468\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.4896007478237152 with total_loss: 24.745530128479004\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.5234952569007874 with total_loss: 25.23513087630272\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.38390231132507324 with total_loss: 25.758626133203506\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.43143048882484436 with total_loss: 26.14252844452858\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.2552752196788788 with total_loss: 26.573958933353424\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.2960940897464752 with total_loss: 26.829234153032303\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.2582704424858093 with total_loss: 27.125328242778778\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.244431734085083 with total_loss: 27.383598685264587\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.21148891746997833 with total_loss: 27.62803041934967\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.11296230554580688 with total_loss: 27.83951933681965\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.18365921080112457 with total_loss: 27.952481642365456\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.3227134346961975 with total_loss: 28.13614085316658\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.14899709820747375 with total_loss: 28.458854287862778\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.1997360736131668 with total_loss: 28.60785138607025\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.2042863816022873 with total_loss: 28.80758745968342\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.1928718537092209 with total_loss: 29.011873841285706\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.1412975937128067 with total_loss: 29.204745694994926\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.13355796039104462 with total_loss: 29.346043288707733\n",
      "  Batch    76  of     94.    Elapsed: 0:00:01. with Loss: 0.13169057667255402 with total_loss: 29.479601249098778\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.10359438508749008 with total_loss: 29.611291825771332\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.17859512567520142 with total_loss: 29.714886210858822\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.13769260048866272 with total_loss: 29.893481336534023\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.09685176610946655 with total_loss: 30.031173937022686\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.156173974275589 with total_loss: 30.128025703132153\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.07443302124738693 with total_loss: 30.28419967740774\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.12348899990320206 with total_loss: 30.35863269865513\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.2430872768163681 with total_loss: 30.48212169855833\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.07016652822494507 with total_loss: 30.7252089753747\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.1112411618232727 with total_loss: 30.795375503599644\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.11964531987905502 with total_loss: 30.906616665422916\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.09965434670448303 with total_loss: 31.02626198530197\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.12281393259763718 with total_loss: 31.125916332006454\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.08244169503450394 with total_loss: 31.24873026460409\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.0781424269080162 with total_loss: 31.331171959638596\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.11203519254922867 with total_loss: 31.409314386546612\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.08229584246873856 with total_loss: 31.52134957909584\n",
      "\n",
      "  Average training loss: 0.34\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 4 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.09374251961708069 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.09079524129629135 with total_loss: 0.09374251961708069\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.08456474542617798 with total_loss: 0.18453776091337204\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.11518818140029907 with total_loss: 0.26910250633955\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.1307421177625656 with total_loss: 0.3842906877398491\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.08529319614171982 with total_loss: 0.5150328055024147\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.10666318982839584 with total_loss: 0.6003260016441345\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.09297154098749161 with total_loss: 0.7069891914725304\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.1381601244211197 with total_loss: 0.799960732460022\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.1253262311220169 with total_loss: 0.9381208568811417\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.11013554781675339 with total_loss: 1.0634470880031586\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.18761412799358368 with total_loss: 1.173582635819912\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.06506160646677017 with total_loss: 1.3611967638134956\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.28520941734313965 with total_loss: 1.4262583702802658\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.07860249280929565 with total_loss: 1.7114677876234055\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.057729173451662064 with total_loss: 1.790070280432701\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.07215864956378937 with total_loss: 1.8477994538843632\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.06917764246463776 with total_loss: 1.9199581034481525\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.08016889542341232 with total_loss: 1.9891357459127903\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.060418564826250076 with total_loss: 2.0693046413362026\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.04892945662140846 with total_loss: 2.1297232061624527\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.050270095467567444 with total_loss: 2.178652662783861\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.04974498227238655 with total_loss: 2.2289227582514286\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.05828321352601051 with total_loss: 2.278667740523815\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.05973726883530617 with total_loss: 2.3369509540498257\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.07194877415895462 with total_loss: 2.396688222885132\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.06041759252548218 with total_loss: 2.4686369970440865\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.09271767735481262 with total_loss: 2.5290545895695686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.04505430534482002 with total_loss: 2.6217722669243813\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.0696207657456398 with total_loss: 2.6668265722692013\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.06053159013390541 with total_loss: 2.736447338014841\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.3482999801635742 with total_loss: 2.7969789281487465\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.4567527770996094 with total_loss: 3.1452789083123207\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.41790464520454407 with total_loss: 3.60203168541193\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.3470495045185089 with total_loss: 4.019936330616474\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.32467278838157654 with total_loss: 4.366985835134983\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.4983498156070709 with total_loss: 4.69165862351656\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.792041540145874 with total_loss: 5.1900084391236305\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.3048531711101532 with total_loss: 5.9820499792695045\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.38143089413642883 with total_loss: 6.286903150379658\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.6647672057151794 with total_loss: 6.668334044516087\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.4800778329372406 with total_loss: 7.333101250231266\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.4406270980834961 with total_loss: 7.813179083168507\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.375102162361145 with total_loss: 8.253806181252003\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.39317014813423157 with total_loss: 8.628908343613148\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.39105233550071716 with total_loss: 9.02207849174738\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.3958626985549927 with total_loss: 9.413130827248096\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.32707902789115906 with total_loss: 9.80899352580309\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.22383590042591095 with total_loss: 10.136072553694248\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.3205249011516571 with total_loss: 10.35990845412016\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.3496626317501068 with total_loss: 10.680433355271816\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.26591336727142334 with total_loss: 11.030095987021923\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.2750122845172882 with total_loss: 11.296009354293346\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.46103334426879883 with total_loss: 11.571021638810635\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.21523256599903107 with total_loss: 12.032054983079433\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.2036399096250534 with total_loss: 12.247287549078465\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.2241625338792801 with total_loss: 12.450927458703518\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.17871040105819702 with total_loss: 12.675089992582798\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.21756362915039062 with total_loss: 12.853800393640995\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.3620639145374298 with total_loss: 13.071364022791386\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.26267528533935547 with total_loss: 13.433427937328815\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.26341795921325684 with total_loss: 13.696103222668171\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.13710954785346985 with total_loss: 13.959521181881428\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.12114280462265015 with total_loss: 14.096630729734898\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.12445924431085587 with total_loss: 14.217773534357548\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.07940912246704102 with total_loss: 14.342232778668404\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.0630333349108696 with total_loss: 14.421641901135445\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.08979109674692154 with total_loss: 14.484675236046314\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.06826033443212509 with total_loss: 14.574466332793236\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.16096051037311554 with total_loss: 14.64272666722536\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.07850904017686844 with total_loss: 14.803687177598476\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.06839995086193085 with total_loss: 14.882196217775345\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.0944964587688446 with total_loss: 14.950596168637276\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.09164615720510483 with total_loss: 15.04509262740612\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.07731794565916061 with total_loss: 15.136738784611225\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.08541939407587051 with total_loss: 15.214056730270386\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.06737818568944931 with total_loss: 15.299476124346256\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.07502128183841705 with total_loss: 15.366854310035706\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.07247307151556015 with total_loss: 15.441875591874123\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.053083647042512894 with total_loss: 15.514348663389683\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.05101625248789787 with total_loss: 15.567432310432196\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.04755914583802223 with total_loss: 15.618448562920094\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.0593213252723217 with total_loss: 15.666007708758116\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.07130195945501328 with total_loss: 15.725329034030437\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.04885176941752434 with total_loss: 15.79663099348545\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.06288962066173553 with total_loss: 15.845482762902975\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0639636293053627 with total_loss: 15.90837238356471\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.05266854166984558 with total_loss: 15.972336012870073\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.05674002692103386 with total_loss: 16.02500455453992\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.05299454927444458 with total_loss: 16.081744581460953\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.057886868715286255 with total_loss: 16.134739130735397\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.05586002394556999 with total_loss: 16.192625999450684\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.08345159888267517 with total_loss: 16.248486023396254\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.054089874029159546 with total_loss: 16.33193762227893\n",
      "\n",
      "  Average training loss: 0.17\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 5 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.06224995478987694 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.053711701184511185 with total_loss: 0.06224995478987694\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.05600126460194588 with total_loss: 0.11596165597438812\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.05317055806517601 with total_loss: 0.171962920576334\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.04561318829655647 with total_loss: 0.22513347864151\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.04666868969798088 with total_loss: 0.2707466669380665\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.08818715810775757 with total_loss: 0.31741535663604736\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.050121109932661057 with total_loss: 0.40560251474380493\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.0481354258954525 with total_loss: 0.455723624676466\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.03275495395064354 with total_loss: 0.5038590505719185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.0617789626121521 with total_loss: 0.536614004522562\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.0492013655602932 with total_loss: 0.5983929671347141\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.05352373793721199 with total_loss: 0.6475943326950073\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.08454068750143051 with total_loss: 0.7011180706322193\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.08088713139295578 with total_loss: 0.7856587581336498\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.04583637788891792 with total_loss: 0.8665458895266056\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.06270525604486465 with total_loss: 0.9123822674155235\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.06132635474205017 with total_loss: 0.9750875234603882\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.07734833657741547 with total_loss: 1.0364138782024384\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.03818434476852417 with total_loss: 1.1137622147798538\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.048949405550956726 with total_loss: 1.151946559548378\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.040168941020965576 with total_loss: 1.2008959650993347\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.040998972952365875 with total_loss: 1.2410649061203003\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.04970075562596321 with total_loss: 1.2820638790726662\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.038726806640625 with total_loss: 1.3317646346986294\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.02386513166129589 with total_loss: 1.3704914413392544\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.035837508738040924 with total_loss: 1.3943565730005503\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.07543674856424332 with total_loss: 1.4301940817385912\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.045805174857378006 with total_loss: 1.5056308303028345\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.048255156725645065 with total_loss: 1.5514360051602125\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.04036613926291466 with total_loss: 1.5996911618858576\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.2738809883594513 with total_loss: 1.6400573011487722\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.30707135796546936 with total_loss: 1.9139382895082235\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.28520235419273376 with total_loss: 2.221009647473693\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.30401936173439026 with total_loss: 2.5062120016664267\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.20588696002960205 with total_loss: 2.810231363400817\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.33747684955596924 with total_loss: 3.016118323430419\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.292101114988327 with total_loss: 3.353595172986388\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.24406366050243378 with total_loss: 3.6456962879747152\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.19682510197162628 with total_loss: 3.889759948477149\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.3532688617706299 with total_loss: 4.086585050448775\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.2127189189195633 with total_loss: 4.439853912219405\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.2617516815662384 with total_loss: 4.6525728311389685\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.25874847173690796 with total_loss: 4.914324512705207\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.37130117416381836 with total_loss: 5.173072984442115\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.17927293479442596 with total_loss: 5.544374158605933\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.19619381427764893 with total_loss: 5.723647093400359\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.1817556470632553 with total_loss: 5.919840907678008\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.1745784729719162 with total_loss: 6.101596554741263\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.2076035737991333 with total_loss: 6.27617502771318\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.16919778287410736 with total_loss: 6.483778601512313\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.203882098197937 with total_loss: 6.65297638438642\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.17133380472660065 with total_loss: 6.856858482584357\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.2353464812040329 with total_loss: 7.028192287310958\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.2930651009082794 with total_loss: 7.263538768514991\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.20203976333141327 with total_loss: 7.55660386942327\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.17099298536777496 with total_loss: 7.7586436327546835\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.15336212515830994 with total_loss: 7.9296366181224585\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.16739948093891144 with total_loss: 8.082998743280768\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.28654929995536804 with total_loss: 8.25039822421968\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.16956353187561035 with total_loss: 8.536947524175048\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.12833364307880402 with total_loss: 8.706511056050658\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.1424318104982376 with total_loss: 8.834844699129462\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.09910734742879868 with total_loss: 8.9772765096277\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.06852491945028305 with total_loss: 9.076383857056499\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.05013555660843849 with total_loss: 9.144908776506782\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.07346265763044357 with total_loss: 9.19504433311522\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.05223428085446358 with total_loss: 9.268506990745664\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.05872352048754692 with total_loss: 9.320741271600127\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.07007517665624619 with total_loss: 9.379464792087674\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.06901638954877853 with total_loss: 9.44953996874392\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.0834960862994194 with total_loss: 9.518556358292699\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.0794372409582138 with total_loss: 9.602052444592118\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.07324627041816711 with total_loss: 9.681489685550332\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.04791024327278137 with total_loss: 9.7547359559685\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.0502220056951046 with total_loss: 9.80264619924128\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.09383172541856766 with total_loss: 9.852868204936385\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.04826674982905388 with total_loss: 9.946699930354953\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.05427937209606171 with total_loss: 9.994966680184007\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.06178531050682068 with total_loss: 10.049246052280068\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.062053605914115906 with total_loss: 10.111031362786889\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.03506162390112877 with total_loss: 10.173084968701005\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.044125527143478394 with total_loss: 10.208146592602134\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.0550716333091259 with total_loss: 10.252272119745612\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.05359775945544243 with total_loss: 10.307343753054738\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.05544422194361687 with total_loss: 10.36094151251018\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0429210364818573 with total_loss: 10.416385734453797\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.04202054813504219 with total_loss: 10.459306770935655\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.053507644683122635 with total_loss: 10.501327319070697\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.05997588858008385 with total_loss: 10.55483496375382\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.03699998930096626 with total_loss: 10.614810852333903\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.033489909023046494 with total_loss: 10.65181084163487\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.03193524107336998 with total_loss: 10.685300750657916\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.04145081341266632 with total_loss: 10.717235991731286\n",
      "\n",
      "  Average training loss: 0.11\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 6 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.045669879764318466 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.031322989612817764 with total_loss: 0.045669879764318466\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.03426126390695572 with total_loss: 0.07699286937713623\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.04791882634162903 with total_loss: 0.11125413328409195\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.040164243429899216 with total_loss: 0.15917295962572098\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.04346148297190666 with total_loss: 0.1993372030556202\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.03226487711071968 with total_loss: 0.24279868602752686\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.03037954866886139 with total_loss: 0.27506356313824654\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.03392493352293968 with total_loss: 0.3054431118071079\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0264641921967268 with total_loss: 0.3393680453300476\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.026656223461031914 with total_loss: 0.3658322375267744\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.047297969460487366 with total_loss: 0.3924884609878063\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.030338918790221214 with total_loss: 0.4397864304482937\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.034600887447595596 with total_loss: 0.4701253492385149\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.02373354323208332 with total_loss: 0.5047262366861105\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.03470480069518089 with total_loss: 0.5284597799181938\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.04033954069018364 with total_loss: 0.5631645806133747\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.03784554824233055 with total_loss: 0.6035041213035583\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.03140999376773834 with total_loss: 0.6413496695458889\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.028574956580996513 with total_loss: 0.6727596633136272\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.027621418237686157 with total_loss: 0.7013346198946238\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.024270234629511833 with total_loss: 0.7289560381323099\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.026158800348639488 with total_loss: 0.7532262727618217\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.03547171875834465 with total_loss: 0.7793850731104612\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.029909253120422363 with total_loss: 0.8148567918688059\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.025068074464797974 with total_loss: 0.8447660449892282\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.034652143716812134 with total_loss: 0.8698341194540262\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.03044256567955017 with total_loss: 0.9044862631708384\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.02726883254945278 with total_loss: 0.9349288288503885\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.033635448664426804 with total_loss: 0.9621976613998413\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.031538162380456924 with total_loss: 0.9958331100642681\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.3533202111721039 with total_loss: 1.027371272444725\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.30773210525512695 with total_loss: 1.380691483616829\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.1803380250930786 with total_loss: 1.6884235888719559\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.21780966222286224 with total_loss: 1.8687616139650345\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.24263416230678558 with total_loss: 2.0865712761878967\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.36265626549720764 with total_loss: 2.3292054384946823\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.31604430079460144 with total_loss: 2.69186170399189\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.22303791344165802 with total_loss: 3.0079060047864914\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.16505153477191925 with total_loss: 3.2309439182281494\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.22561252117156982 with total_loss: 3.3959954530000687\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.17411579191684723 with total_loss: 3.6216079741716385\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.2920125424861908 with total_loss: 3.7957237660884857\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.16061973571777344 with total_loss: 4.0877363085746765\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.18740274012088776 with total_loss: 4.24835604429245\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.11170200258493423 with total_loss: 4.435758784413338\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.13351982831954956 with total_loss: 4.547460786998272\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.12770722806453705 with total_loss: 4.6809806153178215\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.19746048748493195 with total_loss: 4.8086878433823586\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.14789098501205444 with total_loss: 5.0061483308672905\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.17415986955165863 with total_loss: 5.154039315879345\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.17112044990062714 with total_loss: 5.328199185431004\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.1196565255522728 with total_loss: 5.499319635331631\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.29964005947113037 with total_loss: 5.6189761608839035\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.1158914789557457 with total_loss: 5.918616220355034\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.12809278070926666 with total_loss: 6.03450769931078\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.13070563971996307 with total_loss: 6.162600480020046\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.13083307445049286 with total_loss: 6.293306119740009\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.13356782495975494 with total_loss: 6.424139194190502\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.18014878034591675 with total_loss: 6.557707019150257\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.08241917937994003 with total_loss: 6.737855799496174\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.09972699731588364 with total_loss: 6.820274978876114\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.10217482596635818 with total_loss: 6.9200019761919975\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.07673162966966629 with total_loss: 7.022176802158356\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.04967411234974861 with total_loss: 7.098908431828022\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.04698815941810608 with total_loss: 7.148582544177771\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.02635979652404785 with total_loss: 7.195570703595877\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.04897991940379143 with total_loss: 7.2219305001199245\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.051434699445962906 with total_loss: 7.270910419523716\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.05854933336377144 with total_loss: 7.322345118969679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.06483510881662369 with total_loss: 7.38089445233345\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.0448581762611866 with total_loss: 7.445729561150074\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.03420282527804375 with total_loss: 7.490587737411261\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.03471654653549194 with total_loss: 7.524790562689304\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.035589441657066345 with total_loss: 7.559507109224796\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.04014299437403679 with total_loss: 7.595096550881863\n",
      "  Batch    76  of     94.    Elapsed: 0:00:01. with Loss: 0.03852228820323944 with total_loss: 7.635239545255899\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.0344759076833725 with total_loss: 7.673761833459139\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.05938691273331642 with total_loss: 7.708237741142511\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.05059255287051201 with total_loss: 7.767624653875828\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.03656049817800522 with total_loss: 7.81821720674634\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.054580092430114746 with total_loss: 7.854777704924345\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.03247956559062004 with total_loss: 7.90935779735446\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.03689860552549362 with total_loss: 7.94183736294508\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.03474954143166542 with total_loss: 7.978735968470573\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.048661500215530396 with total_loss: 8.013485509902239\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.039078183472156525 with total_loss: 8.06214701011777\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.038336142897605896 with total_loss: 8.101225193589926\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.028216036036610603 with total_loss: 8.139561336487532\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.03014400601387024 with total_loss: 8.167777372524142\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.02949405647814274 with total_loss: 8.197921378538013\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.032705627381801605 with total_loss: 8.227415435016155\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.03258668631315231 with total_loss: 8.260121062397957\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.028314344584941864 with total_loss: 8.29270774871111\n",
      "\n",
      "  Average training loss: 0.09\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 7 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.027404412627220154 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.05261077359318733 with total_loss: 0.027404412627220154\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.03017996996641159 with total_loss: 0.08001518622040749\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.02470572292804718 with total_loss: 0.11019515618681908\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.022222520783543587 with total_loss: 0.13490087911486626\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.02083839662373066 with total_loss: 0.15712339989840984\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.033806875348091125 with total_loss: 0.1779617965221405\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.018155289813876152 with total_loss: 0.21176867187023163\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.03400126472115517 with total_loss: 0.22992396168410778\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.02739299088716507 with total_loss: 0.26392522640526295\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.031817805022001266 with total_loss: 0.291318217292428\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.026110351085662842 with total_loss: 0.3231360223144293\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.022713350132107735 with total_loss: 0.3492463734000921\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.038903675973415375 with total_loss: 0.37195972353219986\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.0315355621278286 with total_loss: 0.41086339950561523\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.059509411454200745 with total_loss: 0.44239896163344383\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.0215440820902586 with total_loss: 0.5019083730876446\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.030596083030104637 with total_loss: 0.5234524551779032\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.032259635627269745 with total_loss: 0.5540485382080078\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.035988107323646545 with total_loss: 0.5863081738352776\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.029640892520546913 with total_loss: 0.6222962811589241\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.03701502084732056 with total_loss: 0.651937173679471\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.03432205691933632 with total_loss: 0.6889521945267916\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.02883661352097988 with total_loss: 0.7232742514461279\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.030743291601538658 with total_loss: 0.7521108649671078\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.02779008448123932 with total_loss: 0.7828541565686464\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.02654288150370121 with total_loss: 0.8106442410498857\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.027088403701782227 with total_loss: 0.837187122553587\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.01942516677081585 with total_loss: 0.8642755262553692\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.02324092388153076 with total_loss: 0.883700693026185\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.02700422890484333 with total_loss: 0.9069416169077158\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.15091051161289215 with total_loss: 0.9339458458125591\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.19920356571674347 with total_loss: 1.0848563574254513\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.13356921076774597 with total_loss: 1.2840599231421947\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.08391053229570389 with total_loss: 1.4176291339099407\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.13178947567939758 with total_loss: 1.5015396662056446\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.30306217074394226 with total_loss: 1.6333291418850422\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.1821456402540207 with total_loss: 1.9363913126289845\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.1326867789030075 with total_loss: 2.118536952883005\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.1639709621667862 with total_loss: 2.2512237317860126\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.12038112431764603 with total_loss: 2.415194693952799\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.10332095623016357 with total_loss: 2.535575818270445\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.10317892581224442 with total_loss: 2.6388967745006084\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.12717776000499725 with total_loss: 2.742075700312853\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.14962215721607208 with total_loss: 2.86925346031785\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.08871104568243027 with total_loss: 3.018875617533922\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.09593450278043747 with total_loss: 3.1075866632163525\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.12094663828611374 with total_loss: 3.20352116599679\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.08442514389753342 with total_loss: 3.3244678042829037\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.1103864312171936 with total_loss: 3.408892948180437\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.11195822805166245 with total_loss: 3.5192793793976307\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.09551026672124863 with total_loss: 3.631237607449293\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.09621227532625198 with total_loss: 3.7267478741705418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.11403878778219223 with total_loss: 3.8229601494967937\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.0807308629155159 with total_loss: 3.936998937278986\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.06934322416782379 with total_loss: 4.017729800194502\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.07375862449407578 with total_loss: 4.087073024362326\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.06755771487951279 with total_loss: 4.160831648856401\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.06699374318122864 with total_loss: 4.228389363735914\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.09201376885175705 with total_loss: 4.295383106917143\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.06538455933332443 with total_loss: 4.3873968757689\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.06028546392917633 with total_loss: 4.452781435102224\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.06305927783250809 with total_loss: 4.513066899031401\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.044355954974889755 with total_loss: 4.576126176863909\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.0343807227909565 with total_loss: 4.6204821318387985\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.022514715790748596 with total_loss: 4.654862854629755\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.023312082514166832 with total_loss: 4.677377570420504\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.03274675831198692 with total_loss: 4.7006896529346704\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.026796935126185417 with total_loss: 4.733436411246657\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.03668065741658211 with total_loss: 4.760233346372843\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.03412254527211189 with total_loss: 4.796914003789425\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.03397316113114357 with total_loss: 4.831036549061537\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.025759100914001465 with total_loss: 4.86500971019268\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.027219029143452644 with total_loss: 4.890768811106682\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.018432537093758583 with total_loss: 4.9179878402501345\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.02728804387152195 with total_loss: 4.936420377343893\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.06549898535013199 with total_loss: 4.963708421215415\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.021400844678282738 with total_loss: 5.029207406565547\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.03637233376502991 with total_loss: 5.05060825124383\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.022889813408255577 with total_loss: 5.08698058500886\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.023246407508850098 with total_loss: 5.109870398417115\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.022024990990757942 with total_loss: 5.133116805925965\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.01597866415977478 with total_loss: 5.155141796916723\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.020707009360194206 with total_loss: 5.171120461076498\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.026119118556380272 with total_loss: 5.191827470436692\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.022696541622281075 with total_loss: 5.2179465889930725\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.02710527740418911 with total_loss: 5.240643130615354\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.02480723150074482 with total_loss: 5.267748408019543\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.01970232091844082 with total_loss: 5.2925556395202875\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.019349725916981697 with total_loss: 5.312257960438728\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.02343934029340744 with total_loss: 5.33160768635571\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.01570955105125904 with total_loss: 5.3550470266491175\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.02277427911758423 with total_loss: 5.3707565777003765\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.016467180103063583 with total_loss: 5.393530856817961\n",
      "\n",
      "  Average training loss: 0.06\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 8 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.020617550238966942 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.02680564858019352 with total_loss: 0.020617550238966942\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.019367102533578873 with total_loss: 0.04742319881916046\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.03565360978245735 with total_loss: 0.06679030135273933\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.01932443305850029 with total_loss: 0.10244391113519669\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.024847140535712242 with total_loss: 0.12176834419369698\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.017430633306503296 with total_loss: 0.14661548472940922\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.02375049702823162 with total_loss: 0.1640461180359125\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.015236354433000088 with total_loss: 0.18779661506414413\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.02750176005065441 with total_loss: 0.20303296949714422\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.01857810467481613 with total_loss: 0.23053472954779863\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.033665455877780914 with total_loss: 0.24911283422261477\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.020516103133559227 with total_loss: 0.2827782901003957\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.026640629395842552 with total_loss: 0.3032943932339549\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.018455946817994118 with total_loss: 0.32993502262979746\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.015605938620865345 with total_loss: 0.3483909694477916\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.01952906884253025 with total_loss: 0.3639969080686569\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.0319492407143116 with total_loss: 0.38352597691118717\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.01887836866080761 with total_loss: 0.41547521762549877\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.01832718215882778 with total_loss: 0.4343535862863064\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.01765122264623642 with total_loss: 0.45268076844513416\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.022694433107972145 with total_loss: 0.4703319910913706\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.02341015636920929 with total_loss: 0.4930264241993427\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.02571389265358448 with total_loss: 0.516436580568552\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.018621714785695076 with total_loss: 0.5421504732221365\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.013814757578074932 with total_loss: 0.5607721880078316\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.015914926305413246 with total_loss: 0.5745869455859065\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.02039785124361515 with total_loss: 0.5905018718913198\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.02716388739645481 with total_loss: 0.6108997231349349\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.023043150082230568 with total_loss: 0.6380636105313897\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.014392546378076077 with total_loss: 0.6611067606136203\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.07203484326601028 with total_loss: 0.6754993069916964\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.15282900631427765 with total_loss: 0.7475341502577066\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.11058715730905533 with total_loss: 0.9003631565719843\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.06558778136968613 with total_loss: 1.0109503138810396\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.06187485530972481 with total_loss: 1.0765380952507257\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.08462732285261154 with total_loss: 1.1384129505604506\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.07882995158433914 with total_loss: 1.223040273413062\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.054501693695783615 with total_loss: 1.3018702249974012\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.0705694779753685 with total_loss: 1.3563719186931849\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.1452721506357193 with total_loss: 1.4269413966685534\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.07157816737890244 with total_loss: 1.5722135473042727\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.06280065327882767 with total_loss: 1.643791714683175\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.05386930704116821 with total_loss: 1.7065923679620028\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.060041215270757675 with total_loss: 1.760461675003171\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.0495847649872303 with total_loss: 1.8205028902739286\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.08007163554430008 with total_loss: 1.870087655261159\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.052515026181936264 with total_loss: 1.950159290805459\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.08297418802976608 with total_loss: 2.0026743169873953\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.05732548236846924 with total_loss: 2.0856485050171614\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.17338980734348297 with total_loss: 2.1429739873856306\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.04764966294169426 with total_loss: 2.3163637947291136\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.06643953174352646 with total_loss: 2.364013457670808\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.0340273417532444 with total_loss: 2.4304529894143343\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.04553220793604851 with total_loss: 2.4644803311675787\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.04330962896347046 with total_loss: 2.510012539103627\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.045030634850263596 with total_loss: 2.5533221680670977\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.047077521681785583 with total_loss: 2.5983528029173613\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.047749679535627365 with total_loss: 2.645430324599147\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.11310642957687378 with total_loss: 2.693180004134774\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.04201091453433037 with total_loss: 2.806286433711648\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.06162811815738678 with total_loss: 2.8482973482459784\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.030305176973342896 with total_loss: 2.909925466403365\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.025478528812527657 with total_loss: 2.940230643376708\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.02197796106338501 with total_loss: 2.9657091721892357\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.02251484990119934 with total_loss: 2.9876871332526207\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.02606811374425888 with total_loss: 3.01020198315382\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.025276198983192444 with total_loss: 3.036270096898079\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.021901240572333336 with total_loss: 3.0615462958812714\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.029757807031273842 with total_loss: 3.0834475364536047\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.016441693529486656 with total_loss: 3.1132053434848785\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.02248275838792324 with total_loss: 3.129647037014365\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.015501454472541809 with total_loss: 3.1521297954022884\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.01853792928159237 with total_loss: 3.1676312498748302\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.02173764258623123 with total_loss: 3.1861691791564226\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.021143943071365356 with total_loss: 3.207906821742654\n",
      "  Batch    76  of     94.    Elapsed: 0:00:01. with Loss: 0.020482411608099937 with total_loss: 3.229050764814019\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.018012473359704018 with total_loss: 3.249533176422119\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.02527514286339283 with total_loss: 3.267545649781823\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.019422003999352455 with total_loss: 3.292820792645216\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.020811324939131737 with total_loss: 3.3122427966445684\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.015996679663658142 with total_loss: 3.3330541215837\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.012401456944644451 with total_loss: 3.3490508012473583\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.02206377126276493 with total_loss: 3.3614522581920028\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.013804045505821705 with total_loss: 3.3835160294547677\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.01978514902293682 with total_loss: 3.3973200749605894\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.016842670738697052 with total_loss: 3.4171052239835262\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.023902231827378273 with total_loss: 3.4339478947222233\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.015801506116986275 with total_loss: 3.4578501265496016\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.01548707950860262 with total_loss: 3.473651632666588\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.017688540741801262 with total_loss: 3.4891387121751904\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.015385535545647144 with total_loss: 3.5068272529169917\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.014517190866172314 with total_loss: 3.522212788462639\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.027061298489570618 with total_loss: 3.536729979328811\n",
      "\n",
      "  Average training loss: 0.04\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 9 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.019169649109244347 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.01778130792081356 with total_loss: 0.019169649109244347\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.013693027198314667 with total_loss: 0.03695095703005791\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.01842849887907505 with total_loss: 0.050643984228372574\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.020643383264541626 with total_loss: 0.06907248310744762\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.01646941527724266 with total_loss: 0.08971586637198925\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.0213934276252985 with total_loss: 0.10618528164923191\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.01432415097951889 with total_loss: 0.1275787092745304\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.021746525540947914 with total_loss: 0.1419028602540493\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.03255843743681908 with total_loss: 0.16364938579499722\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.02287670038640499 with total_loss: 0.1962078232318163\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.015472407452762127 with total_loss: 0.21908452361822128\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.015353508293628693 with total_loss: 0.2345569310709834\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.01817038096487522 with total_loss: 0.2499104393646121\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.012799732387065887 with total_loss: 0.2680808203294873\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.015589259564876556 with total_loss: 0.2808805527165532\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.019050680100917816 with total_loss: 0.29646981228142977\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.020498227328062057 with total_loss: 0.3155204923823476\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.019505294039845467 with total_loss: 0.33601871971040964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.012516113929450512 with total_loss: 0.3555240137502551\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.13116063177585602 with total_loss: 0.3680401276797056\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.017010951414704323 with total_loss: 0.49920075945556164\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.019621362909674644 with total_loss: 0.516211710870266\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.010765936225652695 with total_loss: 0.5358330737799406\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.014116816222667694 with total_loss: 0.5465990100055933\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.015080627985298634 with total_loss: 0.560715826228261\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.01689543016254902 with total_loss: 0.5757964542135596\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.018172621726989746 with total_loss: 0.5926918843761086\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.01194132398813963 with total_loss: 0.6108645061030984\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.015831997618079185 with total_loss: 0.622805830091238\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.02134244702756405 with total_loss: 0.6386378277093172\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.0732261911034584 with total_loss: 0.6599802747368813\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.10319701582193375 with total_loss: 0.7332064658403397\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.06179085746407509 with total_loss: 0.8364034816622734\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.0689903125166893 with total_loss: 0.8981943391263485\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.053566958755254745 with total_loss: 0.9671846516430378\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.041084811091423035 with total_loss: 1.0207516103982925\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.045233774930238724 with total_loss: 1.0618364214897156\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.04143545404076576 with total_loss: 1.1070701964199543\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.04527412727475166 with total_loss: 1.14850565046072\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.043891895562410355 with total_loss: 1.1937797777354717\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.049282848834991455 with total_loss: 1.237671673297882\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.05849507823586464 with total_loss: 1.2869545221328735\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.042561035603284836 with total_loss: 1.3454496003687382\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.050809282809495926 with total_loss: 1.388010635972023\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.07815475016832352 with total_loss: 1.438819918781519\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.038968075066804886 with total_loss: 1.5169746689498425\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.04517233371734619 with total_loss: 1.5559427440166473\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.044404368847608566 with total_loss: 1.6011150777339935\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.04581825062632561 with total_loss: 1.645519446581602\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.046734292060136795 with total_loss: 1.6913376972079277\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.03781693056225777 with total_loss: 1.7380719892680645\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.04241769388318062 with total_loss: 1.7758889198303223\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.036555856466293335 with total_loss: 1.8183066137135029\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.04116252064704895 with total_loss: 1.8548624701797962\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.02997090481221676 with total_loss: 1.8960249908268452\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.02749972976744175 with total_loss: 1.925995895639062\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.04434880614280701 with total_loss: 1.9534956254065037\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.034395117312669754 with total_loss: 1.9978444315493107\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.048477787524461746 with total_loss: 2.0322395488619804\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.033578842878341675 with total_loss: 2.080717336386442\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.12369748204946518 with total_loss: 2.114296179264784\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.038512568920850754 with total_loss: 2.237993661314249\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.03724013641476631 with total_loss: 2.2765062302351\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.030160313472151756 with total_loss: 2.313746366649866\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.0177836325019598 with total_loss: 2.343906680122018\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.018493685871362686 with total_loss: 2.3616903126239777\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.023239200934767723 with total_loss: 2.3801839984953403\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.022374892607331276 with total_loss: 2.403423199430108\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.025311561301350594 with total_loss: 2.4257980920374393\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.021854588761925697 with total_loss: 2.45110965333879\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.025770505890250206 with total_loss: 2.4729642421007156\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.012699618935585022 with total_loss: 2.498734747990966\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.012704710476100445 with total_loss: 2.511434366926551\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.012447900138795376 with total_loss: 2.5241390774026513\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.014080538414418697 with total_loss: 2.5365869775414467\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.024861639365553856 with total_loss: 2.5506675159558654\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.015594645403325558 with total_loss: 2.5755291553214192\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.018457965925335884 with total_loss: 2.591123800724745\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.016358161345124245 with total_loss: 2.6095817666500807\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.01050532329827547 with total_loss: 2.625939927995205\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.016121255233883858 with total_loss: 2.6364452512934804\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.01766452006995678 with total_loss: 2.6525665065273643\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.021341780200600624 with total_loss: 2.670231026597321\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.012244838289916515 with total_loss: 2.6915728067979217\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.015656763687729836 with total_loss: 2.703817645087838\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.017535647377371788 with total_loss: 2.719474408775568\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.01478491723537445 with total_loss: 2.73701005615294\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.012283924035727978 with total_loss: 2.7517949733883142\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.0282172542065382 with total_loss: 2.7640788974240422\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.023039793595671654 with total_loss: 2.7922961516305804\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.01478571817278862 with total_loss: 2.815335945226252\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.015995092689990997 with total_loss: 2.8301216633990407\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.014612340368330479 with total_loss: 2.8461167560890317\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 10 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.01629328913986683 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.01137075200676918 with total_loss: 0.01629328913986683\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.15620921552181244 with total_loss: 0.02766404114663601\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.015408794395625591 with total_loss: 0.18387325666844845\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.013975861482322216 with total_loss: 0.19928205106407404\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.014801844023168087 with total_loss: 0.21325791254639626\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.01675596833229065 with total_loss: 0.22805975656956434\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.015086990781128407 with total_loss: 0.244815724901855\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.02050686813890934 with total_loss: 0.2599027156829834\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.01656654104590416 with total_loss: 0.28040958382189274\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.018598152324557304 with total_loss: 0.2969761248677969\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.017796894535422325 with total_loss: 0.3155742771923542\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.018103543668985367 with total_loss: 0.3333711717277765\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.033314380794763565 with total_loss: 0.3514747153967619\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.012134849093854427 with total_loss: 0.38478909619152546\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.01795297861099243 with total_loss: 0.3969239452853799\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.012065034359693527 with total_loss: 0.4148769238963723\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.022035324946045876 with total_loss: 0.42694195825606585\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.013096236623823643 with total_loss: 0.4489772832021117\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.01611172966659069 with total_loss: 0.46207351982593536\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.018007071688771248 with total_loss: 0.47818524949252605\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.011416216380894184 with total_loss: 0.4961923211812973\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.014088164083659649 with total_loss: 0.5076085375621915\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.019707275554537773 with total_loss: 0.5216967016458511\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.015432375483214855 with total_loss: 0.5414039772003889\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.017661714926362038 with total_loss: 0.5568363526836038\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.013833620585501194 with total_loss: 0.5744980676099658\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.014368879608809948 with total_loss: 0.588331688195467\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.017991334199905396 with total_loss: 0.6027005678042769\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.014371201395988464 with total_loss: 0.6206919020041823\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.01191793754696846 with total_loss: 0.6350631034001708\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.044807400554418564 with total_loss: 0.6469810409471393\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.0462183840572834 with total_loss: 0.6917884415015578\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.030091265216469765 with total_loss: 0.7380068255588412\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.03377464786171913 with total_loss: 0.768098090775311\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.040876034647226334 with total_loss: 0.8018727386370301\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.03807659074664116 with total_loss: 0.8427487732842565\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.034888770431280136 with total_loss: 0.8808253640308976\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.037167493253946304 with total_loss: 0.9157141344621778\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.03261440992355347 with total_loss: 0.9528816277161241\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.035611506551504135 with total_loss: 0.9854960376396775\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.04640887305140495 with total_loss: 1.0211075441911817\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.034033216536045074 with total_loss: 1.0675164172425866\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.02879592776298523 with total_loss: 1.1015496337786317\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.027948768809437752 with total_loss: 1.130345561541617\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.03475678712129593 with total_loss: 1.1582943303510547\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.027636483311653137 with total_loss: 1.1930511174723506\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.029070382937788963 with total_loss: 1.2206876007840037\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.018917862325906754 with total_loss: 1.2497579837217927\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.030648022890090942 with total_loss: 1.2686758460476995\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.026317551732063293 with total_loss: 1.2993238689377904\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.028932316228747368 with total_loss: 1.3256414206698537\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.0335666798055172 with total_loss: 1.354573736898601\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.10047300904989243 with total_loss: 1.3881404167041183\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.0539449118077755 with total_loss: 1.4886134257540107\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.030621076002717018 with total_loss: 1.5425583375617862\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.019492387771606445 with total_loss: 1.5731794135645032\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.027852317318320274 with total_loss: 1.5926718013361096\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.04854893684387207 with total_loss: 1.62052411865443\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.07153602689504623 with total_loss: 1.669073055498302\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.021424027159810066 with total_loss: 1.7406090823933482\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.06476377695798874 with total_loss: 1.7620331095531583\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.01529961358755827 with total_loss: 1.826796886511147\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.014411848969757557 with total_loss: 1.8420965000987053\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.020384835079312325 with total_loss: 1.8565083490684628\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.015011526644229889 with total_loss: 1.8768931841477752\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.014245077967643738 with total_loss: 1.891904710792005\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.016751604154706 with total_loss: 1.9061497887596488\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.015247832983732224 with total_loss: 1.9229013929143548\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.015677450224757195 with total_loss: 1.938149225898087\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.01502196490764618 with total_loss: 1.9538266761228442\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.017640268430113792 with total_loss: 1.9688486410304904\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.01613074541091919 with total_loss: 1.9864889094606042\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.026877492666244507 with total_loss: 2.0026196548715234\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.01862705685198307 with total_loss: 2.029497147537768\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.012702045030891895 with total_loss: 2.048124204389751\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.024099012836813927 with total_loss: 2.060826249420643\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.01718246378004551 with total_loss: 2.084925262257457\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.019303495064377785 with total_loss: 2.1021077260375023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.01414903998374939 with total_loss: 2.12141122110188\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.012929581105709076 with total_loss: 2.1355602610856295\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.01596475951373577 with total_loss: 2.1484898421913385\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.010844714939594269 with total_loss: 2.1644546017050743\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.016648253425955772 with total_loss: 2.1752993166446686\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.02279072441160679 with total_loss: 2.1919475700706244\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.01559132058173418 with total_loss: 2.214738294482231\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.037039417773485184 with total_loss: 2.2303296150639653\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.01820760779082775 with total_loss: 2.2673690328374505\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.00981095526367426 with total_loss: 2.2855766406282783\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.015668077394366264 with total_loss: 2.2953875958919525\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.017705878242850304 with total_loss: 2.311055673286319\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.011471022851765156 with total_loss: 2.328761551529169\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.010469379834830761 with total_loss: 2.3402325743809342\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.009853902272880077 with total_loss: 2.350701954215765\n",
      "\n",
      "  Average training loss: 0.03\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 11 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.10155493766069412 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.011536340229213238 with total_loss: 0.10155493766069412\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.017996469512581825 with total_loss: 0.11309127788990736\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.01377599686384201 with total_loss: 0.13108774740248919\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.015244059264659882 with total_loss: 0.1448637442663312\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.011789005249738693 with total_loss: 0.16010780353099108\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.011227968148887157 with total_loss: 0.17189680878072977\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.015663927420973778 with total_loss: 0.18312477692961693\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.014735154807567596 with total_loss: 0.1987887043505907\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.01609153486788273 with total_loss: 0.2135238591581583\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.009968054480850697 with total_loss: 0.22961539402604103\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.016105061396956444 with total_loss: 0.23958344850689173\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.00908379815518856 with total_loss: 0.25568850990384817\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.01678166724741459 with total_loss: 0.26477230805903673\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.01404802780598402 with total_loss: 0.2815539753064513\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.015268099494278431 with total_loss: 0.29560200311243534\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.014433602802455425 with total_loss: 0.31087010260671377\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.012975546531379223 with total_loss: 0.3253037054091692\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.008579877205193043 with total_loss: 0.3382792519405484\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.011418849229812622 with total_loss: 0.34685912914574146\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.011806446127593517 with total_loss: 0.3582779783755541\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.020374611020088196 with total_loss: 0.3700844245031476\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.025328457355499268 with total_loss: 0.3904590355232358\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.015803705900907516 with total_loss: 0.41578749287873507\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.011322562582790852 with total_loss: 0.4315911987796426\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.01963866502046585 with total_loss: 0.44291376136243343\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.010130512528121471 with total_loss: 0.4625524263828993\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.01358765084296465 with total_loss: 0.47268293891102076\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.011315692216157913 with total_loss: 0.4862705897539854\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.013684608973562717 with total_loss: 0.4975862819701433\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.013232658617198467 with total_loss: 0.511270890943706\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.03788754343986511 with total_loss: 0.5245035495609045\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.06458029896020889 with total_loss: 0.5623910930007696\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.03628944233059883 with total_loss: 0.6269713919609785\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.025782188400626183 with total_loss: 0.6632608342915773\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.02237297035753727 with total_loss: 0.6890430226922035\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.033858153969049454 with total_loss: 0.7114159930497408\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.02546008862555027 with total_loss: 0.7452741470187902\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.03185727819800377 with total_loss: 0.7707342356443405\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.021002784371376038 with total_loss: 0.8025915138423443\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.0475890226662159 with total_loss: 0.8235942982137203\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.044454190880060196 with total_loss: 0.8711833208799362\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.02855999954044819 with total_loss: 0.9156375117599964\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.02662123553454876 with total_loss: 0.9441975113004446\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.02051786705851555 with total_loss: 0.9708187468349934\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.015380092896521091 with total_loss: 0.9913366138935089\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.021102307364344597 with total_loss: 1.00671670679003\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.03604981675744057 with total_loss: 1.0278190141543746\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.02225686050951481 with total_loss: 1.0638688309118152\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.027839243412017822 with total_loss: 1.08612569142133\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.022812360897660255 with total_loss: 1.1139649348333478\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.020190555602312088 with total_loss: 1.136777295731008\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.027769440785050392 with total_loss: 1.1569678513333201\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.050599079579114914 with total_loss: 1.1847372921183705\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.020884817466139793 with total_loss: 1.2353363716974854\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.028222262859344482 with total_loss: 1.2562211891636252\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.047280728816986084 with total_loss: 1.2844434520229697\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.02390351891517639 with total_loss: 1.3317241808399558\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.03452568128705025 with total_loss: 1.3556276997551322\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.03256048262119293 with total_loss: 1.3901533810421824\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.02549353800714016 with total_loss: 1.4227138636633754\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.04158435016870499 with total_loss: 1.4482074016705155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.016121909022331238 with total_loss: 1.4897917518392205\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.017837686464190483 with total_loss: 1.5059136608615518\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.010395356453955173 with total_loss: 1.5237513473257422\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.012453489005565643 with total_loss: 1.5341467037796974\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.010853949934244156 with total_loss: 1.546600192785263\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.01208257395774126 with total_loss: 1.5574541427195072\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.013677512295544147 with total_loss: 1.5695367166772485\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.01582610048353672 with total_loss: 1.5832142289727926\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.01378168910741806 with total_loss: 1.5990403294563293\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.013693645596504211 with total_loss: 1.6128220185637474\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.012159156613051891 with total_loss: 1.6265156641602516\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.013180903159081936 with total_loss: 1.6386748207733035\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.011684422381222248 with total_loss: 1.6518557239323854\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.012393592856824398 with total_loss: 1.6635401463136077\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.014124460518360138 with total_loss: 1.675933739170432\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.010758512653410435 with total_loss: 1.6900581996887922\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.01700170896947384 with total_loss: 1.7008167123422027\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.013923774473369122 with total_loss: 1.7178184213116765\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.012230056338012218 with total_loss: 1.7317421957850456\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.011835050769150257 with total_loss: 1.7439722521230578\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.012708884663879871 with total_loss: 1.755807302892208\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.01228936668485403 with total_loss: 1.768516187556088\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.012974546290934086 with total_loss: 1.780805554240942\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.013257662765681744 with total_loss: 1.793780100531876\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.01478914450854063 with total_loss: 1.8070377632975578\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.013260569423437119 with total_loss: 1.8218269078060985\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.012660558335483074 with total_loss: 1.8350874772295356\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.01771777868270874 with total_loss: 1.8477480355650187\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.008582946844398975 with total_loss: 1.8654658142477274\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.010716214776039124 with total_loss: 1.8740487610921264\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.015433167107403278 with total_loss: 1.8847649758681655\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.011592409573495388 with total_loss: 1.9001981429755688\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 12 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.012451909482479095 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.011589276604354382 with total_loss: 0.012451909482479095\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.011328835040330887 with total_loss: 0.024041186086833477\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.014040068723261356 with total_loss: 0.035370021127164364\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.01235390454530716 with total_loss: 0.04941008985042572\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.015250750817358494 with total_loss: 0.06176399439573288\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.011449120938777924 with total_loss: 0.07701474521309137\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.008264612406492233 with total_loss: 0.0884638661518693\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.010315713472664356 with total_loss: 0.09672847855836153\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.010080189444124699 with total_loss: 0.10704419203102589\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.012493199668824673 with total_loss: 0.11712438147515059\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.009065943770110607 with total_loss: 0.12961758114397526\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.01878258027136326 with total_loss: 0.13868352491408587\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.013630739413201809 with total_loss: 0.15746610518544912\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.021018587052822113 with total_loss: 0.17109684459865093\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.010189131833612919 with total_loss: 0.19211543165147305\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.009330414235591888 with total_loss: 0.20230456348508596\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.009248249232769012 with total_loss: 0.21163497772067785\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.01053445041179657 with total_loss: 0.22088322695344687\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.011337843723595142 with total_loss: 0.23141767736524343\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.009954159148037434 with total_loss: 0.24275552108883858\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.009719877503812313 with total_loss: 0.252709680236876\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.011178016662597656 with total_loss: 0.2624295577406883\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.011872579343616962 with total_loss: 0.273607574403286\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.008793347515165806 with total_loss: 0.28548015374690294\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.010948737151920795 with total_loss: 0.29427350126206875\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.01115258689969778 with total_loss: 0.30522223841398954\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.012182251550257206 with total_loss: 0.3163748253136873\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.010067152790725231 with total_loss: 0.32855707686394453\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.009820345789194107 with total_loss: 0.33862422965466976\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.009830392897129059 with total_loss: 0.34844457544386387\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.03572242334485054 with total_loss: 0.3582749683409929\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.04004880413413048 with total_loss: 0.39399739168584347\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.026075730100274086 with total_loss: 0.43404619581997395\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.01805213838815689 with total_loss: 0.46012192592024803\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.017896512523293495 with total_loss: 0.4781740643084049\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.030383385717868805 with total_loss: 0.4960705768316984\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.024756699800491333 with total_loss: 0.5264539625495672\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.0243882667273283 with total_loss: 0.5512106623500586\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.023290148004889488 with total_loss: 0.5755989290773869\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.029273955151438713 with total_loss: 0.5988890770822763\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.03637537732720375 with total_loss: 0.6281630322337151\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.02071528695523739 with total_loss: 0.6645384095609188\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.05292617157101631 with total_loss: 0.6852536965161562\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.023569459095597267 with total_loss: 0.7381798680871725\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.018659571185708046 with total_loss: 0.7617493271827698\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.018330944702029228 with total_loss: 0.7804088983684778\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.016980234533548355 with total_loss: 0.798739843070507\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.01725608855485916 with total_loss: 0.8157200776040554\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.012853850610554218 with total_loss: 0.8329761661589146\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.02123684249818325 with total_loss: 0.8458300167694688\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.015120044350624084 with total_loss: 0.867066859267652\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.019418062642216682 with total_loss: 0.8821869036182761\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.016838403418660164 with total_loss: 0.9016049662604928\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.015759766101837158 with total_loss: 0.918443369679153\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.016858207061886787 with total_loss: 0.9342031357809901\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.01628374122083187 with total_loss: 0.9510613428428769\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.014500517398118973 with total_loss: 0.9673450840637088\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.016152696684002876 with total_loss: 0.9818456014618278\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.019087783992290497 with total_loss: 0.9979982981458306\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.012471540831029415 with total_loss: 1.0170860821381211\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.030962007120251656 with total_loss: 1.0295576229691505\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.025950312614440918 with total_loss: 1.0605196300894022\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.02170913852751255 with total_loss: 1.0864699427038431\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.01606941409409046 with total_loss: 1.1081790812313557\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.011383282952010632 with total_loss: 1.1242484953254461\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.011973735876381397 with total_loss: 1.1356317782774568\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.010784685611724854 with total_loss: 1.1476055141538382\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.01727583073079586 with total_loss: 1.158390199765563\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.014399726875126362 with total_loss: 1.1756660304963589\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.01980549842119217 with total_loss: 1.1900657573714852\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.027371270582079887 with total_loss: 1.2098712557926774\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.011028609238564968 with total_loss: 1.2372425263747573\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.01603650115430355 with total_loss: 1.2482711356133223\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.012285557575523853 with total_loss: 1.2643076367676258\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.02063540555536747 with total_loss: 1.2765931943431497\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.018059413880109787 with total_loss: 1.2972285998985171\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.017701078206300735 with total_loss: 1.315288013778627\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.029526712372899055 with total_loss: 1.3329890919849277\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.012244101613759995 with total_loss: 1.3625158043578267\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.009140286594629288 with total_loss: 1.3747599059715867\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.008690111339092255 with total_loss: 1.383900192566216\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.012944047339260578 with total_loss: 1.3925903039053082\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.009169762022793293 with total_loss: 1.4055343512445688\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.017511246725916862 with total_loss: 1.4147041132673621\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.01312300842255354 with total_loss: 1.432215359993279\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.00987311452627182 with total_loss: 1.4453383684158325\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.0108909010887146 with total_loss: 1.4552114829421043\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.009444273076951504 with total_loss: 1.466102384030819\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.011552671901881695 with total_loss: 1.4755466571077704\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.009183512069284916 with total_loss: 1.4870993290096521\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.006508262827992439 with total_loss: 1.496282841078937\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.010706034488976002 with total_loss: 1.5027911039069295\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.009291368536651134 with total_loss: 1.5134971383959055\n",
      "\n",
      "  Average training loss: 0.02\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 13 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.009900880046188831 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.007295562420040369 with total_loss: 0.009900880046188831\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.01506184320896864 with total_loss: 0.0171964424662292\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.01092548668384552 with total_loss: 0.03225828567519784\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.01396919321268797 with total_loss: 0.04318377235904336\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.012283309362828732 with total_loss: 0.05715296557173133\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.025019794702529907 with total_loss: 0.06943627493456006\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.009844311513006687 with total_loss: 0.09445606963708997\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.010443960316479206 with total_loss: 0.10430038115009665\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.011719219386577606 with total_loss: 0.11474434146657586\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.012389193288981915 with total_loss: 0.12646356085315347\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.015566050074994564 with total_loss: 0.13885275414213538\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.011615917086601257 with total_loss: 0.15441880421712995\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.01033499464392662 with total_loss: 0.1660347213037312\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.010852289386093616 with total_loss: 0.17636971594765782\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.010185758583247662 with total_loss: 0.18722200533375144\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.012519910000264645 with total_loss: 0.1974077639169991\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.012008271180093288 with total_loss: 0.20992767391726375\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.03643151745200157 with total_loss: 0.22193594509735703\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.012189057655632496 with total_loss: 0.2583674625493586\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.009206295944750309 with total_loss: 0.2705565202049911\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.012409507296979427 with total_loss: 0.2797628161497414\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.009375334717333317 with total_loss: 0.29217232344672084\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.00946033839136362 with total_loss: 0.30154765816405416\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.014445867389440536 with total_loss: 0.3110079965554178\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.008183193393051624 with total_loss: 0.3254538639448583\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.00833913404494524 with total_loss: 0.33363705733790994\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.012896884232759476 with total_loss: 0.3419761913828552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.01090295147150755 with total_loss: 0.35487307561561465\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.011586946435272694 with total_loss: 0.3657760270871222\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.008440623059868813 with total_loss: 0.3773629735223949\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.038250237703323364 with total_loss: 0.3858035965822637\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.028319552540779114 with total_loss: 0.4240538342855871\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.027701733633875847 with total_loss: 0.4523733868263662\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.027998073026537895 with total_loss: 0.48007512046024203\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.02119472436606884 with total_loss: 0.5080731934867799\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.039028916507959366 with total_loss: 0.5292679178528488\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.024307074025273323 with total_loss: 0.5682968343608081\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.018336860463023186 with total_loss: 0.5926039083860815\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.02531588263809681 with total_loss: 0.6109407688491046\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.02267524041235447 with total_loss: 0.6362566514872015\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.01788141392171383 with total_loss: 0.6589318918995559\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.02146555483341217 with total_loss: 0.6768133058212698\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.026353010907769203 with total_loss: 0.6982788606546819\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.01798211596906185 with total_loss: 0.7246318715624511\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.016284292563796043 with total_loss: 0.742613987531513\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.01564296893775463 with total_loss: 0.758898280095309\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.01779870130121708 with total_loss: 0.7745412490330637\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.015477855689823627 with total_loss: 0.7923399503342807\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.01421420555561781 with total_loss: 0.8078178060241044\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.013220134191215038 with total_loss: 0.8220320115797222\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.013521273620426655 with total_loss: 0.8352521457709372\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.01312680821865797 with total_loss: 0.8487734193913639\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.018736492842435837 with total_loss: 0.8619002276100218\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.014835958369076252 with total_loss: 0.8806367204524577\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.012506671249866486 with total_loss: 0.8954726788215339\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.010946974158287048 with total_loss: 0.9079793500714004\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.019297152757644653 with total_loss: 0.9189263242296875\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.02432686649262905 with total_loss: 0.9382234769873321\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.029828181490302086 with total_loss: 0.9625503434799612\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.024981239810585976 with total_loss: 0.9923785249702632\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.01347444113343954 with total_loss: 1.0173597647808492\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.017856573686003685 with total_loss: 1.0308342059142888\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.009728264063596725 with total_loss: 1.0486907796002924\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.017186300829052925 with total_loss: 1.0584190436638892\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.01191219687461853 with total_loss: 1.075605344492942\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.008367176167666912 with total_loss: 1.0875175413675606\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.011352918110787868 with total_loss: 1.0958847175352275\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.013027864508330822 with total_loss: 1.1072376356460154\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.013362325727939606 with total_loss: 1.1202655001543462\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.011692901141941547 with total_loss: 1.1336278258822858\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.008510567247867584 with total_loss: 1.1453207270242274\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.009493502788245678 with total_loss: 1.153831294272095\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.012152653187513351 with total_loss: 1.1633247970603406\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.009836412966251373 with total_loss: 1.175477450247854\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.012203700840473175 with total_loss: 1.1853138632141054\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.007917764596641064 with total_loss: 1.1975175640545785\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.015623122453689575 with total_loss: 1.2054353286512196\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.014914232306182384 with total_loss: 1.2210584511049092\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.009232556447386742 with total_loss: 1.2359726834110916\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.011088651604950428 with total_loss: 1.2452052398584783\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.009821551851928234 with total_loss: 1.2562938914634287\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.011171333491802216 with total_loss: 1.266115443315357\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.01244334876537323 with total_loss: 1.2772867768071592\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.011868588626384735 with total_loss: 1.2897301255725324\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.010915624909102917 with total_loss: 1.3015987141989172\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.010788721032440662 with total_loss: 1.31251433910802\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.010988094843924046 with total_loss: 1.3233030601404607\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.008114085532724857 with total_loss: 1.3342911549843848\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.012412519194185734 with total_loss: 1.3424052405171096\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.008206118829548359 with total_loss: 1.3548177597112954\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.009294373914599419 with total_loss: 1.3630238785408437\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.007658421527594328 with total_loss: 1.3723182524554431\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.009654526598751545 with total_loss: 1.3799766739830375\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 14 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.010241050273180008 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.010841173119843006 with total_loss: 0.010241050273180008\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.010671825148165226 with total_loss: 0.021082223393023014\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.008610446937382221 with total_loss: 0.03175404854118824\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.009818200021982193 with total_loss: 0.04036449547857046\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.011061973869800568 with total_loss: 0.050182695500552654\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.009664141573011875 with total_loss: 0.06124466937035322\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.007263320032507181 with total_loss: 0.0709088109433651\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.017125731334090233 with total_loss: 0.07817213097587228\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.009932913817465305 with total_loss: 0.09529786230996251\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.00949530303478241 with total_loss: 0.10523077612742782\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.0121377008035779 with total_loss: 0.11472607916221023\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.012394580990076065 with total_loss: 0.12686377996578813\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.016139457002282143 with total_loss: 0.1392583609558642\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.009780042804777622 with total_loss: 0.15539781795814633\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.01079337764531374 with total_loss: 0.16517786076292396\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.010408059693872929 with total_loss: 0.1759712384082377\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.007763861212879419 with total_loss: 0.18637929810211062\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.01027380395680666 with total_loss: 0.19414315931499004\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.010544481687247753 with total_loss: 0.2044169632717967\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.00936249177902937 with total_loss: 0.21496144495904446\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.011122108437120914 with total_loss: 0.22432393673807383\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.011814013123512268 with total_loss: 0.23544604517519474\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.008411320857703686 with total_loss: 0.247260058298707\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.013784553855657578 with total_loss: 0.2556713791564107\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.009970528073608875 with total_loss: 0.26945593301206827\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.007842442952096462 with total_loss: 0.27942646108567715\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.0090976282954216 with total_loss: 0.2872689040377736\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.008100898005068302 with total_loss: 0.2963665323331952\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.008171088993549347 with total_loss: 0.3044674303382635\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.00900749210268259 with total_loss: 0.31263851933181286\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.018914872780442238 with total_loss: 0.32164601143449545\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.015562347136437893 with total_loss: 0.3405608842149377\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.013743232004344463 with total_loss: 0.3561232313513756\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.0438334196805954 with total_loss: 0.36986646335572004\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.01737556792795658 with total_loss: 0.41369988303631544\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.03439454361796379 with total_loss: 0.431075450964272\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.01448191236704588 with total_loss: 0.4654699945822358\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.012139223515987396 with total_loss: 0.4799519069492817\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.013801000081002712 with total_loss: 0.4920911304652691\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.017869746312499046 with total_loss: 0.5058921305462718\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.02054818533360958 with total_loss: 0.5237618768587708\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.03615236654877663 with total_loss: 0.5443100621923804\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.016279511153697968 with total_loss: 0.580462428741157\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.014731161296367645 with total_loss: 0.596741939894855\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.014304501004517078 with total_loss: 0.6114731011912227\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.031050875782966614 with total_loss: 0.6257776021957397\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.010917313396930695 with total_loss: 0.6568284779787064\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.013277380727231503 with total_loss: 0.667745791375637\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.013705077581107616 with total_loss: 0.6810231721028686\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.013934597373008728 with total_loss: 0.6947282496839762\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.01300143450498581 with total_loss: 0.7086628470569849\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.019552046433091164 with total_loss: 0.7216642815619707\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.027373500168323517 with total_loss: 0.7412163279950619\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.015175744891166687 with total_loss: 0.7685898281633854\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.009382294490933418 with total_loss: 0.7837655730545521\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.013100511394441128 with total_loss: 0.7931478675454855\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.013984255492687225 with total_loss: 0.8062483789399266\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.012308510951697826 with total_loss: 0.8202326344326138\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.020689697936177254 with total_loss: 0.8325411453843117\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.013348798267543316 with total_loss: 0.8532308433204889\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.014067977666854858 with total_loss: 0.8665796415880322\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.013644821010529995 with total_loss: 0.8806476192548871\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.01185289490967989 with total_loss: 0.8942924402654171\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.014913625083863735 with total_loss: 0.906145335175097\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.009794189594686031 with total_loss: 0.9210589602589607\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.010545815341174603 with total_loss: 0.9308531498536468\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.011961597017943859 with total_loss: 0.9413989651948214\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.014418545179069042 with total_loss: 0.9533605622127652\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.019563307985663414 with total_loss: 0.9677791073918343\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.010639174841344357 with total_loss: 0.9873424153774977\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.00925213098526001 with total_loss: 0.997981590218842\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.009164311923086643 with total_loss: 1.007233721204102\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.01134416088461876 with total_loss: 1.0163980331271887\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.00886563677340746 with total_loss: 1.0277421940118074\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.010417257435619831 with total_loss: 1.036607830785215\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.012320250272750854 with total_loss: 1.0470250882208347\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.01212292816489935 with total_loss: 1.0593453384935856\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.008397976867854595 with total_loss: 1.071468266658485\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.006707110907882452 with total_loss: 1.0798662435263395\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.009894312359392643 with total_loss: 1.086573354434222\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.008995850570499897 with total_loss: 1.0964676667936146\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.008709312416613102 with total_loss: 1.1054635173641145\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.011263360269367695 with total_loss: 1.1141728297807276\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.015342474915087223 with total_loss: 1.1254361900500953\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.00856220442801714 with total_loss: 1.1407786649651825\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.016493918374180794 with total_loss: 1.1493408693931997\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.008846254087984562 with total_loss: 1.1658347877673805\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.01129921805113554 with total_loss: 1.174681041855365\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.009750908240675926 with total_loss: 1.1859802599065006\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.008989933878183365 with total_loss: 1.1957311681471765\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.009696408174932003 with total_loss: 1.2047211020253599\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.01491533499211073 with total_loss: 1.2144175102002919\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.009760401211678982 with total_loss: 1.2293328451924026\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 15 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.007142116781324148 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.010070187039673328 with total_loss: 0.007142116781324148\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.006889428943395615 with total_loss: 0.017212303820997477\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.008226889185607433 with total_loss: 0.02410173276439309\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.010905901901423931 with total_loss: 0.032328621950000525\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.008834258653223515 with total_loss: 0.043234523851424456\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.006684979889541864 with total_loss: 0.05206878250464797\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.01023637130856514 with total_loss: 0.058753762394189835\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.01185560505837202 with total_loss: 0.06899013370275497\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.007567409425973892 with total_loss: 0.080845738761127\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.008809501305222511 with total_loss: 0.08841314818710089\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.010051760822534561 with total_loss: 0.0972226494923234\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.010931466706097126 with total_loss: 0.10727441031485796\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.010702204890549183 with total_loss: 0.11820587702095509\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.007891428656876087 with total_loss: 0.12890808191150427\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.011413839645683765 with total_loss: 0.13679951056838036\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.01123097538948059 with total_loss: 0.14821335021406412\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.01270076259970665 with total_loss: 0.1594443256035447\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.009557253681123257 with total_loss: 0.17214508820325136\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.006324002053588629 with total_loss: 0.18170234188437462\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.00660469988361001 with total_loss: 0.18802634393796325\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.011740786023437977 with total_loss: 0.19463104382157326\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.00885623600333929 with total_loss: 0.20637182984501123\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.009365434758365154 with total_loss: 0.21522806584835052\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.008460422046482563 with total_loss: 0.22459350060671568\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.007490521762520075 with total_loss: 0.23305392265319824\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.011287334375083447 with total_loss: 0.24054444441571832\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.011378669179975986 with total_loss: 0.25183177879080176\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.007479363586753607 with total_loss: 0.26321044797077775\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.00753764109686017 with total_loss: 0.27068981155753136\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.005946433637291193 with total_loss: 0.2782274526543915\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.012581643648445606 with total_loss: 0.2841738862916827\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.013561484403908253 with total_loss: 0.2967555299401283\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.017278658226132393 with total_loss: 0.3103170143440366\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.013864829204976559 with total_loss: 0.32759567257016897\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.008966268040239811 with total_loss: 0.34146050177514553\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.017787734046578407 with total_loss: 0.35042676981538534\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.010893508791923523 with total_loss: 0.36821450386196375\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.012489833869040012 with total_loss: 0.37910801265388727\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.014528632164001465 with total_loss: 0.3915978465229273\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.01393889170140028 with total_loss: 0.40612647868692875\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.01772412471473217 with total_loss: 0.42006537038832903\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.017513332888484 with total_loss: 0.4377894951030612\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.011495780199766159 with total_loss: 0.4553028279915452\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.009778543375432491 with total_loss: 0.46679860819131136\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.011702683754265308 with total_loss: 0.47657715156674385\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.014355058781802654 with total_loss: 0.48827983532100916\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.014268270693719387 with total_loss: 0.5026348941028118\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.010999946855008602 with total_loss: 0.5169031647965312\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.03408917412161827 with total_loss: 0.5279031116515398\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.014144458808004856 with total_loss: 0.5619922857731581\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.013830206356942654 with total_loss: 0.5761367445811629\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.013346217572689056 with total_loss: 0.5899669509381056\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.011298091150820255 with total_loss: 0.6033131685107946\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.014857803471386433 with total_loss: 0.6146112596616149\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.009466812945902348 with total_loss: 0.6294690631330013\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.015180674381554127 with total_loss: 0.6389358760789037\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.014291410334408283 with total_loss: 0.6541165504604578\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.01503557339310646 with total_loss: 0.6684079607948661\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.013192703016102314 with total_loss: 0.6834435341879725\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.011714001186192036 with total_loss: 0.6966362372040749\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.00820836704224348 with total_loss: 0.7083502383902669\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.012329678051173687 with total_loss: 0.7165586054325104\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.011967889964580536 with total_loss: 0.7288882834836841\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.008966018445789814 with total_loss: 0.7408561734482646\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.007416779175400734 with total_loss: 0.7498221918940544\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.008192128501832485 with total_loss: 0.7572389710694551\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.007177846506237984 with total_loss: 0.7654310995712876\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.01196020096540451 with total_loss: 0.7726089460775256\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.00977394450455904 with total_loss: 0.7845691470429301\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.007579388562589884 with total_loss: 0.7943430915474892\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.011333540081977844 with total_loss: 0.801922480110079\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.009735743515193462 with total_loss: 0.8132560201920569\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.014478436671197414 with total_loss: 0.8229917637072504\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.0131447808817029 with total_loss: 0.8374702003784478\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.07446246594190598 with total_loss: 0.8506149812601507\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.008887799456715584 with total_loss: 0.9250774472020566\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.008521190844476223 with total_loss: 0.9339652466587722\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.009327572770416737 with total_loss: 0.9424864375032485\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.008676428347826004 with total_loss: 0.9518140102736652\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.006829957943409681 with total_loss: 0.9604904386214912\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.010220338590443134 with total_loss: 0.9673203965649009\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.007549955043941736 with total_loss: 0.977540735155344\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.0077455476857721806 with total_loss: 0.9850906901992857\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.011385534889996052 with total_loss: 0.9928362378850579\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.015471103601157665 with total_loss: 1.004221772775054\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.01598445139825344 with total_loss: 1.0196928763762116\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.007832963950932026 with total_loss: 1.035677327774465\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.008234611712396145 with total_loss: 1.043510291725397\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.00843073707073927 with total_loss: 1.0517449034377933\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.007142601069062948 with total_loss: 1.0601756405085325\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.009218045510351658 with total_loss: 1.0673182415775955\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.009294980205595493 with total_loss: 1.0765362870879471\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.010906128212809563 with total_loss: 1.0858312672935426\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 16 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.007398711983114481 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.009277664124965668 with total_loss: 0.007398711983114481\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.007941215299069881 with total_loss: 0.01667637610808015\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.008372075855731964 with total_loss: 0.02461759140715003\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.006938877049833536 with total_loss: 0.032989667262881994\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.013006781227886677 with total_loss: 0.03992854431271553\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.00859034527093172 with total_loss: 0.05293532554060221\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.03175029158592224 with total_loss: 0.06152567081153393\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.00936046987771988 with total_loss: 0.09327596239745617\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.007137684617191553 with total_loss: 0.10263643227517605\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.012370798736810684 with total_loss: 0.1097741168923676\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.013157856650650501 with total_loss: 0.12214491562917829\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.011686998419463634 with total_loss: 0.1353027722798288\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0074757542461156845 with total_loss: 0.14698977069929242\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.011517022736370564 with total_loss: 0.1544655249454081\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.009621034376323223 with total_loss: 0.16598254768177867\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.008600572124123573 with total_loss: 0.1756035820581019\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.007022425532341003 with total_loss: 0.18420415418222547\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.010893515311181545 with total_loss: 0.19122657971456647\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.008218900300562382 with total_loss: 0.20212009502574801\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.007658802438527346 with total_loss: 0.2103389953263104\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.008766391314566135 with total_loss: 0.21799779776483774\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.00880227331072092 with total_loss: 0.22676418907940388\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.008014102466404438 with total_loss: 0.2355664623901248\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.010394918732345104 with total_loss: 0.24358056485652924\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.007107398007065058 with total_loss: 0.25397548358887434\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.005869237240403891 with total_loss: 0.2610828815959394\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.010240312665700912 with total_loss: 0.2669521188363433\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.007433904800564051 with total_loss: 0.2771924315020442\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.006459829863160849 with total_loss: 0.28462633630260825\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.008845529519021511 with total_loss: 0.2910861661657691\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.010137461125850677 with total_loss: 0.2999316956847906\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.014508490450680256 with total_loss: 0.3100691568106413\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.010130519978702068 with total_loss: 0.32457764726132154\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.010779825039207935 with total_loss: 0.3347081672400236\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.009423524141311646 with total_loss: 0.34548799227923155\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.015158298425376415 with total_loss: 0.3549115164205432\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.021709462627768517 with total_loss: 0.3700698148459196\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.0116504468023777 with total_loss: 0.3917792774736881\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.012448052875697613 with total_loss: 0.4034297242760658\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.017110710963606834 with total_loss: 0.41587777715176344\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.011941399425268173 with total_loss: 0.4329884881153703\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.0125827481970191 with total_loss: 0.44492988754063845\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.009564404375851154 with total_loss: 0.45751263573765755\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.009828299283981323 with total_loss: 0.4670770401135087\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.008256345055997372 with total_loss: 0.47690533939749\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.011330240406095982 with total_loss: 0.4851616844534874\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.010677079670131207 with total_loss: 0.4964919248595834\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.010137437842786312 with total_loss: 0.5071690045297146\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.010059591382741928 with total_loss: 0.5173064423725009\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.009816610254347324 with total_loss: 0.5273660337552428\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.01039059367030859 with total_loss: 0.5371826440095901\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.0091736214235425 with total_loss: 0.5475732376798987\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.016291899606585503 with total_loss: 0.5567468591034412\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.01193318236619234 with total_loss: 0.5730387587100267\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.010854288935661316 with total_loss: 0.5849719410762191\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.010303488932549953 with total_loss: 0.5958262300118804\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.009768865071237087 with total_loss: 0.6061297189444304\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.012654553167521954 with total_loss: 0.6158985840156674\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.010516178794205189 with total_loss: 0.6285531371831894\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.01730826310813427 with total_loss: 0.6390693159773946\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.012855670414865017 with total_loss: 0.6563775790855289\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.010177139192819595 with total_loss: 0.6692332495003939\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.01066826656460762 with total_loss: 0.6794103886932135\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.006215354893356562 with total_loss: 0.6900786552578211\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.00787483062595129 with total_loss: 0.6962940101511776\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.009223065339028835 with total_loss: 0.7041688407771289\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.009288029745221138 with total_loss: 0.7133919061161578\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.007987432181835175 with total_loss: 0.7226799358613789\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.009410454891622066 with total_loss: 0.7306673680432141\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.00730174919590354 with total_loss: 0.7400778229348361\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.0072641498409211636 with total_loss: 0.7473795721307397\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.00874273106455803 with total_loss: 0.7546437219716609\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.011770602315664291 with total_loss: 0.7633864530362189\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.007603168021887541 with total_loss: 0.7751570553518832\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.00839526578783989 with total_loss: 0.7827602233737707\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.006773345172405243 with total_loss: 0.7911554891616106\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.006928564980626106 with total_loss: 0.7979288343340158\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.008322382345795631 with total_loss: 0.804857399314642\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.007833761163055897 with total_loss: 0.8131797816604376\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.009700995869934559 with total_loss: 0.8210135428234935\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.008259352296590805 with total_loss: 0.830714538693428\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.007172825280576944 with total_loss: 0.8389738909900188\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.006306925322860479 with total_loss: 0.8461467162705958\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.007717350963503122 with total_loss: 0.8524536415934563\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.010082405991852283 with total_loss: 0.8601709925569594\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.00609739450737834 with total_loss: 0.8702533985488117\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.007571701426059008 with total_loss: 0.87635079305619\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.0071556889452040195 with total_loss: 0.883922494482249\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.009326840750873089 with total_loss: 0.891078183427453\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.006684593856334686 with total_loss: 0.9004050241783261\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.005914109293371439 with total_loss: 0.9070896180346608\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.008336598053574562 with total_loss: 0.9130037273280323\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.008534963242709637 with total_loss: 0.9213403253816068\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 17 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.025611350312829018 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.007734960410743952 with total_loss: 0.025611350312829018\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.008033872582018375 with total_loss: 0.03334631072357297\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.007494100835174322 with total_loss: 0.041380183305591345\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.007435137871652842 with total_loss: 0.04887428414076567\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.010220122523605824 with total_loss: 0.05630942201241851\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.011079954914748669 with total_loss: 0.06652954453602433\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.010142077691853046 with total_loss: 0.077609499450773\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.0056096334010362625 with total_loss: 0.08775157714262605\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.00846440065652132 with total_loss: 0.09336121054366231\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.009973038919270039 with total_loss: 0.10182561120018363\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.010198031552135944 with total_loss: 0.11179865011945367\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.010031033307313919 with total_loss: 0.12199668167158961\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.007481306791305542 with total_loss: 0.13202771497890353\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.007013395428657532 with total_loss: 0.13950902177020907\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.007875092327594757 with total_loss: 0.1465224171988666\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.007556976284831762 with total_loss: 0.15439750952646136\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.009662766940891743 with total_loss: 0.16195448581129313\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.008096029050648212 with total_loss: 0.17161725275218487\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.009160398505628109 with total_loss: 0.17971328180283308\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.006336561869829893 with total_loss: 0.1888736803084612\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.006178724113851786 with total_loss: 0.19521024217829108\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.009348669089376926 with total_loss: 0.20138896629214287\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.022620121017098427 with total_loss: 0.2107376353815198\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.00613779341802001 with total_loss: 0.23335775639861822\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.007734993938356638 with total_loss: 0.23949554981663823\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.008995672687888145 with total_loss: 0.24723054375499487\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.009454070590436459 with total_loss: 0.256226216442883\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.006985159125179052 with total_loss: 0.2656802870333195\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.00677350303158164 with total_loss: 0.2726654461584985\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.021102337166666985 with total_loss: 0.27943894919008017\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.010211157612502575 with total_loss: 0.30054128635674715\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.013080798089504242 with total_loss: 0.3107524439692497\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.00981097761541605 with total_loss: 0.32383324205875397\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.010157250799238682 with total_loss: 0.33364421967417\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.009075446985661983 with total_loss: 0.3438014704734087\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.010985252447426319 with total_loss: 0.3528769174590707\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.01297839730978012 with total_loss: 0.363862169906497\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.013355881907045841 with total_loss: 0.3768405672162771\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.02207101322710514 with total_loss: 0.39019644912332296\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.01523541659116745 with total_loss: 0.4122674623504281\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.013247114606201649 with total_loss: 0.42750287894159555\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.008102059364318848 with total_loss: 0.4407499935477972\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.008608747273683548 with total_loss: 0.44885205291211605\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.009058726020157337 with total_loss: 0.4574608001857996\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.016982493922114372 with total_loss: 0.46651952620595694\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.013554617762565613 with total_loss: 0.4835020201280713\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.011594868265092373 with total_loss: 0.4970566378906369\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.010742917656898499 with total_loss: 0.5086515061557293\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.011042122729122639 with total_loss: 0.5193944238126278\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.01494250725954771 with total_loss: 0.5304365465417504\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.010365012101829052 with total_loss: 0.5453790538012981\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.01050631981343031 with total_loss: 0.5557440659031272\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.010906018316745758 with total_loss: 0.5662503857165575\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.010686643421649933 with total_loss: 0.5771564040333033\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.014462294988334179 with total_loss: 0.5878430474549532\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.010115118697285652 with total_loss: 0.6023053424432874\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.01438902784138918 with total_loss: 0.612420461140573\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.014793195761740208 with total_loss: 0.6268094889819622\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.014736086130142212 with total_loss: 0.6416026847437024\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.011152717284858227 with total_loss: 0.6563387708738446\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.010409114882349968 with total_loss: 0.6674914881587029\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.01043951790779829 with total_loss: 0.6779006030410528\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.010556978173553944 with total_loss: 0.6883401209488511\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.0073562744073569775 with total_loss: 0.698897099122405\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.008270076476037502 with total_loss: 0.706253373529762\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.005850841756910086 with total_loss: 0.7145234500057995\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.008149340748786926 with total_loss: 0.7203742917627096\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.006646664347499609 with total_loss: 0.7285236325114965\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.008168903179466724 with total_loss: 0.7351702968589962\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.008472162298858166 with total_loss: 0.7433392000384629\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.007684472948312759 with total_loss: 0.751811362337321\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.0049511766992509365 with total_loss: 0.7594958352856338\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.010429644025862217 with total_loss: 0.7644470119848847\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.006471544969826937 with total_loss: 0.774876656010747\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.008514421992003918 with total_loss: 0.7813482009805739\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.01010244432836771 with total_loss: 0.7898626229725778\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.006295301485806704 with total_loss: 0.7999650673009455\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.009929466061294079 with total_loss: 0.8062603687867522\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.008890296332538128 with total_loss: 0.8161898348480463\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.007145493756979704 with total_loss: 0.8250801311805844\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.0117674320936203 with total_loss: 0.8322256249375641\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.005886884871870279 with total_loss: 0.8439930570311844\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.0069070919416844845 with total_loss: 0.8498799419030547\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.006937103345990181 with total_loss: 0.8567870338447392\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.0069247945211827755 with total_loss: 0.8637241371907294\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.008484472520649433 with total_loss: 0.8706489317119122\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.007290367037057877 with total_loss: 0.8791334042325616\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.008063174784183502 with total_loss: 0.8864237712696195\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.007462451700121164 with total_loss: 0.894486946053803\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.00722971186041832 with total_loss: 0.9019493977539241\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.006968572735786438 with total_loss: 0.9091791096143425\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.007650999817997217 with total_loss: 0.9161476823501289\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.006544501055032015 with total_loss: 0.9237986821681261\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 18 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.007558118551969528 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.008036751300096512 with total_loss: 0.007558118551969528\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.0058952453546226025 with total_loss: 0.01559486985206604\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.007421533111482859 with total_loss: 0.021490115206688643\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.007061478216201067 with total_loss: 0.0289116483181715\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.006554724182933569 with total_loss: 0.03597312653437257\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.00674847699701786 with total_loss: 0.04252785071730614\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.008101541548967361 with total_loss: 0.049276327714324\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.0059544797986745834 with total_loss: 0.05737786926329136\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.00723875081166625 with total_loss: 0.06333234906196594\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.0071897911839187145 with total_loss: 0.07057109987363219\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.007251945789903402 with total_loss: 0.07776089105755091\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.008153867907822132 with total_loss: 0.08501283684745431\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.005260694772005081 with total_loss: 0.09316670475527644\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.006059620063751936 with total_loss: 0.09842739952728152\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.007768075913190842 with total_loss: 0.10448701959103346\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.009758658707141876 with total_loss: 0.1122550955042243\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.006910113152116537 with total_loss: 0.12201375421136618\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.009178346954286098 with total_loss: 0.1289238673634827\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.007566423621028662 with total_loss: 0.1381022143177688\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.005902873817831278 with total_loss: 0.14566863793879747\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.008562873117625713 with total_loss: 0.15157151175662875\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.004335909616202116 with total_loss: 0.16013438487425447\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.008011535741388798 with total_loss: 0.16447029449045658\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.00775822764262557 with total_loss: 0.17248183023184538\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.007625889498740435 with total_loss: 0.18024005787447095\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.007235068827867508 with total_loss: 0.18786594737321138\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.00602822145447135 with total_loss: 0.1951010162010789\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.005738416686654091 with total_loss: 0.20112923765555024\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.0054493192583322525 with total_loss: 0.20686765434220433\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.008438168093562126 with total_loss: 0.21231697360053658\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.011409592814743519 with total_loss: 0.2207551416940987\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.016743846237659454 with total_loss: 0.23216473450884223\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.009182686917483807 with total_loss: 0.24890858074650168\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.013649262487888336 with total_loss: 0.2580912676639855\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.008787405677139759 with total_loss: 0.2717405301518738\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.01090144831687212 with total_loss: 0.2805279358290136\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.013627740554511547 with total_loss: 0.2914293841458857\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.011610276065766811 with total_loss: 0.30505712470039725\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.007210028823465109 with total_loss: 0.31666740076616406\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.012666289694607258 with total_loss: 0.3238774295896292\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.01276750024408102 with total_loss: 0.33654371928423643\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.019683128222823143 with total_loss: 0.34931121952831745\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.011082516051828861 with total_loss: 0.3689943477511406\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.007845907472074032 with total_loss: 0.38007686380296946\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.009302623569965363 with total_loss: 0.3879227712750435\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.007959437556564808 with total_loss: 0.39722539484500885\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.008923523128032684 with total_loss: 0.40518483240157366\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.007400862872600555 with total_loss: 0.41410835552960634\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.008603614754974842 with total_loss: 0.4215092184022069\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.010402507148683071 with total_loss: 0.43011283315718174\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.01046881452202797 with total_loss: 0.4405153403058648\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.009017226286232471 with total_loss: 0.4509841548278928\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.009786033071577549 with total_loss: 0.46000138111412525\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.010445225052535534 with total_loss: 0.4697874141857028\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.009059223346412182 with total_loss: 0.48023263923823833\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.014215310104191303 with total_loss: 0.4892918625846505\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.010768960230052471 with total_loss: 0.5035071726888418\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.016873588785529137 with total_loss: 0.5142761329188943\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.009154937230050564 with total_loss: 0.5311497217044234\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.014579206705093384 with total_loss: 0.540304658934474\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.00826793909072876 with total_loss: 0.5548838656395674\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.011585835367441177 with total_loss: 0.5631518047302961\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.008631032891571522 with total_loss: 0.5747376400977373\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.009732893668115139 with total_loss: 0.5833686729893088\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.010826017707586288 with total_loss: 0.593101566657424\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.006340352352708578 with total_loss: 0.6039275843650103\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.005909770727157593 with total_loss: 0.6102679367177188\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.009666314348578453 with total_loss: 0.6161777074448764\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.008314351551234722 with total_loss: 0.6258440217934549\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.006413383409380913 with total_loss: 0.6341583733446896\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.008038576692342758 with total_loss: 0.6405717567540705\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.006102925166487694 with total_loss: 0.6486103334464133\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.009327078238129616 with total_loss: 0.654713258612901\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.0070156436413526535 with total_loss: 0.6640403368510306\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.005574902053922415 with total_loss: 0.6710559804923832\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.006400352343916893 with total_loss: 0.6766308825463057\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.006371382623910904 with total_loss: 0.6830312348902225\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.006498456466943026 with total_loss: 0.6894026175141335\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.005790459457784891 with total_loss: 0.6959010739810765\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.0073721022345125675 with total_loss: 0.7016915334388614\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.006550030782818794 with total_loss: 0.7090636356733739\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.007903948426246643 with total_loss: 0.7156136664561927\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.006014980375766754 with total_loss: 0.7235176148824394\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.008058310486376286 with total_loss: 0.7295325952582061\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.005291488021612167 with total_loss: 0.7375909057445824\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.006999935954809189 with total_loss: 0.7428823937661946\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.007577985990792513 with total_loss: 0.7498823297210038\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.004612598102539778 with total_loss: 0.7574603157117963\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.005128901917487383 with total_loss: 0.7620729138143361\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.007476795464754105 with total_loss: 0.7672018157318234\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.006540806498378515 with total_loss: 0.7746786111965775\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.009910453110933304 with total_loss: 0.7812194176949561\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.005447820760309696 with total_loss: 0.7911298708058894\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 19 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.007760944310575724 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.007077689748257399 with total_loss: 0.007760944310575724\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.005367273464798927 with total_loss: 0.014838634058833122\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.0072718337178230286 with total_loss: 0.02020590752363205\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.008591384626924992 with total_loss: 0.027477741241455078\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.005786096211522818 with total_loss: 0.03606912586838007\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.008640646934509277 with total_loss: 0.04185522207990289\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.005571444984525442 with total_loss: 0.050495869014412165\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.006762949284166098 with total_loss: 0.05606731399893761\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.00781914684921503 with total_loss: 0.0628302632831037\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.00652192672714591 with total_loss: 0.07064941013231874\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.004889213014394045 with total_loss: 0.07717133685946465\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.007686658296734095 with total_loss: 0.08206054987385869\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.006390098482370377 with total_loss: 0.08974720817059278\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.006114435847848654 with total_loss: 0.09613730665296316\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.010198142379522324 with total_loss: 0.10225174250081182\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.008164221420884132 with total_loss: 0.11244988488033414\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.0066353133879601955 with total_loss: 0.12061410630121827\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.0056685954332351685 with total_loss: 0.12724941968917847\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.007971457205712795 with total_loss: 0.13291801512241364\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.005682012066245079 with total_loss: 0.14088947232812643\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.0065543390810489655 with total_loss: 0.1465714843943715\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.005718243774026632 with total_loss: 0.15312582347542048\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.006886899005621672 with total_loss: 0.1588440672494471\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0069829802960157394 with total_loss: 0.16573096625506878\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.006553536280989647 with total_loss: 0.17271394655108452\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.00562761165201664 with total_loss: 0.17926748283207417\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.0065819076262414455 with total_loss: 0.1848950944840908\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.006553355138748884 with total_loss: 0.19147700211033225\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.008011446334421635 with total_loss: 0.19803035724908113\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.00586579367518425 with total_loss: 0.20604180358350277\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.010127688758075237 with total_loss: 0.21190759725868702\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.01249160896986723 with total_loss: 0.22203528601676226\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.008720780722796917 with total_loss: 0.23452689498662949\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.010374481789767742 with total_loss: 0.2432476757094264\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.0075737969018518925 with total_loss: 0.25362215749919415\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.012410417199134827 with total_loss: 0.26119595440104604\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.015650922432541847 with total_loss: 0.27360637160018086\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.009861280210316181 with total_loss: 0.2892572940327227\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.00725061958655715 with total_loss: 0.2991185742430389\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.007732448633760214 with total_loss: 0.30636919382959604\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.010949328541755676 with total_loss: 0.31410164246335626\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.010686509311199188 with total_loss: 0.32505097100511193\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.012166756205260754 with total_loss: 0.3357374803163111\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.011482718400657177 with total_loss: 0.3479042365215719\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.0074177817441523075 with total_loss: 0.35938695492222905\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.009288058616220951 with total_loss: 0.36680473666638136\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.007252825424075127 with total_loss: 0.3760927952826023\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.007481515873223543 with total_loss: 0.38334562070667744\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.009862980805337429 with total_loss: 0.390827136579901\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.00903425645083189 with total_loss: 0.4006901173852384\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.01921181008219719 with total_loss: 0.4097243738360703\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.008642981760203838 with total_loss: 0.4289361839182675\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.008403540588915348 with total_loss: 0.4375791656784713\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.007786022964864969 with total_loss: 0.4459827062673867\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.009507798589766026 with total_loss: 0.45376872923225164\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.008187049068510532 with total_loss: 0.46327652782201767\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.008039371110498905 with total_loss: 0.4714635768905282\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.007006144151091576 with total_loss: 0.4795029480010271\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.006736373528838158 with total_loss: 0.4865090921521187\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.010468329302966595 with total_loss: 0.49324546568095684\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.008558172732591629 with total_loss: 0.5037137949839234\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.007537738885730505 with total_loss: 0.5122719677165151\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.008248885162174702 with total_loss: 0.5198097066022456\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.006749618332833052 with total_loss: 0.5280585917644203\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.007444481831043959 with total_loss: 0.5348082100972533\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.008666403591632843 with total_loss: 0.5422526919282973\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.005342651158571243 with total_loss: 0.5509190955199301\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.007918959483504295 with total_loss: 0.5562617466785014\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.0077234492637217045 with total_loss: 0.5641807061620057\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.007555596996098757 with total_loss: 0.5719041554257274\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.008454074151813984 with total_loss: 0.5794597524218261\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.005964161362498999 with total_loss: 0.5879138265736401\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.006870876997709274 with total_loss: 0.5938779879361391\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.006028363946825266 with total_loss: 0.6007488649338484\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.007663835305720568 with total_loss: 0.6067772288806736\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.007836680859327316 with total_loss: 0.6144410641863942\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.006440530996769667 with total_loss: 0.6222777450457215\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.006310413125902414 with total_loss: 0.6287182760424912\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.006283685099333525 with total_loss: 0.6350286891683936\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.007746016141027212 with total_loss: 0.6413123742677271\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.008823872543871403 with total_loss: 0.6490583904087543\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.007382331416010857 with total_loss: 0.6578822629526258\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.00743073271587491 with total_loss: 0.6652645943686366\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.005762333050370216 with total_loss: 0.6726953270845115\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.0067430161871016026 with total_loss: 0.6784576601348817\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.008040166459977627 with total_loss: 0.6852006763219833\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.008968643844127655 with total_loss: 0.693240842781961\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.01217168290168047 with total_loss: 0.7022094866260886\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.006979312747716904 with total_loss: 0.7143811695277691\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.006098788231611252 with total_loss: 0.721360482275486\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.0072223409079015255 with total_loss: 0.7274592705070972\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.007281800266355276 with total_loss: 0.7346816114149988\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.005604281090199947 with total_loss: 0.741963411681354\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 20 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.006783708930015564 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.00774986669421196 with total_loss: 0.006783708930015564\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.007170254364609718 with total_loss: 0.014533575624227524\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.007135758642107248 with total_loss: 0.021703829988837242\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.006275604013353586 with total_loss: 0.02883958863094449\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.004399659112095833 with total_loss: 0.03511519264429808\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.005408331751823425 with total_loss: 0.03951485175639391\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.006358180195093155 with total_loss: 0.044923183508217335\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.006695270538330078 with total_loss: 0.05128136370331049\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0075191352516412735 with total_loss: 0.05797663424164057\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.007652852218598127 with total_loss: 0.06549576949328184\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.006575886160135269 with total_loss: 0.07314862171187997\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.006874377373605967 with total_loss: 0.07972450787201524\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0063531119376420975 with total_loss: 0.0865988852456212\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.004809874575585127 with total_loss: 0.0929519971832633\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.0059597729705274105 with total_loss: 0.09776187175884843\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.006460115313529968 with total_loss: 0.10372164472937584\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.009328766725957394 with total_loss: 0.11018176004290581\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.0062515935860574245 with total_loss: 0.1195105267688632\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.00823789183050394 with total_loss: 0.12576212035492063\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.004583796951919794 with total_loss: 0.13400001218542457\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.008140325546264648 with total_loss: 0.13858380913734436\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.009194613434374332 with total_loss: 0.146724134683609\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.006816548760980368 with total_loss: 0.15591874811798334\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.005905075464397669 with total_loss: 0.1627352968789637\n",
      "  Batch    25  of     94.    Elapsed: 0:00:00. with Loss: 0.0053356364369392395 with total_loss: 0.16864037234336138\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.006140002980828285 with total_loss: 0.17397600878030062\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.007758772000670433 with total_loss: 0.1801160117611289\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.006959656253457069 with total_loss: 0.18787478376179934\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.005043016280978918 with total_loss: 0.1948344400152564\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.006662214640527964 with total_loss: 0.19987745629623532\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.008899014443159103 with total_loss: 0.2065396709367633\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.019312715157866478 with total_loss: 0.2154386853799224\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.009800407104194164 with total_loss: 0.23475140053778887\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.011303573846817017 with total_loss: 0.24455180764198303\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.009813708253204823 with total_loss: 0.25585538148880005\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.019109321758151054 with total_loss: 0.26566908974200487\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.009658378548920155 with total_loss: 0.2847784115001559\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.007958569563925266 with total_loss: 0.2944367900490761\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.00787888839840889 with total_loss: 0.30239535961300135\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.026058239862322807 with total_loss: 0.31027424801141024\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.007575098425149918 with total_loss: 0.33633248787373304\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.008702784776687622 with total_loss: 0.34390758629888296\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.01153187919408083 with total_loss: 0.3526103710755706\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.008692343719303608 with total_loss: 0.3641422502696514\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.010819632560014725 with total_loss: 0.372834593988955\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.006881148088723421 with total_loss: 0.38365422654896975\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.006696921307593584 with total_loss: 0.39053537463769317\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.006901256740093231 with total_loss: 0.39723229594528675\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.007546826731413603 with total_loss: 0.40413355268538\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.00660641910508275 with total_loss: 0.4116803794167936\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.007024344522505999 with total_loss: 0.41828679852187634\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.01239809114485979 with total_loss: 0.42531114304438233\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.005398010369390249 with total_loss: 0.4377092341892421\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.007993743754923344 with total_loss: 0.4431072445586324\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.02309921383857727 with total_loss: 0.4511009883135557\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.009289994835853577 with total_loss: 0.474200202152133\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.007299311459064484 with total_loss: 0.48349019698798656\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.00685110641643405 with total_loss: 0.49078950844705105\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.00908739771693945 with total_loss: 0.4976406148634851\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.006751885171979666 with total_loss: 0.5067280125804245\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.0114971324801445 with total_loss: 0.5134798977524042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.011743664741516113 with total_loss: 0.5249770302325487\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.006666472647339106 with total_loss: 0.5367206949740648\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.0071275378577411175 with total_loss: 0.5433871676214039\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.00786497164517641 with total_loss: 0.550514705479145\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.004991308785974979 with total_loss: 0.5583796771243215\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.004555809777230024 with total_loss: 0.5633709859102964\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.00794840045273304 with total_loss: 0.5679267956875265\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.006160980090498924 with total_loss: 0.5758751961402595\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.006918972358107567 with total_loss: 0.5820361762307584\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.008245320059359074 with total_loss: 0.588955148588866\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.008212736807763577 with total_loss: 0.5972004686482251\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.006048021372407675 with total_loss: 0.6054132054559886\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.0065189204178750515 with total_loss: 0.6114612268283963\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.005867911968380213 with total_loss: 0.6179801472462714\n",
      "  Batch    76  of     94.    Elapsed: 0:00:01. with Loss: 0.006679376121610403 with total_loss: 0.6238480592146516\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.0051511735655367374 with total_loss: 0.630527435336262\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.0061754994094371796 with total_loss: 0.6356786089017987\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.006083443760871887 with total_loss: 0.6418541083112359\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.006886763032525778 with total_loss: 0.6479375520721078\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.006720576900988817 with total_loss: 0.6548243151046336\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.0061622983776032925 with total_loss: 0.6615448920056224\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.005123622715473175 with total_loss: 0.6677071903832257\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.005651960149407387 with total_loss: 0.6728308130986989\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.009546189568936825 with total_loss: 0.6784827732481062\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.007643088232725859 with total_loss: 0.6880289628170431\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.004450896289199591 with total_loss: 0.6956720510497689\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.0058986530639231205 with total_loss: 0.7001229473389685\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.004395787138491869 with total_loss: 0.7060216004028916\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.006841587368398905 with total_loss: 0.7104173875413835\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.005021783988922834 with total_loss: 0.7172589749097824\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.0068595693446695805 with total_loss: 0.7222807588987052\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.006061080377548933 with total_loss: 0.7291403282433748\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 21 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.0056810700334608555 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.008915260434150696 with total_loss: 0.0056810700334608555\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.005839365068823099 with total_loss: 0.014596330467611551\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.006665527354925871 with total_loss: 0.02043569553643465\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.0061135976575315 with total_loss: 0.02710122289136052\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.005824057385325432 with total_loss: 0.03321482054889202\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.00707239517942071 with total_loss: 0.03903887793421745\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.00596444308757782 with total_loss: 0.04611127311363816\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.005195177160203457 with total_loss: 0.05207571620121598\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.00655359448865056 with total_loss: 0.05727089336141944\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.005751807242631912 with total_loss: 0.06382448785007\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.006432486232370138 with total_loss: 0.06957629509270191\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.008382153697311878 with total_loss: 0.07600878132507205\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.005577935371547937 with total_loss: 0.08439093502238393\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.007346007972955704 with total_loss: 0.08996887039393187\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.008712773211300373 with total_loss: 0.09731487836688757\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.006033471319824457 with total_loss: 0.10602765157818794\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.010386880487203598 with total_loss: 0.1120611228980124\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.00500743230804801 with total_loss: 0.122448003385216\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.006482233759015799 with total_loss: 0.127455435693264\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.006287938449531794 with total_loss: 0.1339376694522798\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.005299183074384928 with total_loss: 0.1402256079018116\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.004852143581956625 with total_loss: 0.14552479097619653\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.01106763631105423 with total_loss: 0.15037693455815315\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.005446332972496748 with total_loss: 0.16144457086920738\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.007011190056800842 with total_loss: 0.16689090384170413\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.006647883448749781 with total_loss: 0.17390209389850497\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.0055917478166520596 with total_loss: 0.18054997734725475\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.007631709799170494 with total_loss: 0.1861417251639068\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.004970013629645109 with total_loss: 0.1937734349630773\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.010922473855316639 with total_loss: 0.19874344859272242\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.013187789358198643 with total_loss: 0.20966592244803905\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.012754674069583416 with total_loss: 0.2228537118062377\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.006723705213516951 with total_loss: 0.2356083858758211\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.0069748759269714355 with total_loss: 0.24233209108933806\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.007988542318344116 with total_loss: 0.2493069670163095\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.017626551911234856 with total_loss: 0.2572955093346536\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.009610500186681747 with total_loss: 0.27492206124588847\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.008156095631420612 with total_loss: 0.2845325614325702\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.0070490301586687565 with total_loss: 0.29268865706399083\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.01585732400417328 with total_loss: 0.2997376872226596\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.008378629572689533 with total_loss: 0.31559501122683287\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.007478015031665564 with total_loss: 0.3239736407995224\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.00921069085597992 with total_loss: 0.33145165583118796\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.008684221655130386 with total_loss: 0.3406623466871679\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.009884797967970371 with total_loss: 0.34934656834229827\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.012944977730512619 with total_loss: 0.35923136631026864\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.007082939147949219 with total_loss: 0.37217634404078126\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.005727261304855347 with total_loss: 0.3792592831887305\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.007587514817714691 with total_loss: 0.3849865444935858\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.011731733568012714 with total_loss: 0.3925740593113005\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.00659954734146595 with total_loss: 0.40430579287931323\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.00595086207613349 with total_loss: 0.4109053402207792\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.00862076785415411 with total_loss: 0.41685620229691267\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.010763521306216717 with total_loss: 0.4254769701510668\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.007096188608556986 with total_loss: 0.4362404914572835\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.008593798615038395 with total_loss: 0.4433366800658405\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.015192474238574505 with total_loss: 0.4519304786808789\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.009741638787090778 with total_loss: 0.4671229529194534\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.006512841675430536 with total_loss: 0.47686459170654416\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.00694831321015954 with total_loss: 0.4833774333819747\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.006596991326659918 with total_loss: 0.49032574659213424\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.010329321958124638 with total_loss: 0.49692273791879416\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.009281006641685963 with total_loss: 0.5072520598769188\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.00923151709139347 with total_loss: 0.5165330665186048\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.0074232579208910465 with total_loss: 0.5257645836099982\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.006516038905829191 with total_loss: 0.5331878415308893\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.008422710932791233 with total_loss: 0.5397038804367185\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.00852164439857006 with total_loss: 0.5481265913695097\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.005989627446979284 with total_loss: 0.5566482357680798\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.007584935519844294 with total_loss: 0.562637863215059\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.005943031515926123 with total_loss: 0.5702227987349033\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.007194967474788427 with total_loss: 0.5761658302508295\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.004328418057411909 with total_loss: 0.5833607977256179\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.0056502558290958405 with total_loss: 0.5876892157830298\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.008751019835472107 with total_loss: 0.5933394716121256\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.007498322520405054 with total_loss: 0.6020904914475977\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.005981027614325285 with total_loss: 0.6095888139680028\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.047531139105558395 with total_loss: 0.6155698415823281\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.0067100804299116135 with total_loss: 0.6631009806878865\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.005901093129068613 with total_loss: 0.6698110611177981\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.007761020213365555 with total_loss: 0.6757121542468667\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.008260157890617847 with total_loss: 0.6834731744602323\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.005347276572138071 with total_loss: 0.6917333323508501\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.004948165267705917 with total_loss: 0.6970806089229882\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.00928950123488903 with total_loss: 0.7020287741906941\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.007560316473245621 with total_loss: 0.7113182754255831\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.00845223106443882 with total_loss: 0.7188785918988287\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.005655545741319656 with total_loss: 0.7273308229632676\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.012389418669044971 with total_loss: 0.7329863687045872\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.007023323327302933 with total_loss: 0.7453757873736322\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.033107366412878036 with total_loss: 0.7523991107009351\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.010344141162931919 with total_loss: 0.7855064771138132\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.005716560874134302 with total_loss: 0.7958506182767451\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 22 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.10458240658044815 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.006792312487959862 with total_loss: 0.10458240658044815\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.005184403154999018 with total_loss: 0.11137471906840801\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.007268690969794989 with total_loss: 0.11655912222340703\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.006955750286579132 with total_loss: 0.12382781319320202\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.0058922735042870045 with total_loss: 0.13078356347978115\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.006054876837879419 with total_loss: 0.13667583698406816\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.007399024907499552 with total_loss: 0.14273071382194757\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.006601307541131973 with total_loss: 0.15012973872944713\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0066357864998281 with total_loss: 0.1567310462705791\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.008981701917946339 with total_loss: 0.1633668327704072\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.010598008520901203 with total_loss: 0.17234853468835354\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.0064287688583135605 with total_loss: 0.18294654320925474\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.007169206161051989 with total_loss: 0.1893753120675683\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.007107736077159643 with total_loss: 0.1965445182286203\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.006652535405009985 with total_loss: 0.20365225430577993\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.006440300494432449 with total_loss: 0.21030478971078992\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.005477807018905878 with total_loss: 0.21674509020522237\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.007174485828727484 with total_loss: 0.22222289722412825\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.005185805261135101 with total_loss: 0.22939738305285573\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.006139600649476051 with total_loss: 0.23458318831399083\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.006547789555042982 with total_loss: 0.24072278896346688\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.005292283836752176 with total_loss: 0.24727057851850986\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.0057908655144274235 with total_loss: 0.25256286235526204\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0067894491367042065 with total_loss: 0.25835372786968946\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.006688479799777269 with total_loss: 0.26514317700639367\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.00924836378544569 with total_loss: 0.27183165680617094\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.005665717180818319 with total_loss: 0.28108002059161663\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.00535714952275157 with total_loss: 0.28674573777243495\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.011359279043972492 with total_loss: 0.2921028872951865\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.008831948041915894 with total_loss: 0.303462166339159\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.009312618523836136 with total_loss: 0.3122941143810749\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.008583800867199898 with total_loss: 0.32160673290491104\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.008554971776902676 with total_loss: 0.33019053377211094\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.012292306870222092 with total_loss: 0.3387455055490136\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.008649833500385284 with total_loss: 0.3510378124192357\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.009088433347642422 with total_loss: 0.359687645919621\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.03949715569615364 with total_loss: 0.3687760792672634\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.013602801598608494 with total_loss: 0.40827323496341705\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.009426768869161606 with total_loss: 0.42187603656202555\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.01047303806990385 with total_loss: 0.43130280543118715\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.00828161183744669 with total_loss: 0.441775843501091\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.012145273387432098 with total_loss: 0.4500574553385377\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.02511647343635559 with total_loss: 0.4622027287259698\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.007168940734118223 with total_loss: 0.4873192021623254\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.008687465451657772 with total_loss: 0.4944881428964436\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.012239232659339905 with total_loss: 0.5031756083481014\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.007675669621676207 with total_loss: 0.5154148410074413\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.00699220085516572 with total_loss: 0.5230905106291175\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.009190523996949196 with total_loss: 0.5300827114842832\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.009640787728130817 with total_loss: 0.5392732354812324\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.008598855696618557 with total_loss: 0.5489140232093632\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.006468384992331266 with total_loss: 0.5575128789059818\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.0074225240387022495 with total_loss: 0.563981263898313\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.008613910526037216 with total_loss: 0.5714037879370153\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.006328053306788206 with total_loss: 0.5800176984630525\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.0071545932441949844 with total_loss: 0.5863457517698407\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.010182938538491726 with total_loss: 0.5935003450140357\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.007555122021585703 with total_loss: 0.6036832835525274\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.008831475861370564 with total_loss: 0.6112384055741131\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.008530854247510433 with total_loss: 0.6200698814354837\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.008374299854040146 with total_loss: 0.6286007356829941\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.008215553127229214 with total_loss: 0.6369750355370343\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.009006043896079063 with total_loss: 0.6451905886642635\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.012638580985367298 with total_loss: 0.6541966325603426\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.005847549065947533 with total_loss: 0.6668352135457098\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.00528314895927906 with total_loss: 0.6726827626116574\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.01095960196107626 with total_loss: 0.6779659115709364\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.030277594923973083 with total_loss: 0.6889255135320127\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.08169829100370407 with total_loss: 0.7192031084559858\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.007206516806036234 with total_loss: 0.8009013994596899\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.006696442607790232 with total_loss: 0.8081079162657261\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.0063385614193975925 with total_loss: 0.8148043588735163\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.008903171867132187 with total_loss: 0.8211429202929139\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.005696986336261034 with total_loss: 0.8300460921600461\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.006355368997901678 with total_loss: 0.8357430784963071\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.007346344646066427 with total_loss: 0.8420984474942088\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.008271940983831882 with total_loss: 0.8494447921402752\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.005770216230303049 with total_loss: 0.8577167331241071\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.0061517804861068726 with total_loss: 0.8634869493544102\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.004173427354544401 with total_loss: 0.869638729840517\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.008471823297441006 with total_loss: 0.8738121571950614\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.006281367968767881 with total_loss: 0.8822839804925025\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.009113107807934284 with total_loss: 0.8885653484612703\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.007241131272166967 with total_loss: 0.8976784562692046\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.008508470840752125 with total_loss: 0.9049195875413716\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.007890221662819386 with total_loss: 0.9134280583821237\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.006415965501219034 with total_loss: 0.9213182800449431\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.005286359693855047 with total_loss: 0.9277342455461621\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.00645669549703598 with total_loss: 0.9330206052400172\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.005298288073390722 with total_loss: 0.9394773007370532\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.0046426900662481785 with total_loss: 0.9447755888104439\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.005643188487738371 with total_loss: 0.9494182788766921\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.005426941439509392 with total_loss: 0.9550614673644304\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 23 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.008369156159460545 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.004178574774414301 with total_loss: 0.008369156159460545\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.005670525599271059 with total_loss: 0.012547730933874846\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.003450351068750024 with total_loss: 0.018218256533145905\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.005050766747444868 with total_loss: 0.02166860760189593\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.0057309456169605255 with total_loss: 0.026719374349340796\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.0058097937144339085 with total_loss: 0.03245031996630132\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.005389256868511438 with total_loss: 0.03826011368073523\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.00657656928524375 with total_loss: 0.04364937054924667\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0054499139077961445 with total_loss: 0.05022593983449042\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.005110831465572119 with total_loss: 0.05567585374228656\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.008365419693291187 with total_loss: 0.06078668520785868\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.007313277572393417 with total_loss: 0.06915210490114987\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0070619466714560986 with total_loss: 0.07646538247354329\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.005231168586760759 with total_loss: 0.08352732914499938\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.0068933540023863316 with total_loss: 0.08875849773176014\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.006683280225843191 with total_loss: 0.09565185173414648\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.006400486920028925 with total_loss: 0.10233513195998967\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.006536839064210653 with total_loss: 0.10873561888001859\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.0053111836314201355 with total_loss: 0.11527245794422925\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.005807493347674608 with total_loss: 0.12058364157564938\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.010920371860265732 with total_loss: 0.126391134923324\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.006930144038051367 with total_loss: 0.13731150678358972\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.007788509130477905 with total_loss: 0.1442416508216411\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0071449726819992065 with total_loss: 0.152030159952119\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.005204111337661743 with total_loss: 0.1591751326341182\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.00607362762093544 with total_loss: 0.16437924397177994\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.006036757025867701 with total_loss: 0.17045287159271538\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.028074825182557106 with total_loss: 0.17648962861858308\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.006138320546597242 with total_loss: 0.2045644538011402\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.005556183401495218 with total_loss: 0.21070277434773743\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.007256871555000544 with total_loss: 0.21625895774923265\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.009104962460696697 with total_loss: 0.2235158293042332\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.0071859657764434814 with total_loss: 0.2326207917649299\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.006145754363387823 with total_loss: 0.23980675754137337\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.007315676659345627 with total_loss: 0.2459525119047612\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.011231268756091595 with total_loss: 0.2532681885641068\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.008348379284143448 with total_loss: 0.2644994573201984\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.0061950949020683765 with total_loss: 0.27284783660434186\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.005678357556462288 with total_loss: 0.27904293150641024\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.011515538208186626 with total_loss: 0.28472128906287253\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.005807865876704454 with total_loss: 0.29623682727105916\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.00616408372297883 with total_loss: 0.3020446931477636\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.006786874029785395 with total_loss: 0.30820877687074244\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.008321580477058887 with total_loss: 0.31499565090052783\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.0037912745028734207 with total_loss: 0.3233172313775867\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.00659571960568428 with total_loss: 0.32710850588046014\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.008086401037871838 with total_loss: 0.3337042254861444\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.005041785072535276 with total_loss: 0.34179062652401626\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.007364032324403524 with total_loss: 0.34683241159655154\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.006567238364368677 with total_loss: 0.35419644392095506\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.007697633001953363 with total_loss: 0.36076368228532374\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.007448951248079538 with total_loss: 0.3684613152872771\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.0060815061442554 with total_loss: 0.37591026653535664\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.008204372599720955 with total_loss: 0.38199177267961204\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.006923360284417868 with total_loss: 0.390196145279333\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.005204071756452322 with total_loss: 0.39711950556375086\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.006533305626362562 with total_loss: 0.4023235773202032\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.006299590226262808 with total_loss: 0.40885688294656575\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.011514633893966675 with total_loss: 0.41515647317282856\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.007383084390312433 with total_loss: 0.42667110706679523\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.006750080734491348 with total_loss: 0.43405419145710766\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.006745962426066399 with total_loss: 0.440804272191599\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.004038380924612284 with total_loss: 0.4475502346176654\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.0076682991348207 with total_loss: 0.4515886155422777\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.005314058158546686 with total_loss: 0.4592569146770984\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.0038749054074287415 with total_loss: 0.4645709728356451\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.005618640687316656 with total_loss: 0.4684458782430738\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.005794791039079428 with total_loss: 0.4740645189303905\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.0069317989982664585 with total_loss: 0.4798593099694699\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.006685785949230194 with total_loss: 0.48679110896773636\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.0045186304487288 with total_loss: 0.49347689491696656\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.004451700020581484 with total_loss: 0.49799552536569536\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.007580699864774942 with total_loss: 0.5024472253862768\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.005406124051660299 with total_loss: 0.5100279252510518\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.0065062460489571095 with total_loss: 0.5154340493027121\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.005532992538064718 with total_loss: 0.5219402953516692\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.006241858005523682 with total_loss: 0.5274732878897339\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.008645249530673027 with total_loss: 0.5337151458952576\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.00733094522729516 with total_loss: 0.5423603954259306\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.008854862302541733 with total_loss: 0.5496913406532258\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.006438909564167261 with total_loss: 0.5585462029557675\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.008624094538390636 with total_loss: 0.5649851125199348\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.006473851855844259 with total_loss: 0.5736092070583254\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.006172893103212118 with total_loss: 0.5800830589141697\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.007176047656685114 with total_loss: 0.5862559520173818\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.006049467716366053 with total_loss: 0.5934319996740669\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.004841609857976437 with total_loss: 0.599481467390433\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.006950305309146643 with total_loss: 0.6043230772484094\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.006074863951653242 with total_loss: 0.611273382557556\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.004556789994239807 with total_loss: 0.6173482465092093\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.006383026018738747 with total_loss: 0.6219050365034491\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.00462179584428668 with total_loss: 0.6282880625221878\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.005228870548307896 with total_loss: 0.6329098583664745\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 24 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.00499745924025774 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.05428503453731537 with total_loss: 0.00499745924025774\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.004816920962184668 with total_loss: 0.05928249377757311\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.005368437618017197 with total_loss: 0.06409941473975778\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.005597355309873819 with total_loss: 0.06946785235777497\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.00624098489060998 with total_loss: 0.07506520766764879\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.005954263266175985 with total_loss: 0.08130619255825877\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.0065438412129879 with total_loss: 0.08726045582443476\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.004814980085939169 with total_loss: 0.09380429703742266\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.00478002754971385 with total_loss: 0.09861927712336183\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.0052430760115385056 with total_loss: 0.10339930467307568\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.007092745508998632 with total_loss: 0.10864238068461418\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.005702698137611151 with total_loss: 0.11573512619361281\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0065805562771856785 with total_loss: 0.12143782433122396\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.00551082706078887 with total_loss: 0.12801838060840964\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.007586391177028418 with total_loss: 0.1335292076691985\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.006653903517872095 with total_loss: 0.14111559884622693\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.0055520012974739075 with total_loss: 0.14776950236409903\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.004915629047900438 with total_loss: 0.15332150366157293\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.005590788554400206 with total_loss: 0.15823713270947337\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.0033785859122872353 with total_loss: 0.16382792126387358\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.00681484816595912 with total_loss: 0.1672065071761608\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.005026930943131447 with total_loss: 0.17402135534211993\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.005142534617334604 with total_loss: 0.17904828628525138\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.005816781893372536 with total_loss: 0.18419082090258598\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.005541703198105097 with total_loss: 0.19000760279595852\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.00637131929397583 with total_loss: 0.19554930599406362\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.005769402254372835 with total_loss: 0.20192062528803945\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.007984191179275513 with total_loss: 0.20769002754241228\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.00679809832945466 with total_loss: 0.2156742187216878\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.0067525156773626804 with total_loss: 0.22247231705114245\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.009078131057322025 with total_loss: 0.22922483272850513\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.008376792073249817 with total_loss: 0.23830296378582716\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.004832108970731497 with total_loss: 0.24667975585907698\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.005549716297537088 with total_loss: 0.2515118648298085\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.0073518515564501286 with total_loss: 0.25706158112734556\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.043583065271377563 with total_loss: 0.2644134326837957\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.0095252376049757 with total_loss: 0.30799649795517325\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.008118223398923874 with total_loss: 0.31752173556014895\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.014688308350741863 with total_loss: 0.32563995895907283\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.007344547193497419 with total_loss: 0.3403282673098147\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.004673265386372805 with total_loss: 0.3476728145033121\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.00662160525098443 with total_loss: 0.3523460798896849\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.0063705132342875 with total_loss: 0.35896768514066935\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.007627146318554878 with total_loss: 0.36533819837495685\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.00584633881226182 with total_loss: 0.3729653446935117\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.007151570171117783 with total_loss: 0.37881168350577354\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.004662490915507078 with total_loss: 0.3859632536768913\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.00945133063942194 with total_loss: 0.3906257445923984\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.007405780255794525 with total_loss: 0.40007707523182034\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.005063924472779036 with total_loss: 0.40748285548761487\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.004767978098243475 with total_loss: 0.4125467799603939\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.00628417544066906 with total_loss: 0.4173147580586374\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.005708660464733839 with total_loss: 0.42359893349930644\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.005849858280271292 with total_loss: 0.4293075939640403\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.00509822741150856 with total_loss: 0.43515745224431157\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.006729921791702509 with total_loss: 0.44025567965582013\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.005512839183211327 with total_loss: 0.44698560144752264\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.007139042019844055 with total_loss: 0.45249844063073397\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.004786220844835043 with total_loss: 0.459637482650578\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.007427578791975975 with total_loss: 0.46442370349541306\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.022225821390748024 with total_loss: 0.47185128228738904\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.007739173248410225 with total_loss: 0.49407710367813706\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.008726793341338634 with total_loss: 0.5018162769265473\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.006529336795210838 with total_loss: 0.5105430702678859\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.007045072969049215 with total_loss: 0.5170724070630968\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.005387498531490564 with total_loss: 0.524117480032146\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.005955246742814779 with total_loss: 0.5295049785636365\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.0068515934981405735 with total_loss: 0.5354602253064513\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.006142307072877884 with total_loss: 0.5423118188045919\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.006420116871595383 with total_loss: 0.5484541258774698\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.004615596029907465 with total_loss: 0.5548742427490652\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.005669538397341967 with total_loss: 0.5594898387789726\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.005504237022250891 with total_loss: 0.5651593771763146\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.00736111169680953 with total_loss: 0.5706636141985655\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.004983162507414818 with total_loss: 0.578024725895375\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.005893402267247438 with total_loss: 0.5830078884027898\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.006130510941147804 with total_loss: 0.5889012906700373\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.006238877307623625 with total_loss: 0.5950318016111851\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.006500215735286474 with total_loss: 0.6012706789188087\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.0064865779131650925 with total_loss: 0.6077708946540952\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.006452392786741257 with total_loss: 0.6142574725672603\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.005484031047672033 with total_loss: 0.6207098653540015\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.004199275281280279 with total_loss: 0.6261938964016736\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.005659198854118586 with total_loss: 0.6303931716829538\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.006313254591077566 with total_loss: 0.6360523705370724\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.005255008582025766 with total_loss: 0.64236562512815\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.00657653296366334 with total_loss: 0.6476206337101758\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.005066853016614914 with total_loss: 0.6541971666738391\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.0046844701282680035 with total_loss: 0.659264019690454\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.004965375643223524 with total_loss: 0.663948489818722\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.00485666049644351 with total_loss: 0.6689138654619455\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.005447113420814276 with total_loss: 0.673770525958389\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.006155090406537056 with total_loss: 0.6792176393792033\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 25 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.005764163564890623 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.0045460425317287445 with total_loss: 0.005764163564890623\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.005273131188005209 with total_loss: 0.010310206096619368\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.005230935290455818 with total_loss: 0.015583337284624577\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.007177809718996286 with total_loss: 0.020814272575080395\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.005014113616198301 with total_loss: 0.02799208229407668\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.004770152736455202 with total_loss: 0.03300619591027498\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.005801893770694733 with total_loss: 0.037776348646730185\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.0043679107911884785 with total_loss: 0.04357824241742492\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.006822049617767334 with total_loss: 0.047946153208613396\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.004215884488075972 with total_loss: 0.05476820282638073\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.006000960245728493 with total_loss: 0.0589840873144567\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.006184620317071676 with total_loss: 0.0649850475601852\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.004750843625515699 with total_loss: 0.07116966787725687\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.005288187880069017 with total_loss: 0.07592051150277257\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.004790015984326601 with total_loss: 0.08120869938284159\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.004983408842235804 with total_loss: 0.08599871536716819\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.004432010930031538 with total_loss: 0.09098212420940399\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.006265316158533096 with total_loss: 0.09541413513943553\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.006635596975684166 with total_loss: 0.10167945129796863\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.005987841635942459 with total_loss: 0.10831504827365279\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.004505956545472145 with total_loss: 0.11430288990959525\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.004362883046269417 with total_loss: 0.1188088464550674\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.01019977405667305 with total_loss: 0.12317172950133681\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.004521636757999659 with total_loss: 0.13337150355800986\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.004512457642704248 with total_loss: 0.13789314031600952\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.005330685991793871 with total_loss: 0.14240559795871377\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.00777016207575798 with total_loss: 0.14773628395050764\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.00481146527454257 with total_loss: 0.15550644602626562\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.005344230681657791 with total_loss: 0.1603179113008082\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.0051218862645328045 with total_loss: 0.16566214198246598\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.008457311429083347 with total_loss: 0.1707840282469988\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.007861082442104816 with total_loss: 0.17924133967608213\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.006109734531491995 with total_loss: 0.18710242211818695\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.00550325820222497 with total_loss: 0.19321215664967895\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.0058047156780958176 with total_loss: 0.19871541485190392\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.0056610796600580215 with total_loss: 0.20452013052999973\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.00689068203791976 with total_loss: 0.21018121019005775\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.007005537394434214 with total_loss: 0.21707189222797751\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.008137427270412445 with total_loss: 0.22407742962241173\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.007767388131469488 with total_loss: 0.23221485689282417\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.0066691613756120205 with total_loss: 0.23998224502429366\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.00558312376961112 with total_loss: 0.24665140639990568\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.005679770838469267 with total_loss: 0.2522345301695168\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.006082010921090841 with total_loss: 0.25791430100798607\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.005217421799898148 with total_loss: 0.2639963119290769\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.0063657984137535095 with total_loss: 0.26921373372897506\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.007896870374679565 with total_loss: 0.27557953214272857\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.00509535102173686 with total_loss: 0.28347640251740813\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.007359845098108053 with total_loss: 0.288571753539145\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.007186111528426409 with total_loss: 0.29593159863725305\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.007645839359611273 with total_loss: 0.30311771016567945\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.005749373231083155 with total_loss: 0.3107635495252907\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.019331635907292366 with total_loss: 0.3165129227563739\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.005153816659003496 with total_loss: 0.33584455866366625\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.007155189756304026 with total_loss: 0.34099837532266974\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.005847638938575983 with total_loss: 0.34815356507897377\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.005508605390787125 with total_loss: 0.35400120401754975\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.005146319977939129 with total_loss: 0.3595098094083369\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.00623677670955658 with total_loss: 0.364656129386276\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.006339605897665024 with total_loss: 0.3708929060958326\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.006403892766684294 with total_loss: 0.3772325119934976\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.005950869992375374 with total_loss: 0.3836364047601819\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.007233964744955301 with total_loss: 0.3895872747525573\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.00597452512010932 with total_loss: 0.3968212394975126\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.004282018635421991 with total_loss: 0.4027957646176219\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.005860795732587576 with total_loss: 0.4070777832530439\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.0065162330865859985 with total_loss: 0.41293857898563147\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.00752704543992877 with total_loss: 0.41945481207221746\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.006856007967144251 with total_loss: 0.42698185751214623\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.006539460271596909 with total_loss: 0.4338378654792905\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.00651869410648942 with total_loss: 0.4403773257508874\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.005256996024399996 with total_loss: 0.4468960198573768\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.008117744699120522 with total_loss: 0.4521530158817768\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.005939139518886805 with total_loss: 0.46027076058089733\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.004800508264452219 with total_loss: 0.46620990009978414\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.00519126420840621 with total_loss: 0.47101040836423635\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.0054409378208220005 with total_loss: 0.47620167257264256\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.00554819917306304 with total_loss: 0.48164261039346457\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.004561752546578646 with total_loss: 0.4871908095665276\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.005762022454291582 with total_loss: 0.49175256211310625\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.0051204971969127655 with total_loss: 0.49751458456739783\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.01727362535893917 with total_loss: 0.5026350817643106\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.006997241172939539 with total_loss: 0.5199087071232498\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.004141275305300951 with total_loss: 0.5269059482961893\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.005324048455804586 with total_loss: 0.5310472236014903\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.003415496787056327 with total_loss: 0.5363712720572948\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.0042735617607831955 with total_loss: 0.5397867688443512\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.004895092453807592 with total_loss: 0.5440603306051344\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.007881632074713707 with total_loss: 0.548955423058942\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.004832878243178129 with total_loss: 0.5568370551336557\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.005393055733293295 with total_loss: 0.5616699333768338\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.0045242090709507465 with total_loss: 0.5670629891101271\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.005816992372274399 with total_loss: 0.5715871981810778\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 26 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.05954676866531372 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.006274899933487177 with total_loss: 0.05954676866531372\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.004525752272456884 with total_loss: 0.0658216685988009\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.007370065897703171 with total_loss: 0.07034742087125778\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.006333292927592993 with total_loss: 0.07771748676896095\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.006170513574033976 with total_loss: 0.08405077969655395\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.006241193041205406 with total_loss: 0.09022129327058792\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.005622550845146179 with total_loss: 0.09646248631179333\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.004976265598088503 with total_loss: 0.1020850371569395\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0049819485284388065 with total_loss: 0.10706130275502801\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.004501115530729294 with total_loss: 0.11204325128346682\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.005423229653388262 with total_loss: 0.11654436681419611\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.005287304986268282 with total_loss: 0.12196759646758437\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.004694774281233549 with total_loss: 0.12725490145385265\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.005145846400409937 with total_loss: 0.1319496757350862\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.006740882992744446 with total_loss: 0.13709552213549614\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.004509509075433016 with total_loss: 0.14383640512824059\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.005072839558124542 with total_loss: 0.1483459142036736\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.004729850217700005 with total_loss: 0.15341875376179814\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.003654712811112404 with total_loss: 0.15814860397949815\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.0051723201759159565 with total_loss: 0.16180331679061055\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.00740882707759738 with total_loss: 0.1669756369665265\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.0055753085762262344 with total_loss: 0.1743844640441239\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.00449400907382369 with total_loss: 0.17995977262035012\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0062731350772082806 with total_loss: 0.1844537816941738\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.0042822821997106075 with total_loss: 0.1907269167713821\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.004332409705966711 with total_loss: 0.1950091989710927\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.004808534402400255 with total_loss: 0.1993416086770594\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.005526798311620951 with total_loss: 0.20415014307945967\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.006361038889735937 with total_loss: 0.20967694139108062\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.004795528948307037 with total_loss: 0.21603798028081656\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.007520509418100119 with total_loss: 0.2208335092291236\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.0080178277567029 with total_loss: 0.2283540186472237\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.009131553582847118 with total_loss: 0.2363718464039266\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.007305505219846964 with total_loss: 0.24550339998677373\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.011140073649585247 with total_loss: 0.2528089052066207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.029425665736198425 with total_loss: 0.26394897885620594\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.008192283101379871 with total_loss: 0.29337464459240437\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.005741063039749861 with total_loss: 0.30156692769378424\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.008726686239242554 with total_loss: 0.3073079907335341\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.020429501309990883 with total_loss: 0.31603467697277665\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.007475750055164099 with total_loss: 0.33646417828276753\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.007494036108255386 with total_loss: 0.34393992833793163\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.005897084251046181 with total_loss: 0.351433964446187\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.007728555705398321 with total_loss: 0.3573310486972332\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.005964286625385284 with total_loss: 0.3650596044026315\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.00564409838989377 with total_loss: 0.3710238910280168\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.009096994064748287 with total_loss: 0.3766679894179106\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.013301600702106953 with total_loss: 0.38576498348265886\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.015499730594456196 with total_loss: 0.3990665841847658\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.007185912225395441 with total_loss: 0.414566314779222\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.007452031131833792 with total_loss: 0.42175222700461745\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.006255445536226034 with total_loss: 0.42920425813645124\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.00498919514939189 with total_loss: 0.4354597036726773\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.008384336717426777 with total_loss: 0.44044889882206917\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.006217136979103088 with total_loss: 0.44883323553949594\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.006268386263400316 with total_loss: 0.45505037251859903\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.005450948607176542 with total_loss: 0.46131875878199935\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.005460100714117289 with total_loss: 0.4667697073891759\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.010135927237570286 with total_loss: 0.4722298081032932\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.007063443306833506 with total_loss: 0.48236573534086347\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.006300429347902536 with total_loss: 0.48942917864769697\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.005264339502900839 with total_loss: 0.4957296079955995\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.0054278685711324215 with total_loss: 0.5009939474985003\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.005869428161531687 with total_loss: 0.5064218160696328\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.005405303556472063 with total_loss: 0.5122912442311645\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.005595680791884661 with total_loss: 0.5176965477876365\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.006051890552043915 with total_loss: 0.5232922285795212\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.004721152596175671 with total_loss: 0.5293441191315651\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.006717566400766373 with total_loss: 0.5340652717277408\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.004684888292104006 with total_loss: 0.5407828381285071\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.007232654839754105 with total_loss: 0.5454677264206111\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.005287325009703636 with total_loss: 0.5527003812603652\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.004999631550163031 with total_loss: 0.5579877062700689\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.6758762001991272 with total_loss: 0.5629873378202319\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.007462505251169205 with total_loss: 1.2388635380193591\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.008371860720217228 with total_loss: 1.2463260432705283\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.006786091718822718 with total_loss: 1.2546979039907455\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.005906498525291681 with total_loss: 1.2614839957095683\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.0064392429776489735 with total_loss: 1.26739049423486\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.0050404686480760574 with total_loss: 1.273829737212509\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.004431299865245819 with total_loss: 1.278870205860585\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.0626540407538414 with total_loss: 1.2833015057258308\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.006397776305675507 with total_loss: 1.3459555464796722\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.005144074093550444 with total_loss: 1.3523533227853477\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.005865918938070536 with total_loss: 1.3574973968788981\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.005249847192317247 with total_loss: 1.3633633158169687\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.004728177096694708 with total_loss: 1.368613163009286\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.005015613045543432 with total_loss: 1.3733413401059806\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.004664041567593813 with total_loss: 1.378356953151524\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.005419085267931223 with total_loss: 1.3830209947191179\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.0053863259963691235 with total_loss: 1.388440079987049\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.005651228595525026 with total_loss: 1.3938264059834182\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.00523727061226964 with total_loss: 1.3994776345789433\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 27 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.004154689610004425 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.00493701733648777 with total_loss: 0.004154689610004425\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.005962012335658073 with total_loss: 0.009091706946492195\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.005749605130404234 with total_loss: 0.015053719282150269\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.006995491683483124 with total_loss: 0.020803324412554502\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.005727122072130442 with total_loss: 0.027798816096037626\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.00492296414449811 with total_loss: 0.03352593816816807\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.0047294204123318195 with total_loss: 0.03844890231266618\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.005250412970781326 with total_loss: 0.043178322724998\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.005071237683296204 with total_loss: 0.048428735695779324\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.005384048912674189 with total_loss: 0.05349997337907553\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.004109634552150965 with total_loss: 0.058884022291749716\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.00639781728386879 with total_loss: 0.06299365684390068\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.004625420551747084 with total_loss: 0.06939147412776947\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.004050805699080229 with total_loss: 0.07401689467951655\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.005623670760542154 with total_loss: 0.07806770037859678\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.00600397726520896 with total_loss: 0.08369137113913894\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.004327806178480387 with total_loss: 0.0896953484043479\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.0052315667271614075 with total_loss: 0.09402315458282828\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.006552569568157196 with total_loss: 0.09925472130998969\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.004426304250955582 with total_loss: 0.10580729087814689\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.0037371504586189985 with total_loss: 0.11023359512910247\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.004635979887098074 with total_loss: 0.11397074558772147\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.004587224218994379 with total_loss: 0.11860672547481954\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.004761071410030127 with total_loss: 0.12319394969381392\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.004739308264106512 with total_loss: 0.12795502110384405\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.0039502475410699844 with total_loss: 0.13269432936795056\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.004810107406228781 with total_loss: 0.13664457690902054\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.005451627541333437 with total_loss: 0.14145468431524932\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.005430486053228378 with total_loss: 0.14690631185658276\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.00339711457490921 with total_loss: 0.15233679790981114\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.006398288533091545 with total_loss: 0.15573391248472035\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.010995899327099323 with total_loss: 0.1621322010178119\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.006286312360316515 with total_loss: 0.17312810034491122\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.0057312301360070705 with total_loss: 0.17941441270522773\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.008044524118304253 with total_loss: 0.1851456428412348\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.006706540007144213 with total_loss: 0.19319016695953906\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.005679935682564974 with total_loss: 0.19989670696668327\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.005822776351124048 with total_loss: 0.20557664264924824\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.010113629512488842 with total_loss: 0.2113994190003723\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.006036271806806326 with total_loss: 0.22151304851286113\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.010749964974820614 with total_loss: 0.22754932031966746\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.009058806113898754 with total_loss: 0.23829928529448807\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.006628062576055527 with total_loss: 0.24735809140838683\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.004640707280486822 with total_loss: 0.25398615398444235\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.004500761162489653 with total_loss: 0.2586268612649292\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.010476677678525448 with total_loss: 0.26312762242741883\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.005242893006652594 with total_loss: 0.2736043001059443\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.008977902121841908 with total_loss: 0.27884719311259687\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.005611130502074957 with total_loss: 0.2878250952344388\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.006212951149791479 with total_loss: 0.29343622573651373\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.0070421271957457066 with total_loss: 0.2996491768863052\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.005928142461925745 with total_loss: 0.3066913040820509\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.006104618776589632 with total_loss: 0.31261944654397666\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.0072982958517968655 with total_loss: 0.3187240653205663\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.004187493119388819 with total_loss: 0.32602236117236316\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.006822875235229731 with total_loss: 0.330209854291752\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.015483345836400986 with total_loss: 0.3370327295269817\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.005506465211510658 with total_loss: 0.3525160753633827\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.00529133528470993 with total_loss: 0.35802254057489336\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.007216025143861771 with total_loss: 0.3633138758596033\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.0073175677098333836 with total_loss: 0.37052990100346506\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.005570197012275457 with total_loss: 0.37784746871329844\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.0065424698404967785 with total_loss: 0.3834176657255739\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.006072779651731253 with total_loss: 0.3899601355660707\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.0045959618873894215 with total_loss: 0.39603291521780193\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.0053772167302668095 with total_loss: 0.40062887710519135\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.005362812429666519 with total_loss: 0.40600609383545816\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.005126041825860739 with total_loss: 0.4113689062651247\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.005262147169560194 with total_loss: 0.4164949480909854\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.005201318301260471 with total_loss: 0.4217570952605456\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.005549578461796045 with total_loss: 0.4269584135618061\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.008367704227566719 with total_loss: 0.43250799202360213\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.004690955858677626 with total_loss: 0.44087569625116885\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.6058143973350525 with total_loss: 0.4455666521098465\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.005830979440361261 with total_loss: 1.051381049444899\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.00593468127772212 with total_loss: 1.0572120288852602\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.00439524045214057 with total_loss: 1.0631467101629823\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.006612952798604965 with total_loss: 1.067541950615123\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.006965887267142534 with total_loss: 1.0741549034137279\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.004145460668951273 with total_loss: 1.0811207906808704\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.0044851154088974 with total_loss: 1.0852662513498217\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.006387906614691019 with total_loss: 1.089751366758719\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.004315612837672234 with total_loss: 1.09613927337341\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.005461417604237795 with total_loss: 1.1004548862110823\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.004756632726639509 with total_loss: 1.1059163038153201\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.004125771578401327 with total_loss: 1.1106729365419596\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.004673495423048735 with total_loss: 1.114798708120361\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.04901580512523651 with total_loss: 1.1194722035434097\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.10543348640203476 with total_loss: 1.1684880086686462\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.003436669008806348 with total_loss: 1.273921495070681\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.0054904441349208355 with total_loss: 1.2773581640794873\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.003167013404890895 with total_loss: 1.2828486082144082\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.004649479873478413 with total_loss: 1.286015621619299\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 28 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.0049652340821921825 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.006820306647568941 with total_loss: 0.0049652340821921825\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.005419721361249685 with total_loss: 0.011785540729761124\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.005708560347557068 with total_loss: 0.01720526209101081\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.005922651384025812 with total_loss: 0.022913822438567877\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.00517893536016345 with total_loss: 0.02883647382259369\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.0058009871281683445 with total_loss: 0.03401540918275714\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.004517342895269394 with total_loss: 0.039816396310925484\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.005213076714426279 with total_loss: 0.04433373920619488\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0047417934983968735 with total_loss: 0.04954681592062116\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.006684602703899145 with total_loss: 0.05428860941901803\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.00497734360396862 with total_loss: 0.060973212122917175\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.004913351032882929 with total_loss: 0.0659505557268858\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.004952118266373873 with total_loss: 0.07086390675976872\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.00690286373719573 with total_loss: 0.0758160250261426\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.005648910999298096 with total_loss: 0.08271888876333833\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.005348016042262316 with total_loss: 0.08836779976263642\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.006273242179304361 with total_loss: 0.09371581580489874\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.004822432529181242 with total_loss: 0.0999890579842031\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.006802748888731003 with total_loss: 0.10481149051338434\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.005353549029678106 with total_loss: 0.11161423940211535\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.005235923919826746 with total_loss: 0.11696778843179345\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.005422929767519236 with total_loss: 0.1222037123516202\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.005987671669572592 with total_loss: 0.12762664211913943\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0038879846688359976 with total_loss: 0.13361431378871202\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.005061729345470667 with total_loss: 0.13750229845754802\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.004839660134166479 with total_loss: 0.1425640278030187\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.006318582687526941 with total_loss: 0.14740368793718517\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.003760806517675519 with total_loss: 0.1537222706247121\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.0060799941420555115 with total_loss: 0.15748307714238763\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.004616389516741037 with total_loss: 0.16356307128444314\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.009320324286818504 with total_loss: 0.16817946080118418\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.009109198115766048 with total_loss: 0.17749978508800268\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.00647624721750617 with total_loss: 0.18660898320376873\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.007646807935088873 with total_loss: 0.1930852304212749\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.006291519850492477 with total_loss: 0.20073203835636377\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.005124380346387625 with total_loss: 0.20702355820685625\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.009618798270821571 with total_loss: 0.21214793855324388\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.004421904217451811 with total_loss: 0.22176673682406545\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.00849501509219408 with total_loss: 0.22618864104151726\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.06798852235078812 with total_loss: 0.23468365613371134\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.008879677392542362 with total_loss: 0.30267217848449945\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.006195353344082832 with total_loss: 0.3115518558770418\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.0062403627671301365 with total_loss: 0.31774720922112465\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.006149889901280403 with total_loss: 0.3239875719882548\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.004702425096184015 with total_loss: 0.3301374618895352\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.03301263973116875 with total_loss: 0.3348398869857192\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.00511312298476696 with total_loss: 0.36785252671688795\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.006423680577427149 with total_loss: 0.3729656497016549\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.007883274927735329 with total_loss: 0.37938933027908206\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.007564770523458719 with total_loss: 0.3872726052068174\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.007050730753690004 with total_loss: 0.3948373757302761\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.00796386320143938 with total_loss: 0.4018881064839661\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.007223447319120169 with total_loss: 0.4098519696854055\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.006599317770451307 with total_loss: 0.41707541700452566\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.005612339824438095 with total_loss: 0.42367473477497697\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.0055741420947015285 with total_loss: 0.42928707459941506\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.009756484068930149 with total_loss: 0.4348612166941166\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.01190341729670763 with total_loss: 0.44461770076304674\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.01021494809538126 with total_loss: 0.45652111805975437\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.005386368837207556 with total_loss: 0.46673606615513563\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.007359679788351059 with total_loss: 0.4721224349923432\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.008318931795656681 with total_loss: 0.47948211478069425\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.006000809371471405 with total_loss: 0.4878010465763509\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.004346703644841909 with total_loss: 0.49380185594782233\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.006539067719131708 with total_loss: 0.49814855959266424\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.005899732932448387 with total_loss: 0.504687627311796\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.005856080446392298 with total_loss: 0.5105873602442443\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.0038596477825194597 with total_loss: 0.5164434406906366\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.005825703963637352 with total_loss: 0.5203030884731561\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.004421355202794075 with total_loss: 0.5261287924367934\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.005822397768497467 with total_loss: 0.5305501476395875\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.003943896386772394 with total_loss: 0.536372545408085\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.006185166072100401 with total_loss: 0.5403164417948574\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.004616039805114269 with total_loss: 0.5465016078669578\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.004329192917793989 with total_loss: 0.551117647672072\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.005768756847828627 with total_loss: 0.555446840589866\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.0040732454508543015 with total_loss: 0.5612155974376947\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.004367211367934942 with total_loss: 0.565288842888549\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.006068368908017874 with total_loss: 0.5696560542564839\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.007177858147770166 with total_loss: 0.5757244231645018\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.004023349843919277 with total_loss: 0.582902281312272\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.005718396510928869 with total_loss: 0.5869256311561912\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.004913104232400656 with total_loss: 0.5926440276671201\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.004682330414652824 with total_loss: 0.5975571318995208\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.0049128239043056965 with total_loss: 0.6022394623141736\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0034958866890519857 with total_loss: 0.6071522862184793\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.00447390740737319 with total_loss: 0.6106481729075313\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.004928874783217907 with total_loss: 0.6151220803149045\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.005022177007049322 with total_loss: 0.6200509550981224\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.004453592002391815 with total_loss: 0.6250731321051717\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.004597306251525879 with total_loss: 0.6295267241075635\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.006182083860039711 with total_loss: 0.6341240303590894\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.006755130365490913 with total_loss: 0.6403061142191291\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 29 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.00639588525518775 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.005525149405002594 with total_loss: 0.00639588525518775\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.0043798587284982204 with total_loss: 0.011921034660190344\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.005240679252892733 with total_loss: 0.016300893388688564\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.0052143000066280365 with total_loss: 0.021541572641581297\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.006707704160362482 with total_loss: 0.026755872648209333\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.005394539330154657 with total_loss: 0.033463576808571815\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.004724935162812471 with total_loss: 0.03885811613872647\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.004399498924612999 with total_loss: 0.043583051301538944\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0033669702243059874 with total_loss: 0.04798255022615194\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.006042062770575285 with total_loss: 0.05134952045045793\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.003788522444665432 with total_loss: 0.057391583221033216\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.004004289861768484 with total_loss: 0.06118010566569865\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0043029929511249065 with total_loss: 0.06518439552746713\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.004671625792980194 with total_loss: 0.06948738847859204\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.004088308196514845 with total_loss: 0.07415901427157223\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.0044010477140545845 with total_loss: 0.07824732246808708\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.005575752351433039 with total_loss: 0.08264837018214166\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.007871533744037151 with total_loss: 0.0882241225335747\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.005666870623826981 with total_loss: 0.09609565627761185\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.004903723020106554 with total_loss: 0.10176252690143883\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.004462935030460358 with total_loss: 0.10666624992154539\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.004604791756719351 with total_loss: 0.11112918495200574\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.00517576327547431 with total_loss: 0.1157339767087251\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0040876897983253 with total_loss: 0.1209097399841994\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.004340646788477898 with total_loss: 0.1249974297825247\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.0038572659250348806 with total_loss: 0.1293380765710026\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.0039046742022037506 with total_loss: 0.13319534249603748\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.0037727439776062965 with total_loss: 0.13710001669824123\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.006205430720001459 with total_loss: 0.14087276067584753\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.004097944591194391 with total_loss: 0.147078191395849\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.007889051921665668 with total_loss: 0.15117613598704338\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.01131285261362791 with total_loss: 0.15906518790870905\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.00887987483292818 with total_loss: 0.17037804052233696\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.007975214160978794 with total_loss: 0.17925791535526514\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.006378304213285446 with total_loss: 0.18723312951624393\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.009503412991762161 with total_loss: 0.19361143372952938\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.005500030238181353 with total_loss: 0.20311484672129154\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.010501098819077015 with total_loss: 0.2086148769594729\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.007317829877138138 with total_loss: 0.2191159757785499\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.008520605973899364 with total_loss: 0.22643380565568805\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.008703635074198246 with total_loss: 0.2349544116295874\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.010903988964855671 with total_loss: 0.24365804670378566\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.006614458281546831 with total_loss: 0.25456203566864133\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.008184746839106083 with total_loss: 0.26117649395018816\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.005694150924682617 with total_loss: 0.26936124078929424\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.004244954790920019 with total_loss: 0.27505539171397686\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.007855669595301151 with total_loss: 0.2793003465048969\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.00489442003890872 with total_loss: 0.28715601610019803\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.006616357713937759 with total_loss: 0.29205043613910675\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.008255532942712307 with total_loss: 0.2986667938530445\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.006945858243852854 with total_loss: 0.3069223267957568\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.00527341291308403 with total_loss: 0.31386818503960967\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.010019643232226372 with total_loss: 0.3191415979526937\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.0061092977412045 with total_loss: 0.3291612411849201\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.00540725514292717 with total_loss: 0.3352705389261246\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.006276745814830065 with total_loss: 0.34067779406905174\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.006981404032558203 with total_loss: 0.3469545398838818\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.008788011968135834 with total_loss: 0.35393594391644\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.009066298604011536 with total_loss: 0.36272395588457584\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.0063000209629535675 with total_loss: 0.3717902544885874\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.00654534250497818 with total_loss: 0.37809027545154095\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.007645261008292437 with total_loss: 0.3846356179565191\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.006345182657241821 with total_loss: 0.39228087896481156\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.005757249426096678 with total_loss: 0.3986260616220534\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.006086123641580343 with total_loss: 0.40438331104815006\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.005091593135148287 with total_loss: 0.4104694346897304\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.005400035995990038 with total_loss: 0.4155610278248787\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.004990579094737768 with total_loss: 0.42096106382086873\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.005297136027365923 with total_loss: 0.4259516429156065\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.004380980972200632 with total_loss: 0.4312487789429724\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.004601513966917992 with total_loss: 0.43562975991517305\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.004818708170205355 with total_loss: 0.44023127388209105\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.0044168103486299515 with total_loss: 0.4450499820522964\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.005679147783666849 with total_loss: 0.44946679240092635\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.006036287639290094 with total_loss: 0.4551459401845932\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.00553145632147789 with total_loss: 0.4611822278238833\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.0045124138705432415 with total_loss: 0.4667136841453612\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.004359573125839233 with total_loss: 0.4712260980159044\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.0049594067968428135 with total_loss: 0.47558567114174366\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.004090242553502321 with total_loss: 0.4805450779385865\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.004791557788848877 with total_loss: 0.4846353204920888\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.0034479561727494 with total_loss: 0.48942687828093767\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.004420003853738308 with total_loss: 0.49287483445368707\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.004110854119062424 with total_loss: 0.4972948383074254\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.0032902390230447054 with total_loss: 0.5014056924264878\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0050181434489786625 with total_loss: 0.5046959314495325\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.0051782443188130856 with total_loss: 0.5097140748985112\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.005682021379470825 with total_loss: 0.5148923192173243\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.00658576563000679 with total_loss: 0.5205743405967951\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.0036332719027996063 with total_loss: 0.5271601062268019\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.005518441554158926 with total_loss: 0.5307933781296015\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.004018376115709543 with total_loss: 0.5363118196837604\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.004901409614831209 with total_loss: 0.54033019579947\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 30 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.004557845648378134 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.005661683157086372 with total_loss: 0.004557845648378134\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.0033636402804404497 with total_loss: 0.010219528805464506\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.0055536129511892796 with total_loss: 0.013583169085904956\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.0046887523494660854 with total_loss: 0.019136782037094235\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.004182439297437668 with total_loss: 0.02382553438656032\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.00333924381993711 with total_loss: 0.02800797368399799\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.004573681857436895 with total_loss: 0.0313472175039351\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.004239005967974663 with total_loss: 0.035920899361371994\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.004298868123441935 with total_loss: 0.04015990532934666\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.006273861508816481 with total_loss: 0.04445877345278859\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.005607238505035639 with total_loss: 0.05073263496160507\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.007902554236352444 with total_loss: 0.05633987346664071\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.004402671009302139 with total_loss: 0.06424242770299315\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.003828855464234948 with total_loss: 0.0686450987122953\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.0037655653432011604 with total_loss: 0.07247395417653024\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.004900449421256781 with total_loss: 0.0762395195197314\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.005062620621174574 with total_loss: 0.08113996894098818\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.004451987333595753 with total_loss: 0.08620258956216276\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.005161449778825045 with total_loss: 0.09065457689575851\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.004756495356559753 with total_loss: 0.09581602667458355\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.005338872317224741 with total_loss: 0.10057252203114331\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.004931692499667406 with total_loss: 0.10591139434836805\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.004760417155921459 with total_loss: 0.11084308684803545\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.004406285006552935 with total_loss: 0.11560350400395691\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.0048252795822918415 with total_loss: 0.12000978901050985\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.004307389724999666 with total_loss: 0.12483506859280169\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.004111585672944784 with total_loss: 0.12914245831780136\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.0037988091353327036 with total_loss: 0.13325404399074614\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.004068373236805201 with total_loss: 0.13705285312607884\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.004427788313478231 with total_loss: 0.14112122636288404\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.009492447599768639 with total_loss: 0.14554901467636228\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.0076181949116289616 with total_loss: 0.15504146227613091\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.007104312535375357 with total_loss: 0.16265965718775988\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.0077986582182347775 with total_loss: 0.16976396972313523\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.004624348599463701 with total_loss: 0.17756262794137\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.0039053987711668015 with total_loss: 0.1821869765408337\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.006590513978153467 with total_loss: 0.1860923753120005\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.0063648708164691925 with total_loss: 0.19268288929015398\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.006357001140713692 with total_loss: 0.19904776010662317\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.006386398803442717 with total_loss: 0.20540476124733686\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.014296089299023151 with total_loss: 0.21179116005077958\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.0059304614551365376 with total_loss: 0.22608724934980273\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.007874674163758755 with total_loss: 0.23201771080493927\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.00514696491882205 with total_loss: 0.23989238496869802\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.005369081627577543 with total_loss: 0.24503934988752007\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.005220440682023764 with total_loss: 0.2504084315150976\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.00684144115075469 with total_loss: 0.2556288721971214\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.006196094211190939 with total_loss: 0.26247031334787607\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.007938805036246777 with total_loss: 0.268666407559067\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.007054999470710754 with total_loss: 0.2766052125953138\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.0033273871522396803 with total_loss: 0.28366021206602454\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.0054857549257576466 with total_loss: 0.2869875992182642\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.005100341979414225 with total_loss: 0.29247335414402187\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.004977188538759947 with total_loss: 0.2975736961234361\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.0057031684555113316 with total_loss: 0.30255088466219604\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.005211531650274992 with total_loss: 0.30825405311770737\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.005285006016492844 with total_loss: 0.31346558476798236\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.0055034891702234745 with total_loss: 0.3187505907844752\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.004841406363993883 with total_loss: 0.3242540799546987\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.00522565795108676 with total_loss: 0.32909548631869256\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.007096156477928162 with total_loss: 0.3343211442697793\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.007969117723405361 with total_loss: 0.3414173007477075\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.00984338391572237 with total_loss: 0.34938641847111285\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.006038914900273085 with total_loss: 0.3592298023868352\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.003352029947564006 with total_loss: 0.3652687172871083\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.004760626703500748 with total_loss: 0.3686207472346723\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.004920199979096651 with total_loss: 0.37338137393817306\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.005631212145090103 with total_loss: 0.3783015739172697\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.00608885707333684 with total_loss: 0.3839327860623598\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.005265731364488602 with total_loss: 0.39002164313569665\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.004429903347045183 with total_loss: 0.39528737450018525\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.005022368859499693 with total_loss: 0.39971727784723043\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.00467305863276124 with total_loss: 0.4047396467067301\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.0033865750301629305 with total_loss: 0.40941270533949137\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.0039087398909032345 with total_loss: 0.4127992803696543\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.005230279639363289 with total_loss: 0.41670802026055753\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.005619417410343885 with total_loss: 0.4219382998999208\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.0037527766544371843 with total_loss: 0.4275577173102647\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.004829389974474907 with total_loss: 0.4313104939647019\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.005301930475980043 with total_loss: 0.4361398839391768\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.004389126319438219 with total_loss: 0.44144181441515684\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.005737879779189825 with total_loss: 0.44583094073459506\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.004903825465589762 with total_loss: 0.4515688205137849\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.00491757458075881 with total_loss: 0.45647264597937465\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.00369125884026289 with total_loss: 0.46139022056013346\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.00470886891707778 with total_loss: 0.46508147940039635\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.003750453470274806 with total_loss: 0.4697903483174741\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.004253858234733343 with total_loss: 0.47354080178774893\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.004967742599546909 with total_loss: 0.4777946600224823\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.0045045907609164715 with total_loss: 0.4827624026220292\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.004317700397223234 with total_loss: 0.48726699338294566\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.004314644727855921 with total_loss: 0.4915846937801689\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.0035857537295669317 with total_loss: 0.4958993385080248\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 31 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.004462519194930792 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.004981279838830233 with total_loss: 0.004462519194930792\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.004712813999503851 with total_loss: 0.009443799033761024\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.008124575950205326 with total_loss: 0.014156613033264875\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.003436821745708585 with total_loss: 0.0222811889834702\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.0053151375614106655 with total_loss: 0.025718010729178786\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.005240108817815781 with total_loss: 0.031033148290589452\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.0036611200775951147 with total_loss: 0.03627325710840523\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.004178342875093222 with total_loss: 0.03993437718600035\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0053107100538909435 with total_loss: 0.04411272006109357\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.0034772499930113554 with total_loss: 0.04942343011498451\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.004765665158629417 with total_loss: 0.05290068010799587\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.004729838110506535 with total_loss: 0.057666345266625285\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.00426136888563633 with total_loss: 0.06239618337713182\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.0044616153463721275 with total_loss: 0.06665755226276815\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.004519625101238489 with total_loss: 0.07111916760914028\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.005362907890230417 with total_loss: 0.07563879271037877\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.004335235338658094 with total_loss: 0.08100170060060918\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.00488712964579463 with total_loss: 0.08533693593926728\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.004631434101611376 with total_loss: 0.09022406558506191\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.004163868725299835 with total_loss: 0.09485549968667328\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.004718523006886244 with total_loss: 0.09901936841197312\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.003993502352386713 with total_loss: 0.10373789141885936\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.0035210801288485527 with total_loss: 0.10773139377124608\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.004411224275827408 with total_loss: 0.11125247390009463\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.006221668794751167 with total_loss: 0.11566369817592204\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.004757723305374384 with total_loss: 0.1218853669706732\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.004389291163533926 with total_loss: 0.1266430902760476\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.0042769028805196285 with total_loss: 0.1310323814395815\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.004240135196596384 with total_loss: 0.13530928432010114\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.006475936621427536 with total_loss: 0.13954941951669753\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.0126677630469203 with total_loss: 0.14602535613812506\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.008195863105356693 with total_loss: 0.15869311918504536\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.0071133957244455814 with total_loss: 0.16688898229040205\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.006569913122802973 with total_loss: 0.17400237801484764\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.005889915395528078 with total_loss: 0.1805722911376506\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.008506677113473415 with total_loss: 0.1864622065331787\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.006085397209972143 with total_loss: 0.1949688836466521\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.005751641932874918 with total_loss: 0.20105428085662425\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.007353781256824732 with total_loss: 0.20680592278949916\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.007067633327096701 with total_loss: 0.2141597040463239\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.007970093749463558 with total_loss: 0.2212273373734206\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.004378960933536291 with total_loss: 0.22919743112288415\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.0071086096577346325 with total_loss: 0.23357639205642045\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.005584867671132088 with total_loss: 0.24068500171415508\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.005764591041952372 with total_loss: 0.24626986938528717\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.005431898403912783 with total_loss: 0.25203446042723954\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.005032965913414955 with total_loss: 0.2574663588311523\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.00548006035387516 with total_loss: 0.2624993247445673\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.004551330581307411 with total_loss: 0.26797938509844244\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.006595216691493988 with total_loss: 0.27253071567974985\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.005289602559059858 with total_loss: 0.27912593237124383\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.00631622364744544 with total_loss: 0.2844155349303037\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.0056557790376245975 with total_loss: 0.29073175857774913\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.02978028543293476 with total_loss: 0.29638753761537373\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.004942486062645912 with total_loss: 0.3261678230483085\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.004981752950698137 with total_loss: 0.3311103091109544\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.0056586600840091705 with total_loss: 0.33609206206165254\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.004696652293205261 with total_loss: 0.3417507221456617\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.006847584620118141 with total_loss: 0.346447374438867\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.004853771533817053 with total_loss: 0.3532949590589851\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.004776789341121912 with total_loss: 0.35814873059280217\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.003999294713139534 with total_loss: 0.3629255199339241\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.005110474769026041 with total_loss: 0.3669248146470636\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.010173970833420753 with total_loss: 0.37203528941608965\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.0040423013269901276 with total_loss: 0.3822092602495104\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.004573647398501635 with total_loss: 0.38625156157650054\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.00417728628963232 with total_loss: 0.39082520897500217\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.005672775208950043 with total_loss: 0.3950024952646345\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.0036434419453144073 with total_loss: 0.40067527047358453\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.0042672064155340195 with total_loss: 0.40431871241889894\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.004373299423605204 with total_loss: 0.40858591883443296\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.004960769787430763 with total_loss: 0.41295921825803816\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.005764777306467295 with total_loss: 0.4179199880454689\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.00476134242489934 with total_loss: 0.4236847653519362\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.00522227818146348 with total_loss: 0.42844610777683556\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.004197562579065561 with total_loss: 0.43366838595829904\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.003377688815817237 with total_loss: 0.4378659485373646\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.004781113937497139 with total_loss: 0.44124363735318184\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.003435506485402584 with total_loss: 0.446024751290679\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.004568076226860285 with total_loss: 0.44946025777608156\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.004938512109220028 with total_loss: 0.45402833400294185\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.003516578348353505 with total_loss: 0.4589668461121619\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.005012125708162785 with total_loss: 0.4624834244605154\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.004562383983284235 with total_loss: 0.46749555016867816\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.0052645220421254635 with total_loss: 0.4720579341519624\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0048215058632195 with total_loss: 0.47732245619408786\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.0033459076657891273 with total_loss: 0.48214396205730736\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.004731171298772097 with total_loss: 0.4854898697230965\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.004975578747689724 with total_loss: 0.4902210410218686\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.004515813663601875 with total_loss: 0.4951966197695583\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.006556488573551178 with total_loss: 0.4997124334331602\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.0051546222530305386 with total_loss: 0.5062689220067114\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.004965841770172119 with total_loss: 0.5114235442597419\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 32 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.0038583234418183565 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.004596324171870947 with total_loss: 0.0038583234418183565\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.003798070130869746 with total_loss: 0.008454647613689303\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.004145052749663591 with total_loss: 0.01225271774455905\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.00473826052621007 with total_loss: 0.01639777049422264\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.0037907585501670837 with total_loss: 0.02113603102043271\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.0033745896071195602 with total_loss: 0.024926789570599794\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.0029883310198783875 with total_loss: 0.028301379177719355\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.004532034043222666 with total_loss: 0.03128971019759774\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.004867240786552429 with total_loss: 0.03582174424082041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.004847776610404253 with total_loss: 0.04068898502737284\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.004384208936244249 with total_loss: 0.04553676163777709\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.0038790542166680098 with total_loss: 0.04992097057402134\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.003837983123958111 with total_loss: 0.05380002479068935\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.004319719038903713 with total_loss: 0.05763800791464746\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.003917972091585398 with total_loss: 0.06195772695355117\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.0035763282794505358 with total_loss: 0.06587569904513657\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.00365088670514524 with total_loss: 0.0694520273245871\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.0033010642509907484 with total_loss: 0.07310291402973235\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.004448072984814644 with total_loss: 0.0764039782807231\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.004590935073792934 with total_loss: 0.08085205126553774\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.004509472753852606 with total_loss: 0.08544298633933067\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.005196540616452694 with total_loss: 0.08995245909318328\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.004459759686142206 with total_loss: 0.09514899970963597\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.004581884015351534 with total_loss: 0.09960875939577818\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.005277939140796661 with total_loss: 0.10419064341112971\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.004858250264078379 with total_loss: 0.10946858255192637\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.004236288368701935 with total_loss: 0.11432683281600475\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.005254493560642004 with total_loss: 0.11856312118470669\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.003921803552657366 with total_loss: 0.12381761474534869\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.005300241056829691 with total_loss: 0.12773941829800606\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.004943144507706165 with total_loss: 0.13303965935483575\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.005634928122162819 with total_loss: 0.13798280386254191\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.004213577136397362 with total_loss: 0.14361773198470473\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.0064109135419130325 with total_loss: 0.1478313091211021\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.005406143609434366 with total_loss: 0.15424222266301513\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.005374582950025797 with total_loss: 0.1596483662724495\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.005325559061020613 with total_loss: 0.1650229492224753\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.005924983415752649 with total_loss: 0.1703485082834959\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.004245706368237734 with total_loss: 0.17627349169924855\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.004627878312021494 with total_loss: 0.1805191980674863\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.00499702850356698 with total_loss: 0.18514707637950778\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.005573337431997061 with total_loss: 0.19014410488307476\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.004294210579246283 with total_loss: 0.19571744231507182\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.005524363834410906 with total_loss: 0.2000116528943181\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.004914093296974897 with total_loss: 0.205536016728729\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.004557368811219931 with total_loss: 0.2104501100257039\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.005223540123552084 with total_loss: 0.21500747883692384\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.0048325215466320515 with total_loss: 0.22023101896047592\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.004240762442350388 with total_loss: 0.22506354050710797\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.006051364820450544 with total_loss: 0.22930430294945836\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.006052384618669748 with total_loss: 0.2353556677699089\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.005799304228276014 with total_loss: 0.24140805238857865\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.006495364010334015 with total_loss: 0.24720735661685467\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.005496842321008444 with total_loss: 0.2537027206271887\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.005318818148225546 with total_loss: 0.2591995629481971\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.004307916853576899 with total_loss: 0.2645183810964227\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.005604444537311792 with total_loss: 0.26882629794999957\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.004367481917142868 with total_loss: 0.27443074248731136\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.005783971399068832 with total_loss: 0.27879822440445423\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.00571848452091217 with total_loss: 0.28458219580352306\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.004149797838181257 with total_loss: 0.29030068032443523\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.0046715508215129375 with total_loss: 0.2944504781626165\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.00515749491751194 with total_loss: 0.29912202898412943\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.0045848689042031765 with total_loss: 0.30427952390164137\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.004220888484269381 with total_loss: 0.30886439280584455\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.004704090300947428 with total_loss: 0.3130852812901139\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.004049648996442556 with total_loss: 0.31778937159106135\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.006868725176900625 with total_loss: 0.3218390205875039\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.003907696809619665 with total_loss: 0.32870774576440454\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.00444246968254447 with total_loss: 0.3326154425740242\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.004522970411926508 with total_loss: 0.33705791225656867\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.0047784224152565 with total_loss: 0.3415808826684952\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.005530031863600016 with total_loss: 0.3463593050837517\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.00325864739716053 with total_loss: 0.3518893369473517\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.0036333389580249786 with total_loss: 0.3551479843445122\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.0035130446776747704 with total_loss: 0.3587813233025372\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.003985823597759008 with total_loss: 0.362294367980212\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.004219763912260532 with total_loss: 0.366280191577971\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.006285589653998613 with total_loss: 0.3704999554902315\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.005371151491999626 with total_loss: 0.3767855451442301\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.00480786245316267 with total_loss: 0.38215669663622975\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.0031644341070204973 with total_loss: 0.3869645590893924\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.003930161241441965 with total_loss: 0.3901289931964129\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.004073628690093756 with total_loss: 0.3940591544378549\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.004756751004606485 with total_loss: 0.39813278312794864\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0029052570462226868 with total_loss: 0.4028895341325551\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.004816880449652672 with total_loss: 0.4057947911787778\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.0035134460777044296 with total_loss: 0.4106116716284305\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.004057610873132944 with total_loss: 0.4141251177061349\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.004125375300645828 with total_loss: 0.41818272857926786\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.003574028378352523 with total_loss: 0.4223081038799137\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.0044910116121172905 with total_loss: 0.4258821322582662\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.003606051206588745 with total_loss: 0.4303731438703835\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 33 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.0033804308623075485 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.0040739295072853565 with total_loss: 0.0033804308623075485\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.006152996327728033 with total_loss: 0.007454360369592905\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.004017640370875597 with total_loss: 0.013607356697320938\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.0035154856741428375 with total_loss: 0.017624997068196535\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.004229143727570772 with total_loss: 0.021140482742339373\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.005997647996991873 with total_loss: 0.025369626469910145\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.004744959529489279 with total_loss: 0.03136727446690202\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.0032417364418506622 with total_loss: 0.036112233996391296\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.004753250628709793 with total_loss: 0.03935397043824196\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.0032214142847806215 with total_loss: 0.04410722106695175\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.00565268425270915 with total_loss: 0.04732863535173237\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.004835986066609621 with total_loss: 0.052981319604441524\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0034718234091997147 with total_loss: 0.057817305671051145\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.004249241668730974 with total_loss: 0.06128912908025086\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.004351997282356024 with total_loss: 0.06553837074898183\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.0031457357108592987 with total_loss: 0.06989036803133786\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.004241286311298609 with total_loss: 0.07303610374219716\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.0034489587415009737 with total_loss: 0.07727739005349576\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.0047861021012067795 with total_loss: 0.08072634879499674\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.004575816448777914 with total_loss: 0.08551245089620352\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.004343466833233833 with total_loss: 0.09008826734498143\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.003598933108150959 with total_loss: 0.09443173417821527\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.003971072845160961 with total_loss: 0.09803066728636622\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0035151857882738113 with total_loss: 0.10200174013152719\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.004258267115801573 with total_loss: 0.105516925919801\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.00430684257298708 with total_loss: 0.10977519303560257\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.005909664556384087 with total_loss: 0.11408203560858965\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.004944874905049801 with total_loss: 0.11999170016497374\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.0035712188109755516 with total_loss: 0.12493657507002354\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.0036363813560456038 with total_loss: 0.1285077938809991\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.004519860725849867 with total_loss: 0.1321441752370447\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.00742653151974082 with total_loss: 0.13666403596289456\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.004863705486059189 with total_loss: 0.14409056748263538\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.004085323307663202 with total_loss: 0.14895427296869457\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.004294028040021658 with total_loss: 0.15303959627635777\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.005220006685703993 with total_loss: 0.15733362431637943\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.0058022961020469666 with total_loss: 0.16255363100208342\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.003939843270927668 with total_loss: 0.1683559271041304\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.005131716374307871 with total_loss: 0.17229577037505805\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.005368571728467941 with total_loss: 0.17742748674936593\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.005145652685314417 with total_loss: 0.18279605847783387\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.004015013575553894 with total_loss: 0.18794171116314828\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.0043491884134709835 with total_loss: 0.19195672473870218\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.004289609845727682 with total_loss: 0.19630591315217316\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.005049179773777723 with total_loss: 0.20059552299790084\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.004370586946606636 with total_loss: 0.20564470277167857\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.004882253706455231 with total_loss: 0.2100152897182852\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.0046555898152291775 with total_loss: 0.21489754342474043\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.005976361688226461 with total_loss: 0.2195531332399696\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.005116751417517662 with total_loss: 0.22552949492819607\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.005207369569689035 with total_loss: 0.23064624634571373\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.004736032802611589 with total_loss: 0.23585361591540277\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.003538376884534955 with total_loss: 0.24058964871801436\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.004738597199320793 with total_loss: 0.24412802560254931\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.0069693829864263535 with total_loss: 0.2488666228018701\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.004776253830641508 with total_loss: 0.25583600578829646\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.004699475597590208 with total_loss: 0.26061225961893797\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.006623359862715006 with total_loss: 0.2653117352165282\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.007361832540482283 with total_loss: 0.2719350950792432\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.0053931898437440395 with total_loss: 0.27929692761972547\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.0034058152232319117 with total_loss: 0.2846901174634695\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.004728579428046942 with total_loss: 0.2880959326867014\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.004870859440416098 with total_loss: 0.29282451211474836\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.004234139807522297 with total_loss: 0.29769537155516446\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.00420195609331131 with total_loss: 0.30192951136268675\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.004934676922857761 with total_loss: 0.30613146745599806\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.0045188660733401775 with total_loss: 0.3110661443788558\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.004885312635451555 with total_loss: 0.315585010452196\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.004325774032622576 with total_loss: 0.32047032308764756\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.004819642752408981 with total_loss: 0.32479609712027013\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.004351160954684019 with total_loss: 0.3296157398726791\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.005061562638729811 with total_loss: 0.33396690082736313\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.0034768700134009123 with total_loss: 0.33902846346609294\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.005483897868543863 with total_loss: 0.34250533347949386\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.003967957105487585 with total_loss: 0.3479892313480377\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.0033139123115688562 with total_loss: 0.3519571884535253\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.005797719117254019 with total_loss: 0.35527110076509416\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.003622242948040366 with total_loss: 0.3610688198823482\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.003865359351038933 with total_loss: 0.36469106283038855\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.003399949287995696 with total_loss: 0.3685564221814275\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.0033409681636840105 with total_loss: 0.3719563714694232\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.004154563415795565 with total_loss: 0.3752973396331072\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.003586428938433528 with total_loss: 0.37945190304890275\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.0031671130564063787 with total_loss: 0.3830383319873363\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.003927985671907663 with total_loss: 0.38620544504374266\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.004451811779290438 with total_loss: 0.3901334307156503\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.0036380719393491745 with total_loss: 0.39458524249494076\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.0041533224284648895 with total_loss: 0.39822331443428993\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.003497729077935219 with total_loss: 0.4023766368627548\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.003912461455911398 with total_loss: 0.40587436594069004\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.0045644850470125675 with total_loss: 0.40978682739660144\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.00340076070278883 with total_loss: 0.414351312443614\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.003790061455219984 with total_loss: 0.41775207314640284\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 34 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.004807113204151392 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.0040192026644945145 with total_loss: 0.004807113204151392\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.0038321365136653185 with total_loss: 0.008826315868645906\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.0037123358342796564 with total_loss: 0.012658452382311225\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.0044763763435184956 with total_loss: 0.01637078821659088\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.0027110532391816378 with total_loss: 0.020847164560109377\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.0044065662659704685 with total_loss: 0.023558217799291015\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.004515363369137049 with total_loss: 0.027964784065261483\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.004617298021912575 with total_loss: 0.03248014743439853\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0044273813255131245 with total_loss: 0.03709744545631111\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.0033113043755292892 with total_loss: 0.04152482678182423\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.003953772131353617 with total_loss: 0.04483613115735352\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.003923958633095026 with total_loss: 0.04878990328870714\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.003368264064192772 with total_loss: 0.05271386192180216\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.04958631470799446 with total_loss: 0.056082125985994935\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.004692622926086187 with total_loss: 0.1056684406939894\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.005396522581577301 with total_loss: 0.11036106362007558\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.005584117025136948 with total_loss: 0.11575758620165288\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.005000464618206024 with total_loss: 0.12134170322678983\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.0031848938670009375 with total_loss: 0.12634216784499586\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.004263850394636393 with total_loss: 0.1295270617119968\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.0031767154578119516 with total_loss: 0.1337909121066332\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.004215668421238661 with total_loss: 0.13696762756444514\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.0035572482738643885 with total_loss: 0.1411832959856838\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.004582809284329414 with total_loss: 0.1447405442595482\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.0037233245093375444 with total_loss: 0.1493233535438776\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.0037813279777765274 with total_loss: 0.15304667805321515\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.004155668895691633 with total_loss: 0.15682800603099167\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.00403156504034996 with total_loss: 0.1609836749266833\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.003787164343520999 with total_loss: 0.16501523996703327\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.0049331714399158955 with total_loss: 0.16880240431055427\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.006336014252156019 with total_loss: 0.17373557575047016\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.007220687810331583 with total_loss: 0.18007159000262618\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.0051831817254424095 with total_loss: 0.18729227781295776\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.004734165500849485 with total_loss: 0.19247545953840017\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.0037110738921910524 with total_loss: 0.19720962503924966\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.004069361370056868 with total_loss: 0.2009206989314407\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.006914710626006126 with total_loss: 0.20499006030149758\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.010509620420634747 with total_loss: 0.2119047709275037\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.00823158398270607 with total_loss: 0.22241439134813845\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.00898601021617651 with total_loss: 0.23064597533084452\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.005296764429658651 with total_loss: 0.23963198554702103\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.004836654756218195 with total_loss: 0.24492874997667968\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.005548592656850815 with total_loss: 0.24976540473289788\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.00439027464017272 with total_loss: 0.2553139973897487\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.006724874954670668 with total_loss: 0.2597042720299214\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.0049492898397147655 with total_loss: 0.2664291469845921\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.005355954170227051 with total_loss: 0.27137843682430685\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.006041064392775297 with total_loss: 0.2767343909945339\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.004081252031028271 with total_loss: 0.2827754553873092\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.004190866835415363 with total_loss: 0.28685670741833746\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.0036119213327765465 with total_loss: 0.2910475742537528\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.0035557150840759277 with total_loss: 0.2946594955865294\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.0038920461665838957 with total_loss: 0.2982152106706053\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.006148115266114473 with total_loss: 0.3021072568371892\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.0038471671286970377 with total_loss: 0.30825537210330367\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.004155069589614868 with total_loss: 0.3121025392320007\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.0070669986307621 with total_loss: 0.3162576088216156\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.006716103758662939 with total_loss: 0.3233246074523777\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.0050117806531488895 with total_loss: 0.3300407112110406\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.005248867440968752 with total_loss: 0.3350524918641895\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.0039552790112793446 with total_loss: 0.34030135930515826\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.004089504014700651 with total_loss: 0.3442566383164376\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.003033549292013049 with total_loss: 0.34834614233113825\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.005300287622958422 with total_loss: 0.3513796916231513\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.0034969134721904993 with total_loss: 0.3566799792461097\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.0044666072353720665 with total_loss: 0.3601768927183002\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.005604869220405817 with total_loss: 0.3646434999536723\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.004306915681809187 with total_loss: 0.3702483691740781\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.004004786256700754 with total_loss: 0.3745552848558873\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.00417717918753624 with total_loss: 0.37856007111258805\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.004418439697474241 with total_loss: 0.3827372503001243\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.003927893470972776 with total_loss: 0.38715568999759853\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.00338173215277493 with total_loss: 0.3910835834685713\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.004157579503953457 with total_loss: 0.39446531562134624\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.0050460719503462315 with total_loss: 0.3986228951252997\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.005531681701540947 with total_loss: 0.4036689670756459\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.003481284948065877 with total_loss: 0.40920064877718687\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.004819419700652361 with total_loss: 0.41268193372525275\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.004149748478084803 with total_loss: 0.4175013534259051\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.004444850608706474 with total_loss: 0.4216511019039899\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.0035892461892217398 with total_loss: 0.4260959525126964\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.004004984628409147 with total_loss: 0.4296851987019181\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.004407784435898066 with total_loss: 0.4336901833303273\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.0038720201700925827 with total_loss: 0.43809796776622534\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.0034602582454681396 with total_loss: 0.4419699879363179\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.004490192048251629 with total_loss: 0.44543024618178606\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.0037744848523288965 with total_loss: 0.4499204382300377\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.003683430375531316 with total_loss: 0.4536949230823666\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.0038595646619796753 with total_loss: 0.4573783534578979\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.004125306848436594 with total_loss: 0.4612379181198776\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.004347151145339012 with total_loss: 0.46536322496831417\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.004053150303661823 with total_loss: 0.4697103761136532\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.004598155617713928 with total_loss: 0.473763526417315\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 35 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.003705025650560856 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.003894502529874444 with total_loss: 0.003705025650560856\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.00489062862470746 with total_loss: 0.0075995281804353\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.004205300472676754 with total_loss: 0.01249015680514276\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.0038549304008483887 with total_loss: 0.016695457277819514\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.00420577684417367 with total_loss: 0.020550387678667903\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.004059102386236191 with total_loss: 0.024756164522841573\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.00423309113830328 with total_loss: 0.028815266909077764\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.004084636922925711 with total_loss: 0.03304835804738104\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.004756697919219732 with total_loss: 0.037132994970306754\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.0036700658965855837 with total_loss: 0.041889692889526486\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.0036718377377837896 with total_loss: 0.04555975878611207\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.0033792878966778517 with total_loss: 0.04923159652389586\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.003837789176031947 with total_loss: 0.05261088442057371\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.0030635884031653404 with total_loss: 0.05644867359660566\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.0045143007300794125 with total_loss: 0.059512261999771\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.00370698026381433 with total_loss: 0.06402656272985041\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.004013491794466972 with total_loss: 0.06773354299366474\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.0035992891062051058 with total_loss: 0.07174703478813171\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.003782178508117795 with total_loss: 0.07534632389433682\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.004103858955204487 with total_loss: 0.07912850240245461\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.0077875894494354725 with total_loss: 0.0832323613576591\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.004182212986052036 with total_loss: 0.09101995080709457\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.0033538565039634705 with total_loss: 0.09520216379314661\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.004461559001356363 with total_loss: 0.09855602029711008\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.004257890861481428 with total_loss: 0.10301757929846644\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.004032872151583433 with total_loss: 0.10727547015994787\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.003228714456781745 with total_loss: 0.1113083423115313\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.004066138062626123 with total_loss: 0.11453705676831305\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.003321737051010132 with total_loss: 0.11860319483093917\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.004888840485364199 with total_loss: 0.1219249318819493\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.005950314458459616 with total_loss: 0.1268137723673135\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.009360945783555508 with total_loss: 0.13276408682577312\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.00617824075743556 with total_loss: 0.14212503260932863\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.008454508148133755 with total_loss: 0.1483032733667642\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.004697906784713268 with total_loss: 0.15675778151489794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.0035305749624967575 with total_loss: 0.1614556882996112\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.007190978154540062 with total_loss: 0.16498626326210797\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.004778341855853796 with total_loss: 0.17217724141664803\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.004469845909625292 with total_loss: 0.17695558327250183\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.004401983693242073 with total_loss: 0.18142542918212712\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.007884155958890915 with total_loss: 0.1858274128753692\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.004800556693226099 with total_loss: 0.1937115688342601\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.004182822536677122 with total_loss: 0.1985121255274862\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.004625081550329924 with total_loss: 0.20269494806416333\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.004286424722522497 with total_loss: 0.20732002961449325\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.0038029346615076065 with total_loss: 0.21160645433701575\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.004842528607696295 with total_loss: 0.21540938899852335\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.0037224916741251945 with total_loss: 0.22025191760621965\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.003763319691643119 with total_loss: 0.22397440928034484\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.004329402465373278 with total_loss: 0.22773772897198796\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.0041021667420864105 with total_loss: 0.23206713143736124\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.004979507997632027 with total_loss: 0.23616929817944765\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.0039731767028570175 with total_loss: 0.24114880617707968\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.0047152996994555 with total_loss: 0.2451219828799367\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.0038644373416900635 with total_loss: 0.2498372825793922\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.0042846002615988255 with total_loss: 0.25370171992108226\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.0080953324213624 with total_loss: 0.2579863201826811\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.005800125654786825 with total_loss: 0.2660816526040435\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.004736790899187326 with total_loss: 0.2718817782588303\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.005058011505752802 with total_loss: 0.27661856915801764\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.004214680287986994 with total_loss: 0.28167658066377044\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.005027202423661947 with total_loss: 0.28589126095175743\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.006327115464955568 with total_loss: 0.2909184633754194\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.005448672454804182 with total_loss: 0.29724557884037495\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.004356707911938429 with total_loss: 0.30269425129517913\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.004553768318146467 with total_loss: 0.30705095920711756\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.004375646822154522 with total_loss: 0.311604727525264\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.0033648137468844652 with total_loss: 0.31598037434741855\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.003832723945379257 with total_loss: 0.319345188094303\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.06225818395614624 with total_loss: 0.32317791203968227\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.004379595164209604 with total_loss: 0.3854360959958285\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.005318883340805769 with total_loss: 0.3898156911600381\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.004523780662566423 with total_loss: 0.3951345745008439\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.006595592945814133 with total_loss: 0.3996583551634103\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.0037308784667402506 with total_loss: 0.40625394810922444\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.005297312047332525 with total_loss: 0.4099848265759647\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.0037242795806378126 with total_loss: 0.4152821386232972\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.0031744511798024178 with total_loss: 0.419006418203935\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.0027183787897229195 with total_loss: 0.42218086938373744\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.005387572571635246 with total_loss: 0.42489924817346036\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.0027293860912323 with total_loss: 0.4302868207450956\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.003456678008660674 with total_loss: 0.4330162068363279\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.005878140684217215 with total_loss: 0.4364728848449886\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.004643088672310114 with total_loss: 0.4423510255292058\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.003733093850314617 with total_loss: 0.4469941142015159\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0036545342300087214 with total_loss: 0.45072720805183053\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.00286684837192297 with total_loss: 0.45438174228183925\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.0042708879336714745 with total_loss: 0.4572485906537622\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.004137454554438591 with total_loss: 0.4615194785874337\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.0038934650365263224 with total_loss: 0.4656569331418723\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.004108899738639593 with total_loss: 0.4695503981783986\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.004766263533383608 with total_loss: 0.4736592979170382\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.008125808089971542 with total_loss: 0.4784255614504218\n",
      "\n",
      "  Average training loss: 0.01\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 36 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.004146626219153404 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.003561001969501376 with total_loss: 0.004146626219153404\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.0039128693751990795 with total_loss: 0.00770762818865478\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.004699030425399542 with total_loss: 0.01162049756385386\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.005244181025773287 with total_loss: 0.016319527989253402\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.0036106568295508623 with total_loss: 0.02156370901502669\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.0033320505172014236 with total_loss: 0.02517436584457755\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.003912040963768959 with total_loss: 0.028506416361778975\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.003176330355927348 with total_loss: 0.032418457325547934\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0037355872336775064 with total_loss: 0.03559478768147528\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.0033158783335238695 with total_loss: 0.03933037491515279\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.004521089140325785 with total_loss: 0.04264625324867666\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.004123954102396965 with total_loss: 0.04716734238900244\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0047326707281172276 with total_loss: 0.05129129649139941\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.0036457728128880262 with total_loss: 0.056023967219516635\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.0028689568862318993 with total_loss: 0.05966974003240466\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.004048726987093687 with total_loss: 0.06253869691863656\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.0037636496126651764 with total_loss: 0.06658742390573025\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.003320616902783513 with total_loss: 0.07035107351839542\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.0031953772995620966 with total_loss: 0.07367169042117894\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.0032883593812584877 with total_loss: 0.07686706772074103\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.003117028623819351 with total_loss: 0.08015542710199952\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.003345021978020668 with total_loss: 0.08327245572581887\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.003120873123407364 with total_loss: 0.08661747770383954\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0053719510324299335 with total_loss: 0.0897383508272469\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.004074156749993563 with total_loss: 0.09511030185967684\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.0036061902064830065 with total_loss: 0.0991844586096704\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.004203321877866983 with total_loss: 0.10279064881615341\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.004162573721259832 with total_loss: 0.10699397069402039\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.004745717626065016 with total_loss: 0.11115654441528022\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.003596583381295204 with total_loss: 0.11590226204134524\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.00654758932068944 with total_loss: 0.11949884542264044\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.007581996265798807 with total_loss: 0.12604643474332988\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.005585042294114828 with total_loss: 0.1336284310091287\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.0049415952526032925 with total_loss: 0.13921347330324352\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.004382340703159571 with total_loss: 0.1441550685558468\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.005322070326656103 with total_loss: 0.14853740925900638\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.004715791437774897 with total_loss: 0.15385947958566248\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.004692238289862871 with total_loss: 0.15857527102343738\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.004405959974974394 with total_loss: 0.16326750931330025\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.0044645508751273155 with total_loss: 0.16767346928827465\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.006186263170093298 with total_loss: 0.17213802016340196\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.004474964924156666 with total_loss: 0.17832428333349526\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.004229411948472261 with total_loss: 0.18279924825765193\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.0035685517359524965 with total_loss: 0.1870286602061242\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.0038913998287171125 with total_loss: 0.19059721194207668\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.004792553372681141 with total_loss: 0.1944886117707938\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.0075021833181381226 with total_loss: 0.19928116514347494\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.004742099903523922 with total_loss: 0.20678334846161306\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.00525086373090744 with total_loss: 0.21152544836513698\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.0038769671227782965 with total_loss: 0.21677631209604442\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.005713732913136482 with total_loss: 0.22065327921882272\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.00473982747644186 with total_loss: 0.2263670121319592\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.005386076867580414 with total_loss: 0.23110683960840106\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.004011768847703934 with total_loss: 0.23649291647598147\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.003619904862716794 with total_loss: 0.2405046853236854\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.0045003388077020645 with total_loss: 0.2441245901864022\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.004318005871027708 with total_loss: 0.24862492899410427\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.0051203700713813305 with total_loss: 0.252942934865132\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.005280451383441687 with total_loss: 0.2580633049365133\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.005273319780826569 with total_loss: 0.263343756319955\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.004400951322168112 with total_loss: 0.26861707610078156\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.007167944218963385 with total_loss: 0.27301802742294967\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.006529028061777353 with total_loss: 0.28018597164191306\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.006379071623086929 with total_loss: 0.2867149997036904\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.005245843902230263 with total_loss: 0.29309407132677734\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.0034790057688951492 with total_loss: 0.2983399152290076\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.0037720815744251013 with total_loss: 0.30181892099790275\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.0031873825937509537 with total_loss: 0.30559100257232785\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.005259133875370026 with total_loss: 0.3087783851660788\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.005752757657319307 with total_loss: 0.31403751904144883\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.0052357688546180725 with total_loss: 0.31979027669876814\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.003884563222527504 with total_loss: 0.3250260455533862\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.003150867996737361 with total_loss: 0.3289106087759137\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.003160833613947034 with total_loss: 0.3320614767726511\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.0034775312524288893 with total_loss: 0.3352223103865981\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.004387797322124243 with total_loss: 0.338699841639027\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.0033787440042942762 with total_loss: 0.34308763896115124\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.004372617695480585 with total_loss: 0.3464663829654455\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.0033535112161189318 with total_loss: 0.3508390006609261\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.0036436959635466337 with total_loss: 0.35419251187704504\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.004427812527865171 with total_loss: 0.35783620784059167\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.003968336153775454 with total_loss: 0.36226402036845684\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.004033923614770174 with total_loss: 0.3662323565222323\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.003734637750312686 with total_loss: 0.37026628013700247\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.004156575072556734 with total_loss: 0.37400091788731515\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0039555407129228115 with total_loss: 0.3781574929598719\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.00345254666171968 with total_loss: 0.3821130336727947\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.004408734384924173 with total_loss: 0.3855655803345144\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.003850974142551422 with total_loss: 0.38997431471943855\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.005452305544167757 with total_loss: 0.39382528886199\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.00337614375166595 with total_loss: 0.39927759440615773\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.004733292385935783 with total_loss: 0.4026537381578237\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.0026985816657543182 with total_loss: 0.40738703054375947\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 37 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.003488510847091675 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.0031944841612130404 with total_loss: 0.003488510847091675\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.004106896463781595 with total_loss: 0.006682995008304715\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.0038944140542298555 with total_loss: 0.01078989147208631\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.004075640346854925 with total_loss: 0.014684305526316166\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.003490784438326955 with total_loss: 0.01875994587317109\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.00402211956679821 with total_loss: 0.022250730311498046\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.003024967387318611 with total_loss: 0.026272849878296256\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.004432817921042442 with total_loss: 0.029297817265614867\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.004587128758430481 with total_loss: 0.03373063518665731\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.004513686057180166 with total_loss: 0.03831776394508779\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.005304072517901659 with total_loss: 0.04283145000226796\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.0043744598515331745 with total_loss: 0.048135522520169616\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.003403403563424945 with total_loss: 0.05250998237170279\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.0032886744011193514 with total_loss: 0.055913385935127735\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.012269091792404652 with total_loss: 0.059202060336247087\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.007915285415947437 with total_loss: 0.07147115212865174\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.003656877903267741 with total_loss: 0.07938643754459918\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.004610537085682154 with total_loss: 0.08304331544786692\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.004425263497978449 with total_loss: 0.08765385253354907\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.003852316876873374 with total_loss: 0.09207911603152752\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.0028662465047091246 with total_loss: 0.0959314329084009\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.005066512618213892 with total_loss: 0.09879767941311002\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.0035459764767438173 with total_loss: 0.10386419203132391\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.004308224655687809 with total_loss: 0.10741016850806773\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.0031139261554926634 with total_loss: 0.11171839316375554\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.004854022525250912 with total_loss: 0.1148323193192482\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.004231473430991173 with total_loss: 0.11968634184449911\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.003988987300544977 with total_loss: 0.12391781527549028\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.0030801650136709213 with total_loss: 0.12790680257603526\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.0039815716445446014 with total_loss: 0.13098696758970618\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.00654376158490777 with total_loss: 0.13496853923425078\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.0061154854483902454 with total_loss: 0.14151230081915855\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.0046998560428619385 with total_loss: 0.1476277862675488\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.005264987703412771 with total_loss: 0.15232764231041074\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.00754303066059947 with total_loss: 0.1575926300138235\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.004725893959403038 with total_loss: 0.16513566067442298\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.005536366254091263 with total_loss: 0.16986155463382602\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.005648646503686905 with total_loss: 0.17539792088791728\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.005810193717479706 with total_loss: 0.18104656739160419\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.006573012564331293 with total_loss: 0.1868567611090839\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.004819128662347794 with total_loss: 0.19342977367341518\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.006027026101946831 with total_loss: 0.19824890233576298\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.0038450779393315315 with total_loss: 0.2042759284377098\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.004463324323296547 with total_loss: 0.20812100637704134\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.004087838344275951 with total_loss: 0.2125843307003379\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.00452541746199131 with total_loss: 0.21667216904461384\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.004293296951800585 with total_loss: 0.22119758650660515\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.005310382694005966 with total_loss: 0.22549088345840573\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.004249537363648415 with total_loss: 0.2308012661524117\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.004900437314063311 with total_loss: 0.23505080351606011\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.0038473522290587425 with total_loss: 0.23995124083012342\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.0038671584334224463 with total_loss: 0.24379859305918217\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.005468075629323721 with total_loss: 0.2476657514926046\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.004626398906111717 with total_loss: 0.25313382712192833\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.003696414874866605 with total_loss: 0.25776022602804005\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.004035018850117922 with total_loss: 0.26145664090290666\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.004488475155085325 with total_loss: 0.2654916597530246\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.004696411546319723 with total_loss: 0.2699801349081099\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.015657177194952965 with total_loss: 0.2746765464544296\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.0053612119518220425 with total_loss: 0.2903337236493826\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.004127496387809515 with total_loss: 0.29569493560120463\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.005210807081311941 with total_loss: 0.29982243198901415\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.004282831680029631 with total_loss: 0.3050332390703261\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.004722416866570711 with total_loss: 0.3093160707503557\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.0033643655478954315 with total_loss: 0.31403848761692643\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.004215055610984564 with total_loss: 0.31740285316482186\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.0029562616255134344 with total_loss: 0.3216179087758064\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.0037940621841698885 with total_loss: 0.32457417040131986\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.003926742356270552 with total_loss: 0.32836823258548975\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.004927326459437609 with total_loss: 0.3322949749417603\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.003032619133591652 with total_loss: 0.3372223014011979\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.002911451505497098 with total_loss: 0.34025492053478956\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.003629723796620965 with total_loss: 0.34316637204028666\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.0039295111782848835 with total_loss: 0.3467960958369076\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.0036675548180937767 with total_loss: 0.3507256070151925\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.005001936573535204 with total_loss: 0.3543931618332863\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.003913871478289366 with total_loss: 0.3593950984068215\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.003984580747783184 with total_loss: 0.36330896988511086\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.0033444995060563087 with total_loss: 0.36729355063289404\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.002689934568479657 with total_loss: 0.37063805013895035\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.0033571338281035423 with total_loss: 0.37332798470743\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.004797013010829687 with total_loss: 0.37668511853553355\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.0031313567887991667 with total_loss: 0.38148213154636323\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.0036410323809832335 with total_loss: 0.3846134883351624\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.0037838693242520094 with total_loss: 0.38825452071614563\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0047920276410877705 with total_loss: 0.39203839004039764\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.003164749825373292 with total_loss: 0.3968304176814854\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.003526209155097604 with total_loss: 0.3999951675068587\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.0031266342848539352 with total_loss: 0.4035213766619563\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.003977768588811159 with total_loss: 0.40664801094681025\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.004435941111296415 with total_loss: 0.4106257795356214\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.004531241487711668 with total_loss: 0.4150617206469178\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.0032220156863331795 with total_loss: 0.4195929621346295\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 38 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.0037415737751871347 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.003881587414070964 with total_loss: 0.0037415737751871347\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.0033713632728904486 with total_loss: 0.007623161189258099\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.0038373684510588646 with total_loss: 0.010994524462148547\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.008972414769232273 with total_loss: 0.014831892913207412\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.003545583225786686 with total_loss: 0.023804307682439685\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.0046447888016700745 with total_loss: 0.02734989090822637\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.0028162014205008745 with total_loss: 0.031994679709896445\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.0034023821353912354 with total_loss: 0.03481088113039732\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.004514157306402922 with total_loss: 0.038213263265788555\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.0030220106709748507 with total_loss: 0.04272742057219148\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.0038474046159535646 with total_loss: 0.04574943124316633\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.0033660593908280134 with total_loss: 0.04959683585911989\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.003832868067547679 with total_loss: 0.052962895249947906\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.002903393702581525 with total_loss: 0.056795763317495584\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.004158198367804289 with total_loss: 0.05969915702007711\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.0032669564243406057 with total_loss: 0.0638573553878814\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.004620672669261694 with total_loss: 0.067124311812222\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.004573537036776543 with total_loss: 0.0717449844814837\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.004238196182996035 with total_loss: 0.07631852151826024\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.002628479152917862 with total_loss: 0.08055671770125628\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.004388271365314722 with total_loss: 0.08318519685417414\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.003920108545571566 with total_loss: 0.08757346821948886\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.0036746172700077295 with total_loss: 0.09149357676506042\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.002958715194836259 with total_loss: 0.09516819403506815\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.0032990884501487017 with total_loss: 0.09812690922990441\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.0030494460370391607 with total_loss: 0.10142599768005311\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.003475821577012539 with total_loss: 0.10447544371709228\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.0028985291719436646 with total_loss: 0.10795126529410481\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.003895968897268176 with total_loss: 0.11084979446604848\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.004238194320350885 with total_loss: 0.11474576336331666\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.0054241567850112915 with total_loss: 0.11898395768366754\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.005507282447069883 with total_loss: 0.12440811446867883\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.004746500868350267 with total_loss: 0.12991539691574872\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.0038809338584542274 with total_loss: 0.13466189778409898\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.007384670898318291 with total_loss: 0.1385428316425532\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.004034759942442179 with total_loss: 0.1459275025408715\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.004725589416921139 with total_loss: 0.14996226248331368\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.005669792648404837 with total_loss: 0.15468785190023482\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.004422159865498543 with total_loss: 0.16035764454863966\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.0068413205444812775 with total_loss: 0.1647798044141382\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.006868151947855949 with total_loss: 0.17162112495861948\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.004945109132677317 with total_loss: 0.17848927690647542\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.005168796982616186 with total_loss: 0.18343438603915274\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.0027711426373571157 with total_loss: 0.18860318302176893\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.0038471240550279617 with total_loss: 0.19137432565912604\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.00519412150606513 with total_loss: 0.195221449714154\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.004959458950906992 with total_loss: 0.20041557122021914\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.005136316176503897 with total_loss: 0.20537503017112613\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.004045277368277311 with total_loss: 0.21051134634763002\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.003181321546435356 with total_loss: 0.21455662371590734\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.0035549625754356384 with total_loss: 0.2177379452623427\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.004709405358880758 with total_loss: 0.22129290783777833\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.006605390924960375 with total_loss: 0.2260023131966591\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.006986441556364298 with total_loss: 0.23260770412161946\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.004107080399990082 with total_loss: 0.23959414567798376\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.004500977694988251 with total_loss: 0.24370122607797384\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.0037640000227838755 with total_loss: 0.2482022037729621\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.005792112555354834 with total_loss: 0.25196620379574597\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.014082533307373524 with total_loss: 0.2577583163511008\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.003233684226870537 with total_loss: 0.2718408496584743\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.003702410263940692 with total_loss: 0.27507453388534486\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.004113898146897554 with total_loss: 0.27877694414928555\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.004714577924460173 with total_loss: 0.2828908422961831\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.004396870732307434 with total_loss: 0.2876054202206433\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.0038818717002868652 with total_loss: 0.2920022909529507\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.0032757725566625595 with total_loss: 0.2958841626532376\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.0032755627762526274 with total_loss: 0.29915993520990014\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.003664192510768771 with total_loss: 0.30243549798615277\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.0034961027558892965 with total_loss: 0.30609969049692154\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.004352280870079994 with total_loss: 0.30959579325281084\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.00950744841247797 with total_loss: 0.31394807412289083\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.00382613274268806 with total_loss: 0.3234555225353688\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.0047386945225298405 with total_loss: 0.32728165527805686\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.004479847848415375 with total_loss: 0.3320203498005867\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.0038447759579867125 with total_loss: 0.3365001976490021\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.002914733486250043 with total_loss: 0.3403449736069888\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.0028403413016349077 with total_loss: 0.34325970709323883\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.002730501117184758 with total_loss: 0.34610004839487374\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.003504314459860325 with total_loss: 0.3488305495120585\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.0035859784111380577 with total_loss: 0.3523348639719188\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.003288673236966133 with total_loss: 0.3559208423830569\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.0037031546235084534 with total_loss: 0.359209515620023\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.004487288650125265 with total_loss: 0.36291267024353147\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.0037836625706404448 with total_loss: 0.36739995889365673\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.003507771296426654 with total_loss: 0.3711836214642972\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0029502185061573982 with total_loss: 0.37469139276072383\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.003941163886338472 with total_loss: 0.3776416112668812\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.0044961352832615376 with total_loss: 0.3815827751532197\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.0038398941978812218 with total_loss: 0.38607891043648124\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.003835295559838414 with total_loss: 0.38991880463436246\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.002961810678243637 with total_loss: 0.3937541001942009\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.003499808721244335 with total_loss: 0.3967159108724445\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.003203170606866479 with total_loss: 0.40021571959368885\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 39 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.0035572275519371033 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.0035100013483315706 with total_loss: 0.0035572275519371033\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.004675454925745726 with total_loss: 0.007067228900268674\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.0033531079534441233 with total_loss: 0.0117426838260144\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.004508134443312883 with total_loss: 0.015095791779458523\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.0034663446713238955 with total_loss: 0.019603926222771406\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.003611745312809944 with total_loss: 0.0230702708940953\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.0036621782928705215 with total_loss: 0.026682016206905246\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.0032687904313206673 with total_loss: 0.030344194499775767\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.003797154873609543 with total_loss: 0.033612984931096435\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.003968947567045689 with total_loss: 0.03741013980470598\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.0028156936168670654 with total_loss: 0.041379087371751666\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.002806623699143529 with total_loss: 0.04419478098861873\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.003844828112050891 with total_loss: 0.04700140468776226\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.003638572758063674 with total_loss: 0.05084623279981315\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.0034428928047418594 with total_loss: 0.054484805557876825\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.0033173076808452606 with total_loss: 0.057927698362618685\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.0032274657860398293 with total_loss: 0.061245006043463945\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.004569096025079489 with total_loss: 0.06447247182950377\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.003518433542922139 with total_loss: 0.06904156785458326\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.003817203687503934 with total_loss: 0.0725600013975054\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.004599608015269041 with total_loss: 0.07637720508500934\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.0040678661316633224 with total_loss: 0.08097681310027838\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.0030442446004599333 with total_loss: 0.0850446792319417\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.004196401219815016 with total_loss: 0.08808892383240163\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.004511499311774969 with total_loss: 0.09228532505221665\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.0035011882428079844 with total_loss: 0.09679682436399162\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.004074940923601389 with total_loss: 0.1002980126067996\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.003889703191816807 with total_loss: 0.10437295353040099\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.003110454184934497 with total_loss: 0.1082626567222178\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.0028223441913723946 with total_loss: 0.1113731109071523\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.004069183021783829 with total_loss: 0.11419545509852469\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.009019340388476849 with total_loss: 0.11826463812030852\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.004713072907179594 with total_loss: 0.12728397850878537\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.003664938732981682 with total_loss: 0.13199705141596496\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.004256353247910738 with total_loss: 0.13566199014894664\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.0037614628672599792 with total_loss: 0.13991834339685738\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.004524126648902893 with total_loss: 0.14367980626411736\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.004124793224036694 with total_loss: 0.14820393291302025\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.005400302354246378 with total_loss: 0.15232872613705695\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.004321080166846514 with total_loss: 0.15772902849130332\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.003642125055193901 with total_loss: 0.16205010865814984\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.004559256136417389 with total_loss: 0.16569223371334374\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.004785339813679457 with total_loss: 0.17025148984976113\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.004773896653205156 with total_loss: 0.17503682966344059\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.0037854064721614122 with total_loss: 0.17981072631664574\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.0034742197021842003 with total_loss: 0.18359613278880715\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.004154015798121691 with total_loss: 0.18707035249099135\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.0039341333322227 with total_loss: 0.19122436828911304\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.004647047724574804 with total_loss: 0.19515850162133574\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.004348216112703085 with total_loss: 0.19980554934591055\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.005079067777842283 with total_loss: 0.20415376545861363\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.004463201854377985 with total_loss: 0.20923283323645592\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.0032202068250626326 with total_loss: 0.2136960350908339\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.0051149786449968815 with total_loss: 0.21691624191589653\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.004922221414744854 with total_loss: 0.22203122056089342\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.0040059988386929035 with total_loss: 0.22695344197563827\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.004159807227551937 with total_loss: 0.23095944081433117\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.00580652104690671 with total_loss: 0.2351192480418831\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.0027190980035811663 with total_loss: 0.24092576908878982\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.002957233227789402 with total_loss: 0.243644867092371\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.003718583146110177 with total_loss: 0.2466021003201604\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.004550995770841837 with total_loss: 0.25032068346627057\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.004464761819690466 with total_loss: 0.2548716792371124\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.004550456535071135 with total_loss: 0.25933644105680287\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.003736468032002449 with total_loss: 0.263886897591874\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.003910211380571127 with total_loss: 0.26762336562387645\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.0034397009294480085 with total_loss: 0.2715335770044476\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.004254154395312071 with total_loss: 0.2749732779338956\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.004373850766569376 with total_loss: 0.27922743232920766\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.005310633685439825 with total_loss: 0.28360128309577703\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.004356288816779852 with total_loss: 0.28891191678121686\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.0035970162134617567 with total_loss: 0.2932682055979967\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.003168749623000622 with total_loss: 0.29686522181145847\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.004000266548246145 with total_loss: 0.3000339714344591\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.004492260981351137 with total_loss: 0.30403423798270524\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.004393300507217646 with total_loss: 0.3085264989640564\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.0033809884916990995 with total_loss: 0.312919799471274\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.004223165567964315 with total_loss: 0.3163007879629731\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.003667239099740982 with total_loss: 0.32052395353093743\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.0032340865582227707 with total_loss: 0.3241911926306784\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.003225910710170865 with total_loss: 0.3274252791889012\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.004198961425572634 with total_loss: 0.33065118989907205\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.0038589276373386383 with total_loss: 0.3348501513246447\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.002820741618052125 with total_loss: 0.3387090789619833\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.003379862755537033 with total_loss: 0.34152982058003545\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0033169568050652742 with total_loss: 0.3449096833355725\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.003442470682784915 with total_loss: 0.34822664014063776\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.003580429358407855 with total_loss: 0.35166911082342267\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.0036200862377882004 with total_loss: 0.3552495401818305\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.003339758375659585 with total_loss: 0.3588696264196187\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.0035248154308646917 with total_loss: 0.3622093847952783\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.004400233272463083 with total_loss: 0.365734200226143\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.004336371086537838 with total_loss: 0.3701344334986061\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 40 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.004432434216141701 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.0032357180025428534 with total_loss: 0.004432434216141701\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.00400608079507947 with total_loss: 0.007668152218684554\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.003876448841765523 with total_loss: 0.011674233013764024\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.0038464851677417755 with total_loss: 0.015550681855529547\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.0034615707118064165 with total_loss: 0.019397167023271322\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.003913294058293104 with total_loss: 0.02285873773507774\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.0040223910473287106 with total_loss: 0.026772031793370843\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.002843804657459259 with total_loss: 0.030794422840699553\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0035051994491368532 with total_loss: 0.03363822749815881\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.002936132252216339 with total_loss: 0.037143426947295666\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.002730871783569455 with total_loss: 0.040079559199512005\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.0029841409996151924 with total_loss: 0.04281043098308146\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0036038870457559824 with total_loss: 0.04579457198269665\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.00519222067669034 with total_loss: 0.049398459028452635\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.004459332209080458 with total_loss: 0.054590679705142975\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.004033220000565052 with total_loss: 0.05905001191422343\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.003392150392755866 with total_loss: 0.06308323191478848\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.0039566257037222385 with total_loss: 0.06647538230754435\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.0034471636172384024 with total_loss: 0.07043200801126659\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.0035287849605083466 with total_loss: 0.07387917162850499\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.0023665849585086107 with total_loss: 0.07740795658901334\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.0038539674133062363 with total_loss: 0.07977454154752195\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.004192247521132231 with total_loss: 0.08362850896082819\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.003527076682075858 with total_loss: 0.08782075648196042\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.002804167801514268 with total_loss: 0.09134783316403627\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.0032578047830611467 with total_loss: 0.09415200096555054\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.0031961894128471613 with total_loss: 0.09740980574861169\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.003019714029505849 with total_loss: 0.10060599516145885\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.0029134636279195547 with total_loss: 0.1036257091909647\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.004832003731280565 with total_loss: 0.10653917281888425\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.006274805869907141 with total_loss: 0.11137117655016482\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.005533397197723389 with total_loss: 0.11764598242007196\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.005074623040854931 with total_loss: 0.12317937961779535\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.004611508455127478 with total_loss: 0.12825400265865028\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.0034293585922569036 with total_loss: 0.13286551111377776\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.004464081022888422 with total_loss: 0.13629486970603466\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.003821803256869316 with total_loss: 0.14075895072892308\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.004832350183278322 with total_loss: 0.1445807539857924\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.0028304492589086294 with total_loss: 0.14941310416907072\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.004809500649571419 with total_loss: 0.15224355342797935\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.004351580049842596 with total_loss: 0.15705305407755077\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.006825510878115892 with total_loss: 0.16140463412739336\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.004815711174160242 with total_loss: 0.16823014500550926\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.0036706922110170126 with total_loss: 0.1730458561796695\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.004339413717389107 with total_loss: 0.1767165483906865\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.004640141036361456 with total_loss: 0.18105596210807562\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.0034613951575011015 with total_loss: 0.18569610314443707\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.0037661027163267136 with total_loss: 0.18915749830193818\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.00516695948317647 with total_loss: 0.1929236010182649\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.0046984045766294 with total_loss: 0.19809056050144136\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.005927782505750656 with total_loss: 0.20278896507807076\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.0038151778280735016 with total_loss: 0.20871674758382142\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.004976479336619377 with total_loss: 0.21253192541189492\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.005124581512063742 with total_loss: 0.2175084047485143\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.003592514665797353 with total_loss: 0.22263298626057804\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.0030703030060976744 with total_loss: 0.2262255009263754\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.002920799655839801 with total_loss: 0.22929580393247306\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.003980930428951979 with total_loss: 0.23221660358831286\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.0033332586754113436 with total_loss: 0.23619753401726484\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.0036427397280931473 with total_loss: 0.2395307926926762\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.0036288790870457888 with total_loss: 0.24317353242076933\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.0031107717659324408 with total_loss: 0.24680241150781512\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.0031805012840777636 with total_loss: 0.24991318327374756\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.003461427753791213 with total_loss: 0.2530936845578253\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.004532577004283667 with total_loss: 0.25655511231161654\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.003121632384136319 with total_loss: 0.2610876893159002\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.01798541471362114 with total_loss: 0.2642093217000365\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.0038595034275203943 with total_loss: 0.28219473641365767\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.0038804688956588507 with total_loss: 0.28605423984117806\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.0031436861027032137 with total_loss: 0.2899347087368369\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.005230369046330452 with total_loss: 0.2930783948395401\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.00474911741912365 with total_loss: 0.2983087638858706\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.0038213080260902643 with total_loss: 0.3030578813049942\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.0037391253281384706 with total_loss: 0.3068791893310845\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.004669933579862118 with total_loss: 0.31061831465922296\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.0035615686792880297 with total_loss: 0.3152882482390851\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.0037041811738163233 with total_loss: 0.3188498169183731\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.002951049478724599 with total_loss: 0.32255399809218943\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.007154169026762247 with total_loss: 0.32550504757091403\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.0038601995911449194 with total_loss: 0.3326592165976763\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.003006529761478305 with total_loss: 0.3365194161888212\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.004179727751761675 with total_loss: 0.3395259459502995\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.004641505423933268 with total_loss: 0.3437056737020612\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.0029979415703564882 with total_loss: 0.34834717912599444\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.002892813878133893 with total_loss: 0.35134512069635093\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.003685152856633067 with total_loss: 0.3542379345744848\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.0033379346132278442 with total_loss: 0.3579230874311179\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.003337157191708684 with total_loss: 0.36126102204434574\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.0037770885974168777 with total_loss: 0.3645981792360544\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.0032280615996569395 with total_loss: 0.3683752678334713\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.004014911595731974 with total_loss: 0.37160332943312824\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.0028757306281477213 with total_loss: 0.3756182410288602\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.0029304625932127237 with total_loss: 0.37849397165700793\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 41 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.0033041825518012047 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.002466463251039386 with total_loss: 0.0033041825518012047\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.0025528522673994303 with total_loss: 0.0057706458028405905\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.00437944708392024 with total_loss: 0.00832349807024002\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.00296672317199409 with total_loss: 0.012702945154160261\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.002578416606411338 with total_loss: 0.01566966832615435\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.0034141663927584887 with total_loss: 0.01824808493256569\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.0036336828488856554 with total_loss: 0.021662251325324178\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.002946414053440094 with total_loss: 0.025295934174209833\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0027860437985509634 with total_loss: 0.028242348227649927\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.0036690563429147005 with total_loss: 0.03102839202620089\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.0038170721381902695 with total_loss: 0.03469744836911559\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.003725201589986682 with total_loss: 0.03851452050730586\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0036005268339067698 with total_loss: 0.04223972209729254\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.0033822152763605118 with total_loss: 0.04584024893119931\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.004388047847896814 with total_loss: 0.049222464207559824\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.003900613635778427 with total_loss: 0.05361051205545664\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.0026826474349945784 with total_loss: 0.057511125691235065\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.0039758398197591305 with total_loss: 0.060193773126229644\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.002968312008306384 with total_loss: 0.06416961294598877\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.0026896304916590452 with total_loss: 0.06713792495429516\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.003921085502952337 with total_loss: 0.0698275554459542\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.0035062481183558702 with total_loss: 0.07374864094890654\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.0037333357613533735 with total_loss: 0.07725488906726241\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0034468777012079954 with total_loss: 0.08098822482861578\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.004374621901661158 with total_loss: 0.08443510252982378\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.002933141076937318 with total_loss: 0.08880972443148494\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.003245672909542918 with total_loss: 0.09174286550842226\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.00311955064535141 with total_loss: 0.09498853841796517\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.004750998690724373 with total_loss: 0.09810808906331658\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.0036778051871806383 with total_loss: 0.10285908775404096\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.0039061547722667456 with total_loss: 0.1065368929412216\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.004432015120983124 with total_loss: 0.11044304771348834\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.010573864914476871 with total_loss: 0.11487506283447146\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.0056777396239340305 with total_loss: 0.12544892774894834\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.004240224603563547 with total_loss: 0.13112666737288237\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.005187972914427519 with total_loss: 0.1353668919764459\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.005543597042560577 with total_loss: 0.14055486489087343\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.0062975287437438965 with total_loss: 0.146098461933434\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.004640225786715746 with total_loss: 0.1523959906771779\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.004622073378413916 with total_loss: 0.15703621646389365\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.005281155463308096 with total_loss: 0.16165828984230757\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.0046135373413562775 with total_loss: 0.16693944530561566\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.007777055259793997 with total_loss: 0.17155298264697194\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.0031493885908275843 with total_loss: 0.17933003790676594\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.0048192269168794155 with total_loss: 0.18247942649759352\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.004799506161361933 with total_loss: 0.18729865341447294\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.0040377285331487656 with total_loss: 0.19209815957583487\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.003992125857621431 with total_loss: 0.19613588810898364\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.0038362189661711454 with total_loss: 0.20012801396660507\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.005298302974551916 with total_loss: 0.2039642329327762\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.0038446488324552774 with total_loss: 0.20926253590732813\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.0035433629527688026 with total_loss: 0.2131071847397834\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.0033287506084889174 with total_loss: 0.2166505476925522\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.004285439848899841 with total_loss: 0.21997929830104113\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.004087971057742834 with total_loss: 0.22426473814994097\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.0032061245292425156 with total_loss: 0.2283527092076838\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.0053761606104671955 with total_loss: 0.23155883373692632\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.005752644035965204 with total_loss: 0.2369349943473935\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.004154463764280081 with total_loss: 0.24268763838335872\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.004792835097759962 with total_loss: 0.2468421021476388\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.0036323985550552607 with total_loss: 0.25163493724539876\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.0030988138169050217 with total_loss: 0.255267335800454\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.003264632076025009 with total_loss: 0.25836614961735904\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.0036038828548043966 with total_loss: 0.26163078169338405\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.0036282185465097427 with total_loss: 0.26523466454818845\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.004097245167940855 with total_loss: 0.2688628830946982\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.003670988604426384 with total_loss: 0.27296012826263905\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.003983830567449331 with total_loss: 0.27663111686706543\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.0038175685331225395 with total_loss: 0.28061494743451476\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.002879905514419079 with total_loss: 0.2844325159676373\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.0033634027931839228 with total_loss: 0.2873124214820564\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.004489808809012175 with total_loss: 0.2906758242752403\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.0033584528136998415 with total_loss: 0.2951656330842525\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.0032792307902127504 with total_loss: 0.2985240858979523\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.004688518587499857 with total_loss: 0.30180331668816507\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.0033602938055992126 with total_loss: 0.3064918352756649\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.004827673081308603 with total_loss: 0.30985212908126414\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.0029194361995905638 with total_loss: 0.31467980216257274\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.0036357417702674866 with total_loss: 0.3175992383621633\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.003814552677795291 with total_loss: 0.3212349801324308\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.00302653550170362 with total_loss: 0.3250495328102261\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.0031614743638783693 with total_loss: 0.3280760683119297\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.0049332305788993835 with total_loss: 0.33123754267580807\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.004491486120969057 with total_loss: 0.33617077325470746\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.003625730751082301 with total_loss: 0.3406622593756765\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0034564987290650606 with total_loss: 0.3442879901267588\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.0029791623819619417 with total_loss: 0.3477444888558239\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.0028705212753266096 with total_loss: 0.3507236512377858\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.0035925547126680613 with total_loss: 0.3535941725131124\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.0035267930943518877 with total_loss: 0.3571867272257805\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.0034542102366685867 with total_loss: 0.3607135203201324\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.0031859849113970995 with total_loss: 0.36416773055680096\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.0031561932992190123 with total_loss: 0.36735371546819806\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 42 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.003890843829140067 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.003662610426545143 with total_loss: 0.003890843829140067\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.0025596923660486937 with total_loss: 0.00755345425568521\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.0033264292869716883 with total_loss: 0.010113146621733904\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.004875803831964731 with total_loss: 0.013439575908705592\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.0023261054884642363 with total_loss: 0.018315379740670323\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.003678213572129607 with total_loss: 0.02064148522913456\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.0035994055215269327 with total_loss: 0.024319698801264167\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.0029950032476335764 with total_loss: 0.0279191043227911\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0034251397009938955 with total_loss: 0.030914107570424676\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.002912794006988406 with total_loss: 0.03433924727141857\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.003547394648194313 with total_loss: 0.03725204127840698\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.004612103570252657 with total_loss: 0.04079943592660129\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.004777801688760519 with total_loss: 0.04541153949685395\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.002576311118900776 with total_loss: 0.05018934118561447\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.003927602898329496 with total_loss: 0.05276565230451524\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.0033694945741444826 with total_loss: 0.05669325520284474\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.004290119744837284 with total_loss: 0.06006274977698922\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.004035455174744129 with total_loss: 0.0643528695218265\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.0037793696392327547 with total_loss: 0.06838832469657063\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.0026257717981934547 with total_loss: 0.07216769433580339\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.0046158297918736935 with total_loss: 0.07479346613399684\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.0038061507511883974 with total_loss: 0.07940929592587054\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.0030929334461688995 with total_loss: 0.08321544667705894\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0031816165428608656 with total_loss: 0.08630838012322783\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.0037725858855992556 with total_loss: 0.0894899966660887\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.0031334590166807175 with total_loss: 0.09326258255168796\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.002318392740562558 with total_loss: 0.09639604156836867\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.003832625923678279 with total_loss: 0.09871443430893123\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.0030083886813372374 with total_loss: 0.10254706023260951\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.003953120205551386 with total_loss: 0.10555544891394675\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.005030611529946327 with total_loss: 0.10950856911949813\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.00521730026230216 with total_loss: 0.11453918064944446\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.0053293113596737385 with total_loss: 0.11975648091174662\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.004912002012133598 with total_loss: 0.12508579227142036\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.0032949785236269236 with total_loss: 0.12999779428355396\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.006183348596096039 with total_loss: 0.13329277280718088\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.0037827419582754374 with total_loss: 0.13947612140327692\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.004017329309135675 with total_loss: 0.14325886336155236\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.005128804594278336 with total_loss: 0.14727619267068803\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.005587138235569 with total_loss: 0.15240499726496637\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.003619389608502388 with total_loss: 0.15799213550053537\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.005301433149725199 with total_loss: 0.16161152510903776\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.004951257724314928 with total_loss: 0.16691295825876296\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.005379820242524147 with total_loss: 0.17186421598307788\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.003783348947763443 with total_loss: 0.17724403622560203\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.00408213259652257 with total_loss: 0.18102738517336547\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.006276553031057119 with total_loss: 0.18510951776988804\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.005543118808418512 with total_loss: 0.19138607080094516\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.004486560821533203 with total_loss: 0.19692918960936368\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.004082286264747381 with total_loss: 0.20141575043089688\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.0055244299583137035 with total_loss: 0.20549803669564426\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.004969786386936903 with total_loss: 0.21102246665395796\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.0036016430240124464 with total_loss: 0.21599225304089487\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.004950019996613264 with total_loss: 0.2195938960649073\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.004221359733492136 with total_loss: 0.22454391606152058\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.004545977339148521 with total_loss: 0.2287652757950127\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.004029288422316313 with total_loss: 0.23331125313416123\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.004981675185263157 with total_loss: 0.23734054155647755\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.005141808185726404 with total_loss: 0.2423222167417407\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.0042108031921088696 with total_loss: 0.2474640249274671\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.005375849548727274 with total_loss: 0.251674828119576\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.004142897669225931 with total_loss: 0.25705067766830325\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.003937126602977514 with total_loss: 0.2611935753375292\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.0034715058282017708 with total_loss: 0.2651307019405067\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.0035457478370517492 with total_loss: 0.26860220776870847\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.0026261804159730673 with total_loss: 0.2721479556057602\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.003778429003432393 with total_loss: 0.2747741360217333\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.004779390525072813 with total_loss: 0.2785525650251657\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.003563143312931061 with total_loss: 0.2833319555502385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.004275707062333822 with total_loss: 0.28689509886316955\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.0033325161784887314 with total_loss: 0.2911708059255034\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.0035368986427783966 with total_loss: 0.2945033221039921\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.0033512853551656008 with total_loss: 0.2980402207467705\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.003373837796971202 with total_loss: 0.3013915061019361\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.003753150813281536 with total_loss: 0.3047653438989073\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.0037998147308826447 with total_loss: 0.30851849471218884\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.0037133556324988604 with total_loss: 0.3123183094430715\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.004292475525289774 with total_loss: 0.31603166507557034\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.0025111509021371603 with total_loss: 0.3203241406008601\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.003257323056459427 with total_loss: 0.3228352915029973\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.0035069298464804888 with total_loss: 0.3260926145594567\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.0037080973852425814 with total_loss: 0.3295995444059372\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.002428440609946847 with total_loss: 0.3333076417911798\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.003884635865688324 with total_loss: 0.3357360824011266\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.003455593017861247 with total_loss: 0.33962071826681495\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0035476938355714083 with total_loss: 0.3430763112846762\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.0030993977561593056 with total_loss: 0.3466240051202476\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.0031023432966321707 with total_loss: 0.3497234028764069\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.004081482533365488 with total_loss: 0.3528257461730391\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.0032588138710707426 with total_loss: 0.35690722870640457\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.0038861006032675505 with total_loss: 0.3601660425774753\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.004382651299238205 with total_loss: 0.36405214318074286\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.0028187325224280357 with total_loss: 0.36843479447998106\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 43 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.003379062982276082 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.0032541335094720125 with total_loss: 0.003379062982276082\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.002560722641646862 with total_loss: 0.0066331964917480946\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.00358567270450294 with total_loss: 0.009193919133394957\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.0027757196221500635 with total_loss: 0.012779591837897897\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.002566732931882143 with total_loss: 0.01555531146004796\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.0038385808002203703 with total_loss: 0.018122044391930103\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.004123987630009651 with total_loss: 0.021960625192150474\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.0026449605356901884 with total_loss: 0.026084612822160125\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0027744509279727936 with total_loss: 0.028729573357850313\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.003258880926296115 with total_loss: 0.03150402428582311\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.004150927998125553 with total_loss: 0.03476290521211922\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.0035962823312729597 with total_loss: 0.038913833210244775\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0028322970028966665 with total_loss: 0.042510115541517735\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.003807206405326724 with total_loss: 0.0453424125444144\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.003893011948093772 with total_loss: 0.049149618949741125\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.0032291815150529146 with total_loss: 0.0530426308978349\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.0026728406082838774 with total_loss: 0.05627181241288781\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.003614935092628002 with total_loss: 0.05894465302117169\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.0031668164301663637 with total_loss: 0.06255958811379969\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.0036131704691797495 with total_loss: 0.06572640454396605\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.003179289400577545 with total_loss: 0.0693395750131458\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.003933533560484648 with total_loss: 0.07251886441372335\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.0034512195270508528 with total_loss: 0.076452397974208\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0029499127995222807 with total_loss: 0.07990361750125885\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.00280792941339314 with total_loss: 0.08285353030078113\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.0036359087098389864 with total_loss: 0.08566145971417427\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.003434383077546954 with total_loss: 0.08929736842401326\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.0032854918390512466 with total_loss: 0.09273175150156021\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.0030449144542217255 with total_loss: 0.09601724334061146\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.00362148298881948 with total_loss: 0.09906215779483318\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.006575824227184057 with total_loss: 0.10268364078365266\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.006765719037503004 with total_loss: 0.10925946501083672\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.004213713575154543 with total_loss: 0.11602518404833972\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.0036349568981677294 with total_loss: 0.12023889762349427\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.0030930519569665194 with total_loss: 0.123873854521662\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.004849528893828392 with total_loss: 0.12696690647862852\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.005494896788150072 with total_loss: 0.1318164353724569\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.00495612109079957 with total_loss: 0.13731133216060698\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.005157186184078455 with total_loss: 0.14226745325140655\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.006098996382206678 with total_loss: 0.147424639435485\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.004364637657999992 with total_loss: 0.15352363581769168\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.004823646042495966 with total_loss: 0.15788827347569168\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.004036849830299616 with total_loss: 0.16271191951818764\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.0034754646476358175 with total_loss: 0.16674876934848726\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.002859602915123105 with total_loss: 0.17022423399612308\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.004413084592670202 with total_loss: 0.17308383691124618\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.007058810442686081 with total_loss: 0.17749692150391638\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.005505361128598452 with total_loss: 0.18455573194660246\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.005006055813282728 with total_loss: 0.19006109307520092\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.004900005180388689 with total_loss: 0.19506714888848364\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.004339899402111769 with total_loss: 0.19996715406887233\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.0038336932193487883 with total_loss: 0.2043070534709841\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.005860503762960434 with total_loss: 0.2081407466903329\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.004557305946946144 with total_loss: 0.21400125045329332\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.004620511084794998 with total_loss: 0.21855855640023947\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.0034968091640621424 with total_loss: 0.22317906748503447\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.0029671110678464174 with total_loss: 0.2266758766490966\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.004591597244143486 with total_loss: 0.22964298771694303\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.0036513127852231264 with total_loss: 0.2342345849610865\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.0035537153016775846 with total_loss: 0.23788589774630964\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.0030257906764745712 with total_loss: 0.24143961304798722\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.002928607864305377 with total_loss: 0.2444654037244618\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.00396620063111186 with total_loss: 0.24739401158876717\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.003965789917856455 with total_loss: 0.25136021221987903\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.00269860471598804 with total_loss: 0.2553260021377355\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.003165273694321513 with total_loss: 0.2580246068537235\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.0028108106926083565 with total_loss: 0.26118988054804504\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.003915234934538603 with total_loss: 0.2640006912406534\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.0020536696538329124 with total_loss: 0.267915926175192\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.0035109396558254957 with total_loss: 0.2699695958290249\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.0036628295201808214 with total_loss: 0.2734805354848504\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.003626994788646698 with total_loss: 0.27714336500503123\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.00493393512442708 with total_loss: 0.2807703597936779\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.0030437149107456207 with total_loss: 0.285704294918105\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.0048879170790314674 with total_loss: 0.2887480098288506\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.004442103672772646 with total_loss: 0.2936359269078821\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.003892836393788457 with total_loss: 0.29807803058065474\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.004488449078053236 with total_loss: 0.3019708669744432\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.0030334501061588526 with total_loss: 0.30645931605249643\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.003017437644302845 with total_loss: 0.3094927661586553\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.004316192120313644 with total_loss: 0.31251020380295813\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.003327286569401622 with total_loss: 0.3168263959232718\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.004447455983608961 with total_loss: 0.3201536824926734\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.0037686012219637632 with total_loss: 0.32460113847628236\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.0036830983590334654 with total_loss: 0.3283697396982461\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0035426353570073843 with total_loss: 0.3320528380572796\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.0039349147118628025 with total_loss: 0.33559547341428697\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.004263583570718765 with total_loss: 0.3395303881261498\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.002609961898997426 with total_loss: 0.34379397169686854\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.005164712201803923 with total_loss: 0.34640393359586596\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.0034430688247084618 with total_loss: 0.3515686457976699\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.0030639145988970995 with total_loss: 0.35501171462237835\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.002452289219945669 with total_loss: 0.35807562922127545\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 44 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.0040871561504900455 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.0031858356669545174 with total_loss: 0.0040871561504900455\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.0027369430754333735 with total_loss: 0.007272991817444563\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.003875465365126729 with total_loss: 0.010009934892877936\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.0039242045022547245 with total_loss: 0.013885400258004665\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.0031420595478266478 with total_loss: 0.01780960476025939\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.003043955424800515 with total_loss: 0.020951664308086038\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.002901737578213215 with total_loss: 0.023995619732886553\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.003266862826421857 with total_loss: 0.026897357311099768\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.003433879464864731 with total_loss: 0.030164220137521625\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.003616299480199814 with total_loss: 0.033598099602386355\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.003152746008709073 with total_loss: 0.03721439908258617\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.004806653596460819 with total_loss: 0.04036714509129524\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.002770906314253807 with total_loss: 0.04517379868775606\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.0039092376828193665 with total_loss: 0.04794470500200987\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.003360505448654294 with total_loss: 0.051853942684829235\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.003371007042005658 with total_loss: 0.05521444813348353\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.004538396839052439 with total_loss: 0.05858545517548919\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.0025028428062796593 with total_loss: 0.06312385201454163\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.0030559219885617495 with total_loss: 0.06562669482082129\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.002714976668357849 with total_loss: 0.06868261680938303\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.0034906677901744843 with total_loss: 0.07139759347774088\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.0036898721009492874 with total_loss: 0.07488826126791537\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.00391694251447916 with total_loss: 0.07857813336886466\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0029245922341942787 with total_loss: 0.08249507588334382\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.004472959320992231 with total_loss: 0.0854196681175381\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.002585269743576646 with total_loss: 0.08989262743853033\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.003822460537776351 with total_loss: 0.09247789718210697\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.003131641773506999 with total_loss: 0.09630035771988332\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.003070468781515956 with total_loss: 0.09943199949339032\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.003554750233888626 with total_loss: 0.10250246827490628\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.005252959672361612 with total_loss: 0.1060572185087949\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.004960985388606787 with total_loss: 0.11131017818115652\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.006094144657254219 with total_loss: 0.1162711635697633\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.007953628897666931 with total_loss: 0.12236530822701752\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.004038596525788307 with total_loss: 0.13031893712468445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.0026970859616994858 with total_loss: 0.13435753365047276\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.007229880895465612 with total_loss: 0.13705461961217225\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.005393104162067175 with total_loss: 0.14428450050763786\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.004752952605485916 with total_loss: 0.14967760466970503\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.005596044007688761 with total_loss: 0.15443055727519095\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.014250385574996471 with total_loss: 0.1600266012828797\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.004736620467156172 with total_loss: 0.17427698685787618\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.004700262565165758 with total_loss: 0.17901360732503235\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.0038018357008695602 with total_loss: 0.1837138698901981\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.0036526352632790804 with total_loss: 0.18751570559106767\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.0036253829021006823 with total_loss: 0.19116834085434675\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.004456522408872843 with total_loss: 0.19479372375644743\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.004009221214801073 with total_loss: 0.19925024616532028\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.004831972066313028 with total_loss: 0.20325946738012135\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.0038136376533657312 with total_loss: 0.20809143944643438\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.0046079992316663265 with total_loss: 0.2119050770998001\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.002783877542242408 with total_loss: 0.21651307633146644\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.004728944972157478 with total_loss: 0.21929695387370884\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.004018526524305344 with total_loss: 0.22402589884586632\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.003374384017661214 with total_loss: 0.22804442537017167\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.004403307568281889 with total_loss: 0.23141880938783288\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.004563889000564814 with total_loss: 0.23582211695611477\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.0025772901717573404 with total_loss: 0.24038600595667958\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.004516983404755592 with total_loss: 0.24296329612843692\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.005974067375063896 with total_loss: 0.24748027953319252\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.0039055764209479094 with total_loss: 0.2534543469082564\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.003582136007025838 with total_loss: 0.2573599233292043\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.004772258456796408 with total_loss: 0.26094205933623016\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.0035134770441800356 with total_loss: 0.26571431779302657\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.0025285810697823763 with total_loss: 0.2692277948372066\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.0032307186629623175 with total_loss: 0.271756375906989\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.00392215047031641 with total_loss: 0.2749870945699513\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.0035757720470428467 with total_loss: 0.2789092450402677\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.003521665232256055 with total_loss: 0.28248501708731055\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.003287816420197487 with total_loss: 0.2860066823195666\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.003778408281505108 with total_loss: 0.2892944987397641\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.0035327032674103975 with total_loss: 0.2930729070212692\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.0036861796397715807 with total_loss: 0.2966056102886796\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.003994901664555073 with total_loss: 0.3002917899284512\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.0037854171823710203 with total_loss: 0.30428669159300625\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.0041524688713252544 with total_loss: 0.3080721087753773\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.0028259276878088713 with total_loss: 0.31222457764670253\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.0042414129711687565 with total_loss: 0.3150505053345114\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.0027118995785713196 with total_loss: 0.31929191830568016\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.0029846031684428453 with total_loss: 0.3220038178842515\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.00457051070407033 with total_loss: 0.3249884210526943\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.00320029747672379 with total_loss: 0.32955893175676465\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.0028815052937716246 with total_loss: 0.33275922923348844\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.003201886313036084 with total_loss: 0.33564073452726007\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.003019167808815837 with total_loss: 0.33884262084029615\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0033441444393247366 with total_loss: 0.341861788649112\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.003117557615041733 with total_loss: 0.3452059330884367\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.003923563286662102 with total_loss: 0.34832349070347846\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.002235555788502097 with total_loss: 0.35224705399014056\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.0031016997527331114 with total_loss: 0.35448260977864265\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.003492753952741623 with total_loss: 0.35758430953137577\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.003815271658822894 with total_loss: 0.3610770634841174\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.003737017046660185 with total_loss: 0.3648923351429403\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 45 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.0034895066637545824 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.0036876611411571503 with total_loss: 0.0034895066637545824\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.0031605868134647608 with total_loss: 0.007177167804911733\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.003447113558650017 with total_loss: 0.010337754618376493\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.003114293096587062 with total_loss: 0.01378486817702651\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.0031189529690891504 with total_loss: 0.016899161273613572\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.003464249661192298 with total_loss: 0.020018114242702723\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.0033027168828994036 with total_loss: 0.02348236390389502\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.003845982952043414 with total_loss: 0.026785080786794424\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.003604768542572856 with total_loss: 0.030631063738837838\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.004003723617643118 with total_loss: 0.034235832281410694\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.0027006398886442184 with total_loss: 0.03823955589905381\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.00272975186817348 with total_loss: 0.04094019578769803\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0034560225903987885 with total_loss: 0.04366994765587151\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.0035333919804543257 with total_loss: 0.0471259702462703\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.009544153697788715 with total_loss: 0.050659362226724625\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.003471692092716694 with total_loss: 0.06020351592451334\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.003926286939531565 with total_loss: 0.06367520801723003\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.0037553173024207354 with total_loss: 0.0676014949567616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.003397790715098381 with total_loss: 0.07135681225918233\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.00289755966514349 with total_loss: 0.07475460297428071\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.0031781282741576433 with total_loss: 0.0776521626394242\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.0031073372811079025 with total_loss: 0.08083029091358185\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.003244483843445778 with total_loss: 0.08393762819468975\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0030728161800652742 with total_loss: 0.08718211203813553\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.0028918825555592775 with total_loss: 0.0902549282182008\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.0037729593459516764 with total_loss: 0.09314681077376008\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.002411958994343877 with total_loss: 0.09691977011971176\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.0029026654083281755 with total_loss: 0.09933172911405563\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.003028739942237735 with total_loss: 0.10223439452238381\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.0029184415470808744 with total_loss: 0.10526313446462154\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.005914869252592325 with total_loss: 0.10818157601170242\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.006225286517292261 with total_loss: 0.11409644526429474\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.005459953099489212 with total_loss: 0.120321731781587\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.0035559935495257378 with total_loss: 0.12578168488107622\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.004990475717931986 with total_loss: 0.12933767843060195\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.05632810294628143 with total_loss: 0.13432815414853394\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.003458690596744418 with total_loss: 0.19065625709481537\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.004362522624433041 with total_loss: 0.1941149476915598\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.00459514232352376 with total_loss: 0.19847747031599283\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.005028709303587675 with total_loss: 0.2030726126395166\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.004835712257772684 with total_loss: 0.20810132194310427\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.006417779251933098 with total_loss: 0.21293703420087695\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.005537318531423807 with total_loss: 0.21935481345281005\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.003466511145234108 with total_loss: 0.22489213198423386\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.0034969598054885864 with total_loss: 0.22835864312946796\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.0035561772529035807 with total_loss: 0.23185560293495655\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.0040230038575828075 with total_loss: 0.23541178018786013\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.003758906153962016 with total_loss: 0.23943478404544294\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.0031275718938559294 with total_loss: 0.24319369019940495\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.003968014847487211 with total_loss: 0.24632126209326088\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.0038937292993068695 with total_loss: 0.2502892769407481\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.00365586020052433 with total_loss: 0.25418300624005497\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.004333100281655788 with total_loss: 0.2578388664405793\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.0037540991324931383 with total_loss: 0.2621719667222351\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.0037774157244712114 with total_loss: 0.2659260658547282\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.004661072511225939 with total_loss: 0.26970348157919943\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.0035458512138575315 with total_loss: 0.27436455409042537\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.002932147355750203 with total_loss: 0.2779104053042829\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.003809179412201047 with total_loss: 0.2808425526600331\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.003054049564525485 with total_loss: 0.28465173207223415\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.005211471114307642 with total_loss: 0.28770578163675964\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.004605694208294153 with total_loss: 0.2929172527510673\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.0043788268230855465 with total_loss: 0.29752294695936143\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.003488203277811408 with total_loss: 0.301901773782447\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.0042516570538282394 with total_loss: 0.3053899770602584\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.0037602956872433424 with total_loss: 0.30964163411408663\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.0030955511610955 with total_loss: 0.31340192980132997\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.004190992098301649 with total_loss: 0.31649748096242547\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.0030986424535512924 with total_loss: 0.3206884730607271\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.004415040370076895 with total_loss: 0.3237871155142784\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.004639607388526201 with total_loss: 0.3282021558843553\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.00268532638438046 with total_loss: 0.3328417632728815\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.0035141196567565203 with total_loss: 0.33552708965726197\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.0037763204891234636 with total_loss: 0.3390412093140185\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.004395778756588697 with total_loss: 0.34281752980314195\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.003625341923907399 with total_loss: 0.34721330855973065\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.003548508742824197 with total_loss: 0.35083865048363805\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.0033253144938498735 with total_loss: 0.35438715922646224\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.0036104728933423758 with total_loss: 0.3577124737203121\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.0027055025566369295 with total_loss: 0.3613229466136545\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.003694474697113037 with total_loss: 0.3640284491702914\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.004977155942469835 with total_loss: 0.36772292386740446\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.003935393411666155 with total_loss: 0.3727000798098743\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.0038230482023209333 with total_loss: 0.37663547322154045\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.0028075193986296654 with total_loss: 0.3804585214238614\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.004023037385195494 with total_loss: 0.38326604082249105\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.0030133118852972984 with total_loss: 0.38728907820768654\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.002271409844979644 with total_loss: 0.39030239009298384\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.004090191796422005 with total_loss: 0.3925737999379635\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.00299794040620327 with total_loss: 0.3966639917343855\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.0033996121492236853 with total_loss: 0.39966193214058876\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.0037649357691407204 with total_loss: 0.40306154428981245\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.0029056421481072903 with total_loss: 0.40682648005895317\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 46 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.003467297414317727 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.002789400750771165 with total_loss: 0.003467297414317727\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.003132767975330353 with total_loss: 0.006256698165088892\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.00341008510440588 with total_loss: 0.009389466140419245\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.0031151622533798218 with total_loss: 0.012799551244825125\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.0038504747208207846 with total_loss: 0.015914713498204947\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.0030741803348064423 with total_loss: 0.01976518821902573\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.003559156320989132 with total_loss: 0.022839368553832173\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.0029348942916840315 with total_loss: 0.026398524874821305\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.004008565563708544 with total_loss: 0.029333419166505337\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.003350270912051201 with total_loss: 0.03334198473021388\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.0033684775698930025 with total_loss: 0.03669225564226508\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.0030029539484530687 with total_loss: 0.040060733212158084\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0032342018093913794 with total_loss: 0.04306368716061115\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.0037237440701574087 with total_loss: 0.04629788897000253\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.0024171851109713316 with total_loss: 0.05002163304015994\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.003219623351469636 with total_loss: 0.05243881815113127\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.0037467635702341795 with total_loss: 0.05565844150260091\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.00360506190918386 with total_loss: 0.05940520507283509\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.004025150556117296 with total_loss: 0.06301026698201895\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.003055028850212693 with total_loss: 0.06703541753813624\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.0033223277423530817 with total_loss: 0.07009044638834894\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.003035198198631406 with total_loss: 0.07341277413070202\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.0034125216770917177 with total_loss: 0.07644797232933342\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0026748443488031626 with total_loss: 0.07986049400642514\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.003121024928987026 with total_loss: 0.0825353383552283\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.003149645170196891 with total_loss: 0.08565636328421533\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.002932517556473613 with total_loss: 0.08880600845441222\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.0028424113988876343 with total_loss: 0.09173852601088583\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.002990173175930977 with total_loss: 0.09458093740977347\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.0035079186782240868 with total_loss: 0.09757111058570445\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.004498262889683247 with total_loss: 0.10107902926392853\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.0052811442874372005 with total_loss: 0.10557729215361178\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.0054997894912958145 with total_loss: 0.11085843644104898\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.0039284625090658665 with total_loss: 0.1163582259323448\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.0038290296215564013 with total_loss: 0.12028668844141066\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.004417047370225191 with total_loss: 0.12411571806296706\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.0029328269883990288 with total_loss: 0.12853276543319225\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.0034264822024852037 with total_loss: 0.13146559242159128\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.0030990010127425194 with total_loss: 0.13489207462407649\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.0034080713521689177 with total_loss: 0.137991075636819\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.004348499234765768 with total_loss: 0.14139914698898792\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.0036162349861115217 with total_loss: 0.1457476462237537\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.00429155956953764 with total_loss: 0.1493638812098652\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.005111627280712128 with total_loss: 0.15365544077940285\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.003598663955926895 with total_loss: 0.15876706806011498\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.003634891239926219 with total_loss: 0.16236573201604187\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.003889026353135705 with total_loss: 0.1660006232559681\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.004654871299862862 with total_loss: 0.1698896496091038\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.002846699208021164 with total_loss: 0.17454452090896666\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.0029798122122883797 with total_loss: 0.17739122011698782\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.0027242565993219614 with total_loss: 0.1803710323292762\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.0038620533887296915 with total_loss: 0.18309528892859817\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.0031480256002396345 with total_loss: 0.18695734231732786\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.003898096503689885 with total_loss: 0.1901053679175675\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.004742193501442671 with total_loss: 0.19400346442125738\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.004600847605615854 with total_loss: 0.19874565792270005\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.0029121858533471823 with total_loss: 0.2033465055283159\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.0030530483927577734 with total_loss: 0.20625869138166308\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.006245765835046768 with total_loss: 0.20931173977442086\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.004646139219403267 with total_loss: 0.21555750560946763\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.0036291133146733046 with total_loss: 0.2202036448288709\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.023346276953816414 with total_loss: 0.2238327581435442\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.004713401664048433 with total_loss: 0.2471790350973606\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.0043693347834050655 with total_loss: 0.25189243676140904\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.004034414887428284 with total_loss: 0.2562617715448141\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.004460333380848169 with total_loss: 0.2602961864322424\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.0028099536430090666 with total_loss: 0.26475651981309056\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.003248342080041766 with total_loss: 0.26756647345609963\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.017564797773957253 with total_loss: 0.2708148155361414\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.00319855404086411 with total_loss: 0.28837961331009865\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.0035703417379409075 with total_loss: 0.29157816735096276\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.0034527021925896406 with total_loss: 0.29514850908890367\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.003373226849362254 with total_loss: 0.2986012112814933\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.004505002871155739 with total_loss: 0.30197443813085556\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.00397645914927125 with total_loss: 0.3064794410020113\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.0032861276995390654 with total_loss: 0.31045590015128255\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.003011828288435936 with total_loss: 0.3137420278508216\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.0035775925498455763 with total_loss: 0.31675385613925755\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.00337036675773561 with total_loss: 0.3203314486891031\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.0029128259047865868 with total_loss: 0.32370181544683874\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.0036388037260621786 with total_loss: 0.3266146413516253\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.0029919252265244722 with total_loss: 0.3302534450776875\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.003226956119760871 with total_loss: 0.333245370304212\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.002969592809677124 with total_loss: 0.33647232642397285\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.003625220851972699 with total_loss: 0.33944191923364997\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0033534865360707045 with total_loss: 0.34306714008562267\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.0031997710466384888 with total_loss: 0.3464206266216934\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.002870778553187847 with total_loss: 0.34962039766833186\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.00349300354719162 with total_loss: 0.3524911762215197\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.0030696652829647064 with total_loss: 0.35598417976871133\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.0033456943929195404 with total_loss: 0.35905384505167603\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.0035266622435301542 with total_loss: 0.3623995394445956\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.0031510256230831146 with total_loss: 0.36592620168812573\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 47 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.0037601981312036514 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.0032516580540686846 with total_loss: 0.0037601981312036514\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.002656163414940238 with total_loss: 0.007011856185272336\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.0035100525710731745 with total_loss: 0.009668019600212574\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.0025116645265370607 with total_loss: 0.013178072171285748\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.003127983771264553 with total_loss: 0.01568973669782281\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.003290753113105893 with total_loss: 0.018817720469087362\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.0037550695706158876 with total_loss: 0.022108473582193255\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.003309012157842517 with total_loss: 0.025863543152809143\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0029286742210388184 with total_loss: 0.02917255531065166\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.003119807690382004 with total_loss: 0.03210122953169048\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.0033175861462950706 with total_loss: 0.03522103722207248\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.0032586008310317993 with total_loss: 0.03853862336836755\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0029046423733234406 with total_loss: 0.04179722419939935\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.0031420793384313583 with total_loss: 0.04470186657272279\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.003937621135264635 with total_loss: 0.04784394591115415\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.0024495546240359545 with total_loss: 0.051781567046418786\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.002986086765304208 with total_loss: 0.05423112167045474\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.003524723229929805 with total_loss: 0.05721720843575895\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.003023669822141528 with total_loss: 0.06074193166568875\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.002136061666533351 with total_loss: 0.06376560148783028\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.004036613740026951 with total_loss: 0.06590166315436363\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.003157765604555607 with total_loss: 0.06993827689439058\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.0032783362548798323 with total_loss: 0.07309604249894619\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0036439483519643545 with total_loss: 0.07637437875382602\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.0033312560990452766 with total_loss: 0.08001832710579038\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.003833002643659711 with total_loss: 0.08334958320483565\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.0038060725200921297 with total_loss: 0.08718258584849536\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.002911879913881421 with total_loss: 0.0909886583685875\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.0031795513350516558 with total_loss: 0.09390053828246891\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.003430091543123126 with total_loss: 0.09708008961752057\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.004334613215178251 with total_loss: 0.1005101811606437\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.00488183693960309 with total_loss: 0.10484479437582195\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.005129852797836065 with total_loss: 0.10972663131542504\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.004750376101583242 with total_loss: 0.1148564841132611\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.003398936940357089 with total_loss: 0.11960686021484435\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.0038926468696445227 with total_loss: 0.12300579715520144\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.0042506312020123005 with total_loss: 0.12689844402484596\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.0033253366127610207 with total_loss: 0.13114907522685826\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.004468320403248072 with total_loss: 0.13447441183961928\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.003655562875792384 with total_loss: 0.13894273224286735\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.0034051772672683 with total_loss: 0.14259829511865973\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.00767646124586463 with total_loss: 0.14600347238592803\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.003440530737861991 with total_loss: 0.15367993363179266\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.004228284582495689 with total_loss: 0.15712046436965466\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.003917037509381771 with total_loss: 0.16134874895215034\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.005165383219718933 with total_loss: 0.16526578646153212\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.003347354242578149 with total_loss: 0.17043116968125105\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.002860385924577713 with total_loss: 0.1737785239238292\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.0029116563964635134 with total_loss: 0.1766389098484069\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.0036429299507290125 with total_loss: 0.17955056624487042\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.0028830550145357847 with total_loss: 0.18319349619559944\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.0035664457827806473 with total_loss: 0.18607655121013522\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.004160440061241388 with total_loss: 0.18964299699291587\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.004474299028515816 with total_loss: 0.19380343705415726\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.0035778142046183348 with total_loss: 0.19827773608267307\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.0032170105259865522 with total_loss: 0.2018555502872914\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.0037418578285723925 with total_loss: 0.20507256081327796\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.004722664598375559 with total_loss: 0.20881441864185035\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.0054308827966451645 with total_loss: 0.2135370832402259\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.003911043982952833 with total_loss: 0.21896796603687108\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.0037489617243409157 with total_loss: 0.2228790100198239\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.003232972463592887 with total_loss: 0.22662797174416482\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.002910192823037505 with total_loss: 0.2298609442077577\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.004893462639302015 with total_loss: 0.23277113703079522\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.004425509367138147 with total_loss: 0.23766459967009723\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.003894379362463951 with total_loss: 0.24209010903723538\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.003575896145775914 with total_loss: 0.24598448839969933\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.004119349177926779 with total_loss: 0.24956038454547524\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.0032458000350743532 with total_loss: 0.253679733723402\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.003794816555455327 with total_loss: 0.2569255337584764\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.0023718310985714197 with total_loss: 0.2607203503139317\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.0030630771070718765 with total_loss: 0.2630921814125031\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.0026756965089589357 with total_loss: 0.266155258519575\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.003412306308746338 with total_loss: 0.26883095502853394\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.0036393695045262575 with total_loss: 0.2722432613372803\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.0029475081246346235 with total_loss: 0.27588263084180653\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.002924532862380147 with total_loss: 0.27883013896644115\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.003188682720065117 with total_loss: 0.2817546718288213\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.002476314315572381 with total_loss: 0.2849433545488864\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.0027702562510967255 with total_loss: 0.2874196688644588\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.003016861854121089 with total_loss: 0.2901899251155555\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.002233759267255664 with total_loss: 0.2932067869696766\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.002714853733778 with total_loss: 0.2954405462369323\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.002898051403462887 with total_loss: 0.2981553999707103\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.00325111486017704 with total_loss: 0.30105345137417316\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0036808315198868513 with total_loss: 0.3043045662343502\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.002491539577022195 with total_loss: 0.30798539775423706\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.0036672677379101515 with total_loss: 0.31047693733125925\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.0029668062925338745 with total_loss: 0.3141442050691694\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.0025811363011598587 with total_loss: 0.3171110113617033\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.0029317624866962433 with total_loss: 0.31969214766286314\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.002344872336834669 with total_loss: 0.3226239101495594\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.0026764969807118177 with total_loss: 0.32496878248639405\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 48 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.003428315045312047 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.0030279492493718863 with total_loss: 0.003428315045312047\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.003914711996912956 with total_loss: 0.006456264294683933\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.0029289412777870893 with total_loss: 0.01037097629159689\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.0032371338456869125 with total_loss: 0.013299917569383979\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.0034613674506545067 with total_loss: 0.01653705141507089\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.003082825569435954 with total_loss: 0.019998418865725398\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.0041257659904658794 with total_loss: 0.023081244435161352\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.0036031128838658333 with total_loss: 0.02720701042562723\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0026300421450287104 with total_loss: 0.030810123309493065\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.0033199016470462084 with total_loss: 0.033440165454521775\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.0030067095067352057 with total_loss: 0.036760067101567984\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.007191601675003767 with total_loss: 0.03976677660830319\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0031976730097085238 with total_loss: 0.046958378283306956\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.0029925385024398565 with total_loss: 0.05015605129301548\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.0030980429146438837 with total_loss: 0.05314858979545534\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.003075564978644252 with total_loss: 0.05624663271009922\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.0026732732076197863 with total_loss: 0.05932219768874347\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.003919883631169796 with total_loss: 0.06199547089636326\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.0029302199836820364 with total_loss: 0.06591535452753305\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.001966506242752075 with total_loss: 0.06884557451121509\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.0030745218973606825 with total_loss: 0.07081208075396717\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.002739619230851531 with total_loss: 0.07388660265132785\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.0023963379207998514 with total_loss: 0.07662622188217938\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.0034980338532477617 with total_loss: 0.07902255980297923\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.0030761025846004486 with total_loss: 0.08252059365622699\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.0037800392601639032 with total_loss: 0.08559669624082744\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.004232578910887241 with total_loss: 0.08937673550099134\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.0027912685181945562 with total_loss: 0.09360931441187859\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.0026037846691906452 with total_loss: 0.09640058293007314\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.002035995712503791 with total_loss: 0.09900436759926379\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.003472483716905117 with total_loss: 0.10104036331176758\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.0033373935148119926 with total_loss: 0.1045128470286727\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.004055678378790617 with total_loss: 0.10785024054348469\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.00339541700668633 with total_loss: 0.1119059189222753\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.0036459078546613455 with total_loss: 0.11530133592896163\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.004689441528171301 with total_loss: 0.11894724378362298\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.004399277735501528 with total_loss: 0.12363668531179428\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.003290131688117981 with total_loss: 0.1280359630472958\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.0037437407299876213 with total_loss: 0.1313260947354138\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.004249277990311384 with total_loss: 0.1350698354654014\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.003645060583949089 with total_loss: 0.1393191134557128\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.0038666038308292627 with total_loss: 0.14296417403966188\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.003624140517786145 with total_loss: 0.14683077787049115\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.0044738841243088245 with total_loss: 0.1504549183882773\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.0034996531903743744 with total_loss: 0.15492880251258612\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.0029362470377236605 with total_loss: 0.1584284557029605\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.004591428674757481 with total_loss: 0.16136470274068415\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.009407238103449345 with total_loss: 0.16595613141544163\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.0027330510783940554 with total_loss: 0.17536336951889098\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.003687361953780055 with total_loss: 0.17809642059728503\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.004652225412428379 with total_loss: 0.1817837825510651\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.003131876466795802 with total_loss: 0.18643600796349347\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.003437645733356476 with total_loss: 0.18956788443028927\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.00447889044880867 with total_loss: 0.19300553016364574\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.003472781740128994 with total_loss: 0.19748442061245441\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.004680152516812086 with total_loss: 0.2009572023525834\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.0065349494107067585 with total_loss: 0.2056373548693955\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.0038440448697656393 with total_loss: 0.21217230428010225\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.003764593740925193 with total_loss: 0.2160163491498679\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.003765447298064828 with total_loss: 0.21978094289079309\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.0027370431926101446 with total_loss: 0.2235463901888579\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.003760178340598941 with total_loss: 0.22628343338146806\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.0025866106152534485 with total_loss: 0.230043611722067\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.0025748044718056917 with total_loss: 0.23263022233732045\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.002411777852103114 with total_loss: 0.23520502680912614\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.002905137138441205 with total_loss: 0.23761680466122925\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.00423422222957015 with total_loss: 0.24052194179967046\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.0025008325465023518 with total_loss: 0.2447561640292406\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.004156103823333979 with total_loss: 0.24725699657574296\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.002892878605052829 with total_loss: 0.25141310039907694\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.0030544495675712824 with total_loss: 0.25430597900412977\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.0024335114285349846 with total_loss: 0.25736042857170105\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.003788355505093932 with total_loss: 0.25979394000023603\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.006734948605298996 with total_loss: 0.26358229550532997\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.00255434587597847 with total_loss: 0.27031724411062896\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.003434300422668457 with total_loss: 0.27287158998660743\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.0028983382508158684 with total_loss: 0.2763058904092759\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.0023662527091801167 with total_loss: 0.27920422866009176\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.0031432441901415586 with total_loss: 0.2815704813692719\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.0034209834411740303 with total_loss: 0.28471372555941343\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.004326396621763706 with total_loss: 0.28813470900058746\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.0029731609392911196 with total_loss: 0.29246110562235117\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.0032935626804828644 with total_loss: 0.2954342665616423\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.004055797588080168 with total_loss: 0.29872782924212515\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.004305928945541382 with total_loss: 0.3027836268302053\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.003588101826608181 with total_loss: 0.3070895557757467\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.0033114191610366106 with total_loss: 0.3106776576023549\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.003048958955332637 with total_loss: 0.3139890767633915\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.002928509609773755 with total_loss: 0.31703803571872413\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.0033885855227708817 with total_loss: 0.3199665453284979\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.002334450138732791 with total_loss: 0.32335513085126877\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.0035943062976002693 with total_loss: 0.32568958099000156\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.0032687324564903975 with total_loss: 0.32928388728760183\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 49 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.003043870674446225 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.003200354753062129 with total_loss: 0.003043870674446225\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.003226358676329255 with total_loss: 0.006244225427508354\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.003933831583708525 with total_loss: 0.00947058410383761\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.002698936266824603 with total_loss: 0.013404415687546134\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.0023668892681598663 with total_loss: 0.016103351954370737\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.002585201757028699 with total_loss: 0.018470241222530603\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.0025163281243294477 with total_loss: 0.021055442979559302\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.003595392918214202 with total_loss: 0.02357177110388875\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.0026050631422549486 with total_loss: 0.027167164022102952\n",
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.003061754396185279 with total_loss: 0.0297722271643579\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.003381265327334404 with total_loss: 0.03283398156054318\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.00374634494073689 with total_loss: 0.036215246887877584\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0026364752557128668 with total_loss: 0.03996159182861447\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.003451703116297722 with total_loss: 0.04259806708432734\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.0038160085678100586 with total_loss: 0.04604977020062506\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.004161989316344261 with total_loss: 0.04986577876843512\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.0023423638194799423 with total_loss: 0.05402776808477938\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.003258651355281472 with total_loss: 0.056370131904259324\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.0030482604634016752 with total_loss: 0.059628783259540796\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.002375700743868947 with total_loss: 0.06267704372294247\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.0027309039141982794 with total_loss: 0.06505274446681142\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.0025747837498784065 with total_loss: 0.0677836483810097\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.0030780378729104996 with total_loss: 0.0703584321308881\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.004151926375925541 with total_loss: 0.0734364700037986\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.0026375222951173782 with total_loss: 0.07758839637972414\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.0028563712257891893 with total_loss: 0.08022591867484152\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.002936213044449687 with total_loss: 0.08308228990063071\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.00428681680932641 with total_loss: 0.0860185029450804\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.0025075923185795546 with total_loss: 0.09030531975440681\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.0030061237048357725 with total_loss: 0.09281291207298636\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.003538668854162097 with total_loss: 0.09581903577782214\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.004235937260091305 with total_loss: 0.09935770463198423\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.002873092656955123 with total_loss: 0.10359364189207554\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.003927307669073343 with total_loss: 0.10646673454903066\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.004874071571975946 with total_loss: 0.110394042218104\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.0035001365467906 with total_loss: 0.11526811379007995\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.003675077110528946 with total_loss: 0.11876825033687055\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.004191820975393057 with total_loss: 0.1224433274473995\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.004311160650104284 with total_loss: 0.12663514842279255\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.0066552069038152695 with total_loss: 0.13094630907289684\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.0030145084019750357 with total_loss: 0.1376015159767121\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.004283720161765814 with total_loss: 0.14061602437868714\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.004911721218377352 with total_loss: 0.14489974454045296\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.005509007256478071 with total_loss: 0.1498114657588303\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.004474426154047251 with total_loss: 0.15532047301530838\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.003297252580523491 with total_loss: 0.15979489916935563\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.0031230810564011335 with total_loss: 0.16309215174987912\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.004311042372137308 with total_loss: 0.16621523280628026\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.004497821908444166 with total_loss: 0.17052627517841756\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.003002069192007184 with total_loss: 0.17502409708686173\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.003323222743347287 with total_loss: 0.1780261662788689\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.00461434805765748 with total_loss: 0.1813493890222162\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.0026961599942296743 with total_loss: 0.18596373707987368\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.004168287850916386 with total_loss: 0.18865989707410336\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.003527262480929494 with total_loss: 0.19282818492501974\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.0037536397576332092 with total_loss: 0.19635544740594923\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.0033531170338392258 with total_loss: 0.20010908716358244\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.002497572684660554 with total_loss: 0.20346220419742167\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.003313056891784072 with total_loss: 0.20595977688208222\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.00448093144223094 with total_loss: 0.2092728337738663\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.003342823125422001 with total_loss: 0.21375376521609724\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.004279560875147581 with total_loss: 0.21709658834151924\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.002747400663793087 with total_loss: 0.22137614921666682\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.003079816000536084 with total_loss: 0.2241235498804599\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.0027849602047353983 with total_loss: 0.227203365880996\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.0031721957493573427 with total_loss: 0.2299883260857314\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.004618047270923853 with total_loss: 0.23316052183508873\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.002891635289415717 with total_loss: 0.23777856910601258\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.0039560310542583466 with total_loss: 0.2406702043954283\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.0031795150134712458 with total_loss: 0.24462623544968665\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.0031187732238322496 with total_loss: 0.2478057504631579\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.0034707181621342897 with total_loss: 0.25092452368699014\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.0035643745213747025 with total_loss: 0.25439524184912443\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.0036889314651489258 with total_loss: 0.25795961637049913\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.005302461329847574 with total_loss: 0.26164854783564806\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.0029342027846723795 with total_loss: 0.26695100916549563\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.0036746065597981215 with total_loss: 0.269885211950168\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.003276294795796275 with total_loss: 0.27355981850996614\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.004003710579127073 with total_loss: 0.2768361133057624\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.0022384854964911938 with total_loss: 0.2808398238848895\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.003057075897231698 with total_loss: 0.2830783093813807\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.0034634231124073267 with total_loss: 0.2861353852786124\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.002672482281923294 with total_loss: 0.2895988083910197\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.003612792817875743 with total_loss: 0.292271290672943\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.0027670301496982574 with total_loss: 0.29588408349081874\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0029508955776691437 with total_loss: 0.298651113640517\n",
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.0024211008567363024 with total_loss: 0.30160200921818614\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.0030144525226205587 with total_loss: 0.30402311007492244\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.0036681245546787977 with total_loss: 0.307037562597543\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.004152338486164808 with total_loss: 0.3107056871522218\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.002939584432169795 with total_loss: 0.3148580256383866\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.005102908238768578 with total_loss: 0.3177976100705564\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.002858312102034688 with total_loss: 0.322900518309325\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "======== Epoch 50 / 50 ========\n",
      "Training...\n",
      "  Batch     0  of     94.    Elapsed: 0:00:00. with Loss: 0.00385960447601974 with total_loss: 0\n",
      "  Batch     1  of     94.    Elapsed: 0:00:00. with Loss: 0.0034450648818165064 with total_loss: 0.00385960447601974\n",
      "  Batch     2  of     94.    Elapsed: 0:00:00. with Loss: 0.0025095834862440825 with total_loss: 0.0073046693578362465\n",
      "  Batch     3  of     94.    Elapsed: 0:00:00. with Loss: 0.0036277209874242544 with total_loss: 0.009814252844080329\n",
      "  Batch     4  of     94.    Elapsed: 0:00:00. with Loss: 0.0028291454073041677 with total_loss: 0.013441973831504583\n",
      "  Batch     5  of     94.    Elapsed: 0:00:00. with Loss: 0.0029520131647586823 with total_loss: 0.01627111923880875\n",
      "  Batch     6  of     94.    Elapsed: 0:00:00. with Loss: 0.00236071296967566 with total_loss: 0.019223132403567433\n",
      "  Batch     7  of     94.    Elapsed: 0:00:00. with Loss: 0.0034191058948636055 with total_loss: 0.021583845373243093\n",
      "  Batch     8  of     94.    Elapsed: 0:00:00. with Loss: 0.0027271683793514967 with total_loss: 0.0250029512681067\n",
      "  Batch     9  of     94.    Elapsed: 0:00:00. with Loss: 0.003872340777888894 with total_loss: 0.027730119647458196\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    10  of     94.    Elapsed: 0:00:00. with Loss: 0.0032937561627477407 with total_loss: 0.03160246042534709\n",
      "  Batch    11  of     94.    Elapsed: 0:00:00. with Loss: 0.003137923777103424 with total_loss: 0.03489621658809483\n",
      "  Batch    12  of     94.    Elapsed: 0:00:00. with Loss: 0.0026302889455109835 with total_loss: 0.038034140365198255\n",
      "  Batch    13  of     94.    Elapsed: 0:00:00. with Loss: 0.0030165284406393766 with total_loss: 0.04066442931070924\n",
      "  Batch    14  of     94.    Elapsed: 0:00:00. with Loss: 0.002792980521917343 with total_loss: 0.043680957751348615\n",
      "  Batch    15  of     94.    Elapsed: 0:00:00. with Loss: 0.002163032768294215 with total_loss: 0.04647393827326596\n",
      "  Batch    16  of     94.    Elapsed: 0:00:00. with Loss: 0.0032627086620777845 with total_loss: 0.04863697104156017\n",
      "  Batch    17  of     94.    Elapsed: 0:00:00. with Loss: 0.0026456976775079966 with total_loss: 0.05189967970363796\n",
      "  Batch    18  of     94.    Elapsed: 0:00:00. with Loss: 0.002990003675222397 with total_loss: 0.054545377381145954\n",
      "  Batch    19  of     94.    Elapsed: 0:00:00. with Loss: 0.003183458000421524 with total_loss: 0.05753538105636835\n",
      "  Batch    20  of     94.    Elapsed: 0:00:00. with Loss: 0.0029341026674956083 with total_loss: 0.060718839056789875\n",
      "  Batch    21  of     94.    Elapsed: 0:00:00. with Loss: 0.004142835736274719 with total_loss: 0.06365294172428548\n",
      "  Batch    22  of     94.    Elapsed: 0:00:00. with Loss: 0.003903372911736369 with total_loss: 0.0677957774605602\n",
      "  Batch    23  of     94.    Elapsed: 0:00:00. with Loss: 0.0033550255466252565 with total_loss: 0.07169915037229657\n",
      "  Batch    24  of     94.    Elapsed: 0:00:00. with Loss: 0.003341561881825328 with total_loss: 0.07505417591892183\n",
      "  Batch    25  of     94.    Elapsed: 0:00:01. with Loss: 0.0022729288320988417 with total_loss: 0.07839573780074716\n",
      "  Batch    26  of     94.    Elapsed: 0:00:01. with Loss: 0.003090760437771678 with total_loss: 0.080668666632846\n",
      "  Batch    27  of     94.    Elapsed: 0:00:01. with Loss: 0.06284555792808533 with total_loss: 0.08375942707061768\n",
      "  Batch    28  of     94.    Elapsed: 0:00:01. with Loss: 0.0032705555204302073 with total_loss: 0.146604984998703\n",
      "  Batch    29  of     94.    Elapsed: 0:00:01. with Loss: 0.0032948299776762724 with total_loss: 0.1498755405191332\n",
      "  Batch    30  of     94.    Elapsed: 0:00:01. with Loss: 0.002678841119632125 with total_loss: 0.15317037049680948\n",
      "  Batch    31  of     94.    Elapsed: 0:00:01. with Loss: 0.0032190484926104546 with total_loss: 0.1558492116164416\n",
      "  Batch    32  of     94.    Elapsed: 0:00:01. with Loss: 0.0067178853787481785 with total_loss: 0.15906826010905206\n",
      "  Batch    33  of     94.    Elapsed: 0:00:01. with Loss: 0.0036634448915719986 with total_loss: 0.16578614548780024\n",
      "  Batch    34  of     94.    Elapsed: 0:00:01. with Loss: 0.0032368646934628487 with total_loss: 0.16944959037937224\n",
      "  Batch    35  of     94.    Elapsed: 0:00:01. with Loss: 0.00286734476685524 with total_loss: 0.1726864550728351\n",
      "  Batch    36  of     94.    Elapsed: 0:00:01. with Loss: 0.003489762544631958 with total_loss: 0.17555379983969033\n",
      "  Batch    37  of     94.    Elapsed: 0:00:01. with Loss: 0.004105780739337206 with total_loss: 0.17904356238432229\n",
      "  Batch    38  of     94.    Elapsed: 0:00:01. with Loss: 0.04599025472998619 with total_loss: 0.1831493431236595\n",
      "  Batch    39  of     94.    Elapsed: 0:00:01. with Loss: 0.004814606159925461 with total_loss: 0.22913959785364568\n",
      "  Batch    40  of     94.    Elapsed: 0:00:01. with Loss: 0.004026949871331453 with total_loss: 0.23395420401357114\n",
      "  Batch    41  of     94.    Elapsed: 0:00:01. with Loss: 0.00488562835380435 with total_loss: 0.2379811538849026\n",
      "  Batch    42  of     94.    Elapsed: 0:00:01. with Loss: 0.003525935811921954 with total_loss: 0.24286678223870695\n",
      "  Batch    43  of     94.    Elapsed: 0:00:01. with Loss: 0.0035709738731384277 with total_loss: 0.2463927180506289\n",
      "  Batch    44  of     94.    Elapsed: 0:00:01. with Loss: 0.003941864240914583 with total_loss: 0.24996369192376733\n",
      "  Batch    45  of     94.    Elapsed: 0:00:01. with Loss: 0.0032011286821216345 with total_loss: 0.2539055561646819\n",
      "  Batch    46  of     94.    Elapsed: 0:00:01. with Loss: 0.003934884909540415 with total_loss: 0.25710668484680355\n",
      "  Batch    47  of     94.    Elapsed: 0:00:01. with Loss: 0.004739358555525541 with total_loss: 0.26104156975634396\n",
      "  Batch    48  of     94.    Elapsed: 0:00:01. with Loss: 0.003426794894039631 with total_loss: 0.2657809283118695\n",
      "  Batch    49  of     94.    Elapsed: 0:00:01. with Loss: 0.002861011540517211 with total_loss: 0.26920772320590913\n",
      "  Batch    50  of     94.    Elapsed: 0:00:01. with Loss: 0.0038384783547371626 with total_loss: 0.27206873474642634\n",
      "  Batch    51  of     94.    Elapsed: 0:00:01. with Loss: 0.0034910354297608137 with total_loss: 0.2759072131011635\n",
      "  Batch    52  of     94.    Elapsed: 0:00:01. with Loss: 0.0034018587321043015 with total_loss: 0.2793982485309243\n",
      "  Batch    53  of     94.    Elapsed: 0:00:01. with Loss: 0.006476591806858778 with total_loss: 0.2828001072630286\n",
      "  Batch    54  of     94.    Elapsed: 0:00:01. with Loss: 0.004004338756203651 with total_loss: 0.2892766990698874\n",
      "  Batch    55  of     94.    Elapsed: 0:00:01. with Loss: 0.002591713098809123 with total_loss: 0.29328103782609105\n",
      "  Batch    56  of     94.    Elapsed: 0:00:01. with Loss: 0.012630942277610302 with total_loss: 0.2958727509249002\n",
      "  Batch    57  of     94.    Elapsed: 0:00:01. with Loss: 0.004795100074261427 with total_loss: 0.3085036932025105\n",
      "  Batch    58  of     94.    Elapsed: 0:00:01. with Loss: 0.0034562023356556892 with total_loss: 0.3132987932767719\n",
      "  Batch    59  of     94.    Elapsed: 0:00:01. with Loss: 0.004493223503232002 with total_loss: 0.3167549956124276\n",
      "  Batch    60  of     94.    Elapsed: 0:00:01. with Loss: 0.0043387338519096375 with total_loss: 0.3212482191156596\n",
      "  Batch    61  of     94.    Elapsed: 0:00:01. with Loss: 0.006878180895000696 with total_loss: 0.32558695296756923\n",
      "  Batch    62  of     94.    Elapsed: 0:00:01. with Loss: 0.003064802847802639 with total_loss: 0.33246513386256993\n",
      "  Batch    63  of     94.    Elapsed: 0:00:01. with Loss: 0.0026680687442421913 with total_loss: 0.33552993671037257\n",
      "  Batch    64  of     94.    Elapsed: 0:00:01. with Loss: 0.003291928442195058 with total_loss: 0.33819800545461476\n",
      "  Batch    65  of     94.    Elapsed: 0:00:01. with Loss: 0.0033323673997074366 with total_loss: 0.3414899338968098\n",
      "  Batch    66  of     94.    Elapsed: 0:00:01. with Loss: 0.003062307834625244 with total_loss: 0.34482230129651725\n",
      "  Batch    67  of     94.    Elapsed: 0:00:01. with Loss: 0.0027613441925495863 with total_loss: 0.3478846091311425\n",
      "  Batch    68  of     94.    Elapsed: 0:00:01. with Loss: 0.004015015438199043 with total_loss: 0.3506459533236921\n",
      "  Batch    69  of     94.    Elapsed: 0:00:01. with Loss: 0.0033381388057023287 with total_loss: 0.3546609687618911\n",
      "  Batch    70  of     94.    Elapsed: 0:00:01. with Loss: 0.003921105992048979 with total_loss: 0.35799910756759346\n",
      "  Batch    71  of     94.    Elapsed: 0:00:01. with Loss: 0.0037326382007449865 with total_loss: 0.36192021355964243\n",
      "  Batch    72  of     94.    Elapsed: 0:00:01. with Loss: 0.0032975345384329557 with total_loss: 0.3656528517603874\n",
      "  Batch    73  of     94.    Elapsed: 0:00:01. with Loss: 0.003460673848167062 with total_loss: 0.3689503862988204\n",
      "  Batch    74  of     94.    Elapsed: 0:00:01. with Loss: 0.003127681091427803 with total_loss: 0.37241106014698744\n",
      "  Batch    75  of     94.    Elapsed: 0:00:01. with Loss: 0.0028301251586526632 with total_loss: 0.37553874123841524\n",
      "  Batch    76  of     94.    Elapsed: 0:00:02. with Loss: 0.002739791525527835 with total_loss: 0.3783688663970679\n",
      "  Batch    77  of     94.    Elapsed: 0:00:02. with Loss: 0.005056360270828009 with total_loss: 0.38110865792259574\n",
      "  Batch    78  of     94.    Elapsed: 0:00:02. with Loss: 0.002907702699303627 with total_loss: 0.38616501819342375\n",
      "  Batch    79  of     94.    Elapsed: 0:00:02. with Loss: 0.004255182575434446 with total_loss: 0.3890727208927274\n",
      "  Batch    80  of     94.    Elapsed: 0:00:02. with Loss: 0.003848377848044038 with total_loss: 0.3933279034681618\n",
      "  Batch    81  of     94.    Elapsed: 0:00:02. with Loss: 0.002692944137379527 with total_loss: 0.39717628131620586\n",
      "  Batch    82  of     94.    Elapsed: 0:00:02. with Loss: 0.0027909406926482916 with total_loss: 0.3998692254535854\n",
      "  Batch    83  of     94.    Elapsed: 0:00:02. with Loss: 0.002774024149402976 with total_loss: 0.4026601661462337\n",
      "  Batch    84  of     94.    Elapsed: 0:00:02. with Loss: 0.00247389473952353 with total_loss: 0.40543419029563665\n",
      "  Batch    85  of     94.    Elapsed: 0:00:02. with Loss: 0.0030510611832141876 with total_loss: 0.4079080850351602\n",
      "  Batch    86  of     94.    Elapsed: 0:00:02. with Loss: 0.0029765982180833817 with total_loss: 0.41095914621837437\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    87  of     94.    Elapsed: 0:00:02. with Loss: 0.0035527972504496574 with total_loss: 0.41393574443645775\n",
      "  Batch    88  of     94.    Elapsed: 0:00:02. with Loss: 0.007396614644676447 with total_loss: 0.4174885416869074\n",
      "  Batch    89  of     94.    Elapsed: 0:00:02. with Loss: 0.00374009576626122 with total_loss: 0.42488515633158386\n",
      "  Batch    90  of     94.    Elapsed: 0:00:02. with Loss: 0.0026044994592666626 with total_loss: 0.4286252520978451\n",
      "  Batch    91  of     94.    Elapsed: 0:00:02. with Loss: 0.0027573120314627886 with total_loss: 0.43122975155711174\n",
      "  Batch    92  of     94.    Elapsed: 0:00:02. with Loss: 0.0031753506045788527 with total_loss: 0.43398706358857453\n",
      "  Batch    93  of     94.    Elapsed: 0:00:02. with Loss: 0.00394742377102375 with total_loss: 0.4371624141931534\n",
      "\n",
      "  Average training loss: 0.00\n",
      "  Training epcoh took: 0:00:02\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import time\n",
    "seed_val = 42\n",
    "\n",
    "random.seed(seed_val)\n",
    "np.random.seed(seed_val)\n",
    "torch.manual_seed(seed_val)\n",
    "torch.cuda.manual_seed_all(seed_val)\n",
    "# model.to(device)\n",
    "\n",
    "# Store the average loss after each epoch so we can plot them.\n",
    "loss_values = []\n",
    "\n",
    "# For each epoch...\n",
    "for epoch_i in range(0, epochs):\n",
    "    \n",
    "    # ========================================\n",
    "    #               Training\n",
    "    # ========================================\n",
    "    \n",
    "    # Perform one full pass over the training set.\n",
    "\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "\n",
    "    # Measure how long the training epoch takes.\n",
    "    t0 = time.time()\n",
    "\n",
    "    # Reset the total loss for this epoch.\n",
    "    total_loss = 0\n",
    "\n",
    "    model.train()\n",
    "    \n",
    "\n",
    "    # For each batch of training data...\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "\n",
    "        b_input_ids = batch[0].to(device)\n",
    "        b_attention_mask=batch[1].to(device)\n",
    "        b_labels = batch[2].to(device)\n",
    "\n",
    " \n",
    "        model.zero_grad()        \n",
    "\n",
    "        outputs = model(inputs_embeds=b_input_ids, \n",
    "#                     token_type_ids=None, \n",
    "                    attention_mask=None, \n",
    "                    labels=b_labels)        \n",
    "    \n",
    "        loss = outputs[0]\n",
    "        if step%1==0:\n",
    "            elapsed = format_time(time.time() - t0)\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    Elapsed: {:}. with Loss: {:} with total_loss: {:}'.format(step, len(train_dataloader), elapsed,loss.item(),total_loss))\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        # Perform a backward pass to calculate the gradients.\n",
    "        loss.backward()\n",
    "\n",
    "    \n",
    "        optimizer.step()\n",
    "\n",
    "        # Update the learning rate.\n",
    "        scheduler.step()\n",
    "#         \n",
    "        # Report progress.\n",
    "\n",
    "    # Calculate the average loss over the training data.\n",
    "    avg_train_loss = total_loss / len(train_dataloader)  \n",
    "\n",
    "    \n",
    "    # Store the loss value for plotting the learning curve.\n",
    "    loss_values.append(avg_train_loss)\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "    print(\"  Training epcoh took: {:}\".format(format_time(time.time() - t0)))\n",
    "        \n",
    "print(\"\")\n",
    "print(\"Training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[4.730220934970582,\n",
       " 0.8991862846974362,\n",
       " 0.3362089938464317,\n",
       " 0.17431944145008604,\n",
       " 0.11445411494833992,\n",
       " 0.08852151163080905,\n",
       " 0.05755317060554281,\n",
       " 0.037912673168280654,\n",
       " 0.030433288260184703,\n",
       " 0.025112296345623883,\n",
       " 0.020338197367543234,\n",
       " 0.016199877733325072,\n",
       " 0.014783310644487117,\n",
       " 0.013181843046851932,\n",
       " 0.011667419101131405,\n",
       " 0.009892290304514004,\n",
       " 0.009897267906629342,\n",
       " 0.008474230761342544,\n",
       " 0.007952847795442064,\n",
       " 0.007821291581073657,\n",
       " 0.008527310416498717,\n",
       " 0.010217961795786594,\n",
       " 0.006788709882072154,\n",
       " 0.007291199253039791,\n",
       " 0.006142597771844172,\n",
       " 0.014943775587140563,\n",
       " 0.013730479803114653,\n",
       " 0.00688363026153851,\n",
       " 0.0058003362278117145,\n",
       " 0.0053136711940169334,\n",
       " 0.005493504106701213,\n",
       " 0.004616799947627364,\n",
       " 0.004484490793634286,\n",
       " 0.005088954064202436,\n",
       " 0.0051760783993658865,\n",
       " 0.0043626128958458915,\n",
       " 0.004498031678946412,\n",
       " 0.004291690321282503,\n",
       " 0.003983731963671744,\n",
       " 0.004057706747342773,\n",
       " 0.003941594774121458,\n",
       " 0.003949505606408607,\n",
       " 0.003835403387672565,\n",
       " 0.003921588853080856,\n",
       " 0.004358852363904898,\n",
       " 0.003926353482034137,\n",
       " 0.0034855880794372966,\n",
       " 0.0035377938270648107,\n",
       " 0.003465519472461273,\n",
       " 0.0046926578506827354]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9.2054],\n",
      "         [ 1.0229],\n",
      "         [-0.0790]]], device='cuda:0')\n",
      "tensor([[[ 9.2469],\n",
      "         [ 1.0548],\n",
      "         [-0.0285]]], device='cuda:0')\n",
      "tensor([[[ 9.2045],\n",
      "         [ 1.0173],\n",
      "         [-0.0215]]], device='cuda:0')\n",
      "tensor([[[ 9.2564],\n",
      "         [ 1.0526],\n",
      "         [-0.0104]]], device='cuda:0')\n",
      "tensor([[[ 9.2414],\n",
      "         [ 1.0281],\n",
      "         [-0.0149]]], device='cuda:0')\n",
      "tensor([[[ 9.2176],\n",
      "         [ 1.0658],\n",
      "         [-0.0169]]], device='cuda:0')\n",
      "tensor([[[ 9.1953e+00],\n",
      "         [ 1.0563e+00],\n",
      "         [-9.3516e-04]]], device='cuda:0')\n",
      "tensor([[[ 9.2371],\n",
      "         [ 1.0494],\n",
      "         [-0.0140]]], device='cuda:0')\n",
      "tensor([[[ 9.2388],\n",
      "         [ 1.0615],\n",
      "         [-0.0206]]], device='cuda:0')\n",
      "tensor([[[ 9.2766],\n",
      "         [ 1.0612],\n",
      "         [-0.0103]]], device='cuda:0')\n",
      "tensor([[[9.2500e+00],\n",
      "         [1.0715e+00],\n",
      "         [4.6618e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2348],\n",
      "         [ 1.0624],\n",
      "         [-0.0221]]], device='cuda:0')\n",
      "tensor([[[ 9.2170],\n",
      "         [ 1.0643],\n",
      "         [-0.0474]]], device='cuda:0')\n",
      "tensor([[[9.2228e+00],\n",
      "         [1.0693e+00],\n",
      "         [4.0027e-03]]], device='cuda:0')\n",
      "tensor([[[9.2437e+00],\n",
      "         [1.0555e+00],\n",
      "         [6.9068e-04]]], device='cuda:0')\n",
      "tensor([[[ 9.2301],\n",
      "         [ 1.0619],\n",
      "         [-0.0151]]], device='cuda:0')\n",
      "tensor([[[ 9.2271],\n",
      "         [ 1.0344],\n",
      "         [-0.0334]]], device='cuda:0')\n",
      "tensor([[[ 9.2526],\n",
      "         [ 1.0550],\n",
      "         [-0.0231]]], device='cuda:0')\n",
      "tensor([[[ 9.2062],\n",
      "         [ 1.0478],\n",
      "         [-0.0153]]], device='cuda:0')\n",
      "tensor([[[ 9.2477e+00],\n",
      "         [ 1.0605e+00],\n",
      "         [-6.8125e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2580e+00],\n",
      "         [ 1.0743e+00],\n",
      "         [-3.5805e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2379],\n",
      "         [ 1.0694],\n",
      "         [-0.0353]]], device='cuda:0')\n",
      "tensor([[[ 9.2504],\n",
      "         [ 1.0381],\n",
      "         [-0.0214]]], device='cuda:0')\n",
      "tensor([[[9.2167],\n",
      "         [1.0511],\n",
      "         [0.0615]]], device='cuda:0')\n",
      "tensor([[[ 9.2340],\n",
      "         [ 1.0611],\n",
      "         [-0.0203]]], device='cuda:0')\n",
      "tensor([[[ 9.2361],\n",
      "         [ 1.0278],\n",
      "         [-0.0295]]], device='cuda:0')\n",
      "tensor([[[ 9.2370],\n",
      "         [ 1.0577],\n",
      "         [-0.0131]]], device='cuda:0')\n",
      "tensor([[[ 9.2263],\n",
      "         [ 1.0571],\n",
      "         [-0.0260]]], device='cuda:0')\n",
      "tensor([[[ 9.2034e+00],\n",
      "         [ 1.0657e+00],\n",
      "         [-7.8714e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2487e+00],\n",
      "         [ 1.0597e+00],\n",
      "         [-4.9784e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2504],\n",
      "         [ 1.0519],\n",
      "         [-0.0096]]], device='cuda:0')\n",
      "tensor([[[ 9.2143],\n",
      "         [ 1.0349],\n",
      "         [-0.0116]]], device='cuda:0')\n",
      "tensor([[[ 9.2366e+00],\n",
      "         [ 1.0889e+00],\n",
      "         [-4.7168e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2117],\n",
      "         [ 1.0358],\n",
      "         [-0.0243]]], device='cuda:0')\n",
      "tensor([[[ 9.2322],\n",
      "         [ 1.0321],\n",
      "         [-0.0108]]], device='cuda:0')\n",
      "tensor([[[ 9.2566e+00],\n",
      "         [ 1.0611e+00],\n",
      "         [-8.7164e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2410e+00],\n",
      "         [ 1.0332e+00],\n",
      "         [-8.3538e-03]]], device='cuda:0')\n",
      "tensor([[[9.2601e+00],\n",
      "         [1.0537e+00],\n",
      "         [2.9150e-03]]], device='cuda:0')\n",
      "tensor([[[9.2202e+00],\n",
      "         [1.0485e+00],\n",
      "         [4.7556e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2235],\n",
      "         [ 1.0580],\n",
      "         [-0.0106]]], device='cuda:0')\n",
      "tensor([[[ 9.2575],\n",
      "         [ 1.0584],\n",
      "         [-0.0216]]], device='cuda:0')\n",
      "tensor([[[ 9.2662],\n",
      "         [ 1.0607],\n",
      "         [-0.0370]]], device='cuda:0')\n",
      "tensor([[[ 9.2516e+00],\n",
      "         [ 1.0492e+00],\n",
      "         [-7.1358e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2704],\n",
      "         [ 1.0578],\n",
      "         [-0.0138]]], device='cuda:0')\n",
      "tensor([[[ 9.2529],\n",
      "         [ 1.0641],\n",
      "         [-0.0159]]], device='cuda:0')\n",
      "tensor([[[ 9.2425e+00],\n",
      "         [ 1.0686e+00],\n",
      "         [-2.5732e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2126],\n",
      "         [ 1.0255],\n",
      "         [-0.0551]]], device='cuda:0')\n",
      "tensor([[[9.2253],\n",
      "         [1.0543],\n",
      "         [0.0882]]], device='cuda:0')\n",
      "tensor([[[ 9.2346],\n",
      "         [ 1.0550],\n",
      "         [-0.0148]]], device='cuda:0')\n",
      "tensor([[[ 9.2445],\n",
      "         [ 1.0339],\n",
      "         [-0.0141]]], device='cuda:0')\n",
      "tensor([[[ 9.2639],\n",
      "         [ 1.0262],\n",
      "         [-0.0238]]], device='cuda:0')\n",
      "tensor([[[ 9.2559],\n",
      "         [ 1.0627],\n",
      "         [-0.0364]]], device='cuda:0')\n",
      "tensor([[[ 9.2334],\n",
      "         [ 1.0493],\n",
      "         [-0.0303]]], device='cuda:0')\n",
      "tensor([[[9.1888],\n",
      "         [1.0756],\n",
      "         [0.0589]]], device='cuda:0')\n",
      "tensor([[[ 9.2534e+00],\n",
      "         [ 1.0616e+00],\n",
      "         [-5.8972e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2212],\n",
      "         [ 1.0437],\n",
      "         [-0.0143]]], device='cuda:0')\n",
      "tensor([[[ 9.2266],\n",
      "         [ 1.0544],\n",
      "         [-0.0147]]], device='cuda:0')\n",
      "tensor([[[9.2521e+00],\n",
      "         [1.0705e+00],\n",
      "         [4.6175e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2295],\n",
      "         [ 1.0549],\n",
      "         [-0.0143]]], device='cuda:0')\n",
      "tensor([[[ 9.2389],\n",
      "         [ 1.0350],\n",
      "         [-0.0148]]], device='cuda:0')\n",
      "tensor([[[ 9.2550e+00],\n",
      "         [ 1.0639e+00],\n",
      "         [-4.5580e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2347],\n",
      "         [ 1.0390],\n",
      "         [-0.0199]]], device='cuda:0')\n",
      "tensor([[[9.2403e+00],\n",
      "         [1.0551e+00],\n",
      "         [5.1056e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2516e+00],\n",
      "         [ 9.8669e-01],\n",
      "         [-2.3597e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2512],\n",
      "         [ 1.0075],\n",
      "         [-0.0133]]], device='cuda:0')\n",
      "tensor([[[ 9.2193],\n",
      "         [ 1.0716],\n",
      "         [-0.0433]]], device='cuda:0')\n",
      "tensor([[[ 9.2033],\n",
      "         [ 1.0322],\n",
      "         [-0.0154]]], device='cuda:0')\n",
      "tensor([[[9.1763],\n",
      "         [1.1065],\n",
      "         [0.1662]]], device='cuda:0')\n",
      "tensor([[[ 9.2062],\n",
      "         [ 1.0575],\n",
      "         [-0.0150]]], device='cuda:0')\n",
      "tensor([[[9.2351e+00],\n",
      "         [1.0476e+00],\n",
      "         [3.3675e-03]]], device='cuda:0')\n",
      "tensor([[[9.2087],\n",
      "         [1.0616],\n",
      "         [0.0515]]], device='cuda:0')\n",
      "tensor([[[ 9.2504],\n",
      "         [ 1.0502],\n",
      "         [-0.0453]]], device='cuda:0')\n",
      "tensor([[[ 9.2388],\n",
      "         [ 1.0590],\n",
      "         [-0.0631]]], device='cuda:0')\n",
      "tensor([[[ 9.2436e+00],\n",
      "         [ 1.0640e+00],\n",
      "         [-8.5339e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2909],\n",
      "         [ 1.0300],\n",
      "         [-0.0553]]], device='cuda:0')\n",
      "tensor([[[9.1969],\n",
      "         [1.0535],\n",
      "         [0.0103]]], device='cuda:0')\n",
      "tensor([[[ 9.2180],\n",
      "         [ 1.0655],\n",
      "         [-0.0549]]], device='cuda:0')\n",
      "tensor([[[ 9.2194],\n",
      "         [ 1.0304],\n",
      "         [-0.0286]]], device='cuda:0')\n",
      "tensor([[[ 9.2082],\n",
      "         [ 1.0199],\n",
      "         [-0.0406]]], device='cuda:0')\n",
      "tensor([[[ 9.2213],\n",
      "         [ 1.0565],\n",
      "         [-0.0212]]], device='cuda:0')\n",
      "tensor([[[ 9.2367],\n",
      "         [ 1.0280],\n",
      "         [-0.0261]]], device='cuda:0')\n",
      "tensor([[[ 9.2081],\n",
      "         [ 1.0578],\n",
      "         [-0.0195]]], device='cuda:0')\n",
      "tensor([[[ 9.2108e+00],\n",
      "         [ 1.0457e+00],\n",
      "         [-8.4377e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2518],\n",
      "         [ 1.0538],\n",
      "         [-0.0298]]], device='cuda:0')\n",
      "tensor([[[9.2505e+00],\n",
      "         [1.0556e+00],\n",
      "         [3.1845e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2099e+00],\n",
      "         [ 1.0541e+00],\n",
      "         [-3.9830e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2586],\n",
      "         [ 1.0323],\n",
      "         [-0.0103]]], device='cuda:0')\n",
      "tensor([[[ 9.2396],\n",
      "         [ 1.0631],\n",
      "         [-0.0459]]], device='cuda:0')\n",
      "tensor([[[ 9.2207],\n",
      "         [ 1.0541],\n",
      "         [-0.0152]]], device='cuda:0')\n",
      "tensor([[[9.2548],\n",
      "         [1.0641],\n",
      "         [0.0507]]], device='cuda:0')\n",
      "tensor([[[9.1940],\n",
      "         [1.0739],\n",
      "         [0.0496]]], device='cuda:0')\n",
      "tensor([[[ 9.2279],\n",
      "         [ 1.0961],\n",
      "         [-0.0483]]], device='cuda:0')\n",
      "tensor([[[ 9.2327],\n",
      "         [ 1.0553],\n",
      "         [-0.0469]]], device='cuda:0')\n",
      "tensor([[[ 9.2347],\n",
      "         [ 1.0486],\n",
      "         [-0.0340]]], device='cuda:0')\n",
      "tensor([[[ 9.2541],\n",
      "         [ 1.0630],\n",
      "         [-0.0165]]], device='cuda:0')\n",
      "tensor([[[ 9.2558e+00],\n",
      "         [ 1.0625e+00],\n",
      "         [-4.7424e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2674],\n",
      "         [ 1.0496],\n",
      "         [-0.0117]]], device='cuda:0')\n",
      "tensor([[[ 9.2167],\n",
      "         [ 1.0422],\n",
      "         [-0.0139]]], device='cuda:0')\n",
      "tensor([[[ 9.2369],\n",
      "         [ 1.0611],\n",
      "         [-0.0261]]], device='cuda:0')\n",
      "tensor([[[ 9.2415e+00],\n",
      "         [ 1.0613e+00],\n",
      "         [-9.0664e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2526],\n",
      "         [ 1.0266],\n",
      "         [-0.0551]]], device='cuda:0')\n",
      "tensor([[[ 9.2465e+00],\n",
      "         [ 1.0661e+00],\n",
      "         [-3.3402e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2174e+00],\n",
      "         [ 1.0497e+00],\n",
      "         [-7.1847e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2083e+00],\n",
      "         [ 1.0561e+00],\n",
      "         [-6.1078e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2422e+00],\n",
      "         [ 1.0603e+00],\n",
      "         [-3.5417e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2155],\n",
      "         [ 1.0647],\n",
      "         [-0.0191]]], device='cuda:0')\n",
      "tensor([[[ 9.2288e+00],\n",
      "         [ 1.0636e+00],\n",
      "         [-8.6162e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2395],\n",
      "         [ 1.0681],\n",
      "         [-0.0109]]], device='cuda:0')\n",
      "tensor([[[ 9.2277e+00],\n",
      "         [ 1.0534e+00],\n",
      "         [-3.3134e-03]]], device='cuda:0')\n",
      "tensor([[[9.2000],\n",
      "         [1.0518],\n",
      "         [0.0722]]], device='cuda:0')\n",
      "tensor([[[ 9.2364],\n",
      "         [ 1.0444],\n",
      "         [-0.0132]]], device='cuda:0')\n",
      "tensor([[[ 9.2436],\n",
      "         [ 1.0521],\n",
      "         [-0.0341]]], device='cuda:0')\n",
      "tensor([[[9.2120],\n",
      "         [1.1031],\n",
      "         [0.1665]]], device='cuda:0')\n",
      "tensor([[[9.2506e+00],\n",
      "         [1.0523e+00],\n",
      "         [2.7020e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2394],\n",
      "         [ 1.0697],\n",
      "         [-0.0343]]], device='cuda:0')\n",
      "tensor([[[ 9.2565e+00],\n",
      "         [ 1.0632e+00],\n",
      "         [-8.0825e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2372e+00],\n",
      "         [ 1.0670e+00],\n",
      "         [-2.6175e-03]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9.2673],\n",
      "         [ 1.0394],\n",
      "         [-0.0106]]], device='cuda:0')\n",
      "tensor([[[ 9.2315],\n",
      "         [ 1.0433],\n",
      "         [-0.0109]]], device='cuda:0')\n",
      "tensor([[[ 9.1947],\n",
      "         [ 1.0888],\n",
      "         [-0.0529]]], device='cuda:0')\n",
      "tensor([[[ 9.2068],\n",
      "         [ 1.0859],\n",
      "         [-0.0115]]], device='cuda:0')\n",
      "tensor([[[ 9.2490],\n",
      "         [ 0.9893],\n",
      "         [-0.0419]]], device='cuda:0')\n",
      "tensor([[[ 9.2327],\n",
      "         [ 1.0446],\n",
      "         [-0.0117]]], device='cuda:0')\n",
      "tensor([[[ 9.2364],\n",
      "         [ 1.0653],\n",
      "         [-0.0617]]], device='cuda:0')\n",
      "tensor([[[9.2426e+00],\n",
      "         [1.0551e+00],\n",
      "         [3.1929e-03]]], device='cuda:0')\n",
      "tensor([[[9.2232e+00],\n",
      "         [1.0549e+00],\n",
      "         [1.4150e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2161],\n",
      "         [ 1.0298],\n",
      "         [-0.0537]]], device='cuda:0')\n",
      "tensor([[[ 9.2514],\n",
      "         [ 1.0715],\n",
      "         [-0.0427]]], device='cuda:0')\n",
      "tensor([[[ 9.2208],\n",
      "         [ 1.0880],\n",
      "         [-0.0494]]], device='cuda:0')\n",
      "tensor([[[ 9.2104],\n",
      "         [ 1.0531],\n",
      "         [-0.0116]]], device='cuda:0')\n",
      "tensor([[[9.2045e+00],\n",
      "         [1.0035e+00],\n",
      "         [2.6060e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2002],\n",
      "         [ 1.0453],\n",
      "         [-0.0113]]], device='cuda:0')\n",
      "tensor([[[ 9.2304],\n",
      "         [ 1.0670],\n",
      "         [-0.0532]]], device='cuda:0')\n",
      "tensor([[[ 9.2092],\n",
      "         [ 1.0438],\n",
      "         [-0.0427]]], device='cuda:0')\n",
      "tensor([[[ 9.2285],\n",
      "         [ 1.0274],\n",
      "         [-0.0328]]], device='cuda:0')\n",
      "tensor([[[9.2283],\n",
      "         [1.1040],\n",
      "         [0.1787]]], device='cuda:0')\n",
      "tensor([[[ 9.2176],\n",
      "         [ 1.0573],\n",
      "         [-0.0201]]], device='cuda:0')\n",
      "tensor([[[9.2278],\n",
      "         [1.0612],\n",
      "         [0.0488]]], device='cuda:0')\n",
      "tensor([[[ 9.2336],\n",
      "         [ 1.0580],\n",
      "         [-0.0140]]], device='cuda:0')\n",
      "tensor([[[ 9.2240],\n",
      "         [ 1.0487],\n",
      "         [-0.0135]]], device='cuda:0')\n",
      "tensor([[[9.2268],\n",
      "         [1.0599],\n",
      "         [0.0487]]], device='cuda:0')\n",
      "tensor([[[ 9.2159],\n",
      "         [ 1.0546],\n",
      "         [-0.0257]]], device='cuda:0')\n",
      "tensor([[[ 9.2246],\n",
      "         [ 1.0573],\n",
      "         [-0.0621]]], device='cuda:0')\n",
      "tensor([[[9.2215e+00],\n",
      "         [1.0431e+00],\n",
      "         [2.2611e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2534],\n",
      "         [ 1.0660],\n",
      "         [-0.0355]]], device='cuda:0')\n",
      "tensor([[[ 9.2295],\n",
      "         [ 1.0498],\n",
      "         [-0.0345]]], device='cuda:0')\n",
      "tensor([[[ 9.2301e+00],\n",
      "         [ 1.0500e+00],\n",
      "         [-8.8923e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2314],\n",
      "         [ 1.0229],\n",
      "         [-0.0343]]], device='cuda:0')\n",
      "tensor([[[ 9.2525],\n",
      "         [ 1.0659],\n",
      "         [-0.0205]]], device='cuda:0')\n",
      "tensor([[[ 9.2424e+00],\n",
      "         [ 1.0662e+00],\n",
      "         [-2.9126e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2859],\n",
      "         [ 1.0505],\n",
      "         [-0.0097]]], device='cuda:0')\n",
      "tensor([[[ 9.2306],\n",
      "         [ 1.0264],\n",
      "         [-0.0121]]], device='cuda:0')\n",
      "tensor([[[ 9.2382e+00],\n",
      "         [ 1.0426e+00],\n",
      "         [-2.7283e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2314],\n",
      "         [ 1.0341],\n",
      "         [-0.0217]]], device='cuda:0')\n",
      "tensor([[[ 9.2465e+00],\n",
      "         [ 1.0596e+00],\n",
      "         [-8.5830e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2359],\n",
      "         [ 1.0518],\n",
      "         [-0.0450]]], device='cuda:0')\n",
      "tensor([[[ 9.2313e+00],\n",
      "         [ 1.0618e+00],\n",
      "         [-4.7979e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2654],\n",
      "         [ 1.0714],\n",
      "         [-0.0104]]], device='cuda:0')\n",
      "tensor([[[ 9.2431],\n",
      "         [ 1.0331],\n",
      "         [-0.0390]]], device='cuda:0')\n",
      "tensor([[[ 9.2377],\n",
      "         [ 1.0420],\n",
      "         [-0.0423]]], device='cuda:0')\n",
      "tensor([[[ 9.2603],\n",
      "         [ 1.0739],\n",
      "         [-0.0105]]], device='cuda:0')\n",
      "tensor([[[ 9.2183e+00],\n",
      "         [ 1.0524e+00],\n",
      "         [-2.2698e-03]]], device='cuda:0')\n",
      "tensor([[[9.2533],\n",
      "         [1.0484],\n",
      "         [0.0128]]], device='cuda:0')\n",
      "tensor([[[9.2383e+00],\n",
      "         [1.0591e+00],\n",
      "         [4.1884e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2562],\n",
      "         [ 1.0620],\n",
      "         [-0.0202]]], device='cuda:0')\n",
      "tensor([[[ 9.2282],\n",
      "         [ 1.0566],\n",
      "         [-0.0205]]], device='cuda:0')\n",
      "tensor([[[9.2196],\n",
      "         [1.0495],\n",
      "         [0.0727]]], device='cuda:0')\n",
      "tensor([[[ 9.2492],\n",
      "         [ 1.0456],\n",
      "         [-0.0472]]], device='cuda:0')\n",
      "tensor([[[ 9.2558e+00],\n",
      "         [ 1.0625e+00],\n",
      "         [-4.7424e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2663],\n",
      "         [ 1.0323],\n",
      "         [-0.0107]]], device='cuda:0')\n",
      "tensor([[[ 9.2393],\n",
      "         [ 1.0406],\n",
      "         [-0.0101]]], device='cuda:0')\n",
      "tensor([[[ 9.2323e+00],\n",
      "         [ 1.0482e+00],\n",
      "         [-1.7265e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2264],\n",
      "         [ 1.0652],\n",
      "         [-0.0465]]], device='cuda:0')\n",
      "tensor([[[ 9.2576],\n",
      "         [ 1.0694],\n",
      "         [-0.0355]]], device='cuda:0')\n",
      "tensor([[[9.1982],\n",
      "         [1.0464],\n",
      "         [0.0304]]], device='cuda:0')\n",
      "tensor([[[ 9.2445],\n",
      "         [ 1.0611],\n",
      "         [-0.0101]]], device='cuda:0')\n",
      "tensor([[[ 9.1953e+00],\n",
      "         [ 1.0563e+00],\n",
      "         [-9.3516e-04]]], device='cuda:0')\n",
      "tensor([[[9.2427],\n",
      "         [1.0510],\n",
      "         [0.0116]]], device='cuda:0')\n",
      "tensor([[[ 9.2048],\n",
      "         [ 1.0640],\n",
      "         [-0.0191]]], device='cuda:0')\n",
      "tensor([[[ 9.2461e+00],\n",
      "         [ 1.0494e+00],\n",
      "         [-9.0373e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2478],\n",
      "         [ 1.0679],\n",
      "         [-0.0254]]], device='cuda:0')\n",
      "tensor([[[ 9.2252],\n",
      "         [ 1.0491],\n",
      "         [-0.0364]]], device='cuda:0')\n",
      "tensor([[[ 9.2037e+00],\n",
      "         [ 1.1823e+00],\n",
      "         [-7.6797e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2328],\n",
      "         [ 1.0939],\n",
      "         [-0.0474]]], device='cuda:0')\n",
      "tensor([[[ 9.2111],\n",
      "         [ 1.0328],\n",
      "         [-0.0553]]], device='cuda:0')\n",
      "tensor([[[ 9.2266],\n",
      "         [ 1.0550],\n",
      "         [-0.0158]]], device='cuda:0')\n",
      "tensor([[[9.2215],\n",
      "         [1.0707],\n",
      "         [0.0425]]], device='cuda:0')\n",
      "tensor([[[ 9.2416],\n",
      "         [ 1.0404],\n",
      "         [-0.0162]]], device='cuda:0')\n",
      "tensor([[[ 9.2661],\n",
      "         [ 1.0695],\n",
      "         [-0.0104]]], device='cuda:0')\n",
      "tensor([[[ 9.2313e+00],\n",
      "         [ 1.0301e+00],\n",
      "         [-8.9222e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2752e+00],\n",
      "         [ 9.8760e-01],\n",
      "         [-3.3734e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2423],\n",
      "         [ 1.0585],\n",
      "         [-0.0131]]], device='cuda:0')\n",
      "tensor([[[ 9.2140],\n",
      "         [ 1.0682],\n",
      "         [-0.0200]]], device='cuda:0')\n",
      "tensor([[[9.2297e+00],\n",
      "         [1.0841e+00],\n",
      "         [7.2467e-03]]], device='cuda:0')\n",
      "tensor([[[9.2317],\n",
      "         [1.0669],\n",
      "         [0.0906]]], device='cuda:0')\n",
      "tensor([[[ 9.2449],\n",
      "         [ 1.0615],\n",
      "         [-0.0103]]], device='cuda:0')\n",
      "tensor([[[9.1945],\n",
      "         [0.9831],\n",
      "         [0.0534]]], device='cuda:0')\n",
      "tensor([[[ 9.2455],\n",
      "         [ 1.0857],\n",
      "         [-0.0524]]], device='cuda:0')\n",
      "tensor([[[ 9.1461e+00],\n",
      "         [ 1.1777e+00],\n",
      "         [-7.2145e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2677],\n",
      "         [ 1.0449],\n",
      "         [-0.0146]]], device='cuda:0')\n",
      "tensor([[[ 9.1822],\n",
      "         [ 1.1331],\n",
      "         [-0.0510]]], device='cuda:0')\n",
      "tensor([[[ 9.2474e+00],\n",
      "         [ 1.0515e+00],\n",
      "         [-9.0883e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2559],\n",
      "         [ 1.0557],\n",
      "         [-0.0193]]], device='cuda:0')\n",
      "tensor([[[ 9.2053],\n",
      "         [ 1.0594],\n",
      "         [-0.0338]]], device='cuda:0')\n",
      "tensor([[[ 9.2256],\n",
      "         [ 1.0689],\n",
      "         [-0.0342]]], device='cuda:0')\n",
      "tensor([[[ 9.2485],\n",
      "         [ 1.0870],\n",
      "         [-0.0523]]], device='cuda:0')\n",
      "tensor([[[ 9.1780],\n",
      "         [ 1.0518],\n",
      "         [-0.0273]]], device='cuda:0')\n",
      "tensor([[[ 9.2631],\n",
      "         [ 1.0642],\n",
      "         [-0.0228]]], device='cuda:0')\n",
      "tensor([[[ 9.1996e+00],\n",
      "         [ 1.0433e+00],\n",
      "         [-8.8463e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2150e+00],\n",
      "         [ 1.1718e+00],\n",
      "         [-4.0705e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2230e+00],\n",
      "         [ 9.9862e-01],\n",
      "         [-1.9893e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2412],\n",
      "         [ 1.0378],\n",
      "         [-0.0176]]], device='cuda:0')\n",
      "tensor([[[ 9.2517],\n",
      "         [ 1.0510],\n",
      "         [-0.0192]]], device='cuda:0')\n",
      "tensor([[[ 9.2258e+00],\n",
      "         [ 1.0466e+00],\n",
      "         [-7.7268e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2145],\n",
      "         [ 1.0420],\n",
      "         [-0.0287]]], device='cuda:0')\n",
      "tensor([[[ 9.2391],\n",
      "         [ 1.0660],\n",
      "         [-0.0302]]], device='cuda:0')\n",
      "tensor([[[ 9.2345],\n",
      "         [ 1.0863],\n",
      "         [-0.0498]]], device='cuda:0')\n",
      "tensor([[[9.2024],\n",
      "         [1.0473],\n",
      "         [0.0541]]], device='cuda:0')\n",
      "tensor([[[9.2185],\n",
      "         [1.0628],\n",
      "         [0.0275]]], device='cuda:0')\n",
      "tensor([[[ 9.2577],\n",
      "         [ 1.0591],\n",
      "         [-0.0181]]], device='cuda:0')\n",
      "tensor([[[ 9.2439],\n",
      "         [ 1.0212],\n",
      "         [-0.0767]]], device='cuda:0')\n",
      "tensor([[[ 9.2640],\n",
      "         [ 1.0701],\n",
      "         [-0.0308]]], device='cuda:0')\n",
      "tensor([[[9.2283],\n",
      "         [1.1040],\n",
      "         [0.1787]]], device='cuda:0')\n",
      "tensor([[[ 9.2391],\n",
      "         [ 1.0606],\n",
      "         [-0.0308]]], device='cuda:0')\n",
      "tensor([[[ 9.2203],\n",
      "         [ 1.0405],\n",
      "         [-0.0321]]], device='cuda:0')\n",
      "tensor([[[ 9.2445],\n",
      "         [ 1.0339],\n",
      "         [-0.0141]]], device='cuda:0')\n",
      "tensor([[[9.2311],\n",
      "         [1.0659],\n",
      "         [0.0867]]], device='cuda:0')\n",
      "tensor([[[ 9.2704],\n",
      "         [ 1.0343],\n",
      "         [-0.0099]]], device='cuda:0')\n",
      "tensor([[[9.1983],\n",
      "         [1.0682],\n",
      "         [0.0321]]], device='cuda:0')\n",
      "tensor([[[ 9.2333],\n",
      "         [ 1.0530],\n",
      "         [-0.0135]]], device='cuda:0')\n",
      "tensor([[[ 9.2100],\n",
      "         [ 1.0281],\n",
      "         [-0.0300]]], device='cuda:0')\n",
      "tensor([[[ 9.2012],\n",
      "         [ 1.0656],\n",
      "         [-0.0219]]], device='cuda:0')\n",
      "tensor([[[9.2361e+00],\n",
      "         [1.0500e+00],\n",
      "         [2.9299e-03]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[9.2565],\n",
      "         [1.0494],\n",
      "         [0.0105]]], device='cuda:0')\n",
      "tensor([[[ 9.2429e+00],\n",
      "         [ 1.0522e+00],\n",
      "         [-1.8967e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2600],\n",
      "         [ 1.0587],\n",
      "         [-0.0125]]], device='cuda:0')\n",
      "tensor([[[9.2205],\n",
      "         [1.0499],\n",
      "         [0.0169]]], device='cuda:0')\n",
      "tensor([[[9.2371],\n",
      "         [1.0517],\n",
      "         [0.0116]]], device='cuda:0')\n",
      "tensor([[[ 9.2241e+00],\n",
      "         [ 1.0531e+00],\n",
      "         [-2.7763e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2276e+00],\n",
      "         [ 1.0487e+00],\n",
      "         [-8.7254e-04]]], device='cuda:0')\n",
      "tensor([[[ 9.2350],\n",
      "         [ 1.0600],\n",
      "         [-0.0624]]], device='cuda:0')\n",
      "tensor([[[ 9.2429],\n",
      "         [ 1.0625],\n",
      "         [-0.0603]]], device='cuda:0')\n",
      "tensor([[[ 9.2527],\n",
      "         [ 1.0628],\n",
      "         [-0.0311]]], device='cuda:0')\n",
      "tensor([[[ 9.2621],\n",
      "         [ 1.0401],\n",
      "         [-0.0299]]], device='cuda:0')\n",
      "tensor([[[ 9.2166],\n",
      "         [ 1.0175],\n",
      "         [-0.0285]]], device='cuda:0')\n",
      "tensor([[[ 9.2447e+00],\n",
      "         [ 1.0622e+00],\n",
      "         [-5.3626e-03]]], device='cuda:0')\n",
      "tensor([[[9.2065],\n",
      "         [1.1034],\n",
      "         [0.1453]]], device='cuda:0')\n",
      "tensor([[[ 9.2338],\n",
      "         [ 1.0843],\n",
      "         [-0.0514]]], device='cuda:0')\n",
      "tensor([[[ 9.2196e+00],\n",
      "         [ 1.0617e+00],\n",
      "         [-3.2764e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2426],\n",
      "         [ 1.0559],\n",
      "         [-0.0138]]], device='cuda:0')\n",
      "tensor([[[ 9.2276],\n",
      "         [ 1.0717],\n",
      "         [-0.0099]]], device='cuda:0')\n",
      "tensor([[[ 9.2582],\n",
      "         [ 1.0642],\n",
      "         [-0.0258]]], device='cuda:0')\n",
      "tensor([[[ 9.2868],\n",
      "         [ 1.0627],\n",
      "         [-0.0369]]], device='cuda:0')\n",
      "tensor([[[ 9.2805],\n",
      "         [ 1.0412],\n",
      "         [-0.0300]]], device='cuda:0')\n",
      "tensor([[[ 9.2418],\n",
      "         [ 1.0710],\n",
      "         [-0.0327]]], device='cuda:0')\n",
      "tensor([[[9.2279],\n",
      "         [1.0656],\n",
      "         [0.0539]]], device='cuda:0')\n",
      "tensor([[[ 9.2295],\n",
      "         [ 1.0281],\n",
      "         [-0.0142]]], device='cuda:0')\n",
      "tensor([[[9.2095],\n",
      "         [1.0463],\n",
      "         [0.0521]]], device='cuda:0')\n",
      "tensor([[[ 9.2471],\n",
      "         [ 1.0550],\n",
      "         [-0.0336]]], device='cuda:0')\n",
      "tensor([[[ 9.2102e+00],\n",
      "         [ 1.0711e+00],\n",
      "         [-5.2274e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2347],\n",
      "         [ 1.0388],\n",
      "         [-0.0141]]], device='cuda:0')\n",
      "tensor([[[ 9.2555],\n",
      "         [ 1.0195],\n",
      "         [-0.0321]]], device='cuda:0')\n",
      "tensor([[[9.2709e+00],\n",
      "         [1.0864e+00],\n",
      "         [5.2666e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2161],\n",
      "         [ 1.0335],\n",
      "         [-0.0294]]], device='cuda:0')\n",
      "tensor([[[ 9.2616],\n",
      "         [ 1.0564],\n",
      "         [-0.0204]]], device='cuda:0')\n",
      "tensor([[[ 9.2436],\n",
      "         [ 1.0374],\n",
      "         [-0.0112]]], device='cuda:0')\n",
      "tensor([[[ 9.2379],\n",
      "         [ 1.0510],\n",
      "         [-0.0451]]], device='cuda:0')\n",
      "tensor([[[ 9.2217e+00],\n",
      "         [ 9.9040e-01],\n",
      "         [-8.0282e-03]]], device='cuda:0')\n",
      "tensor([[[9.2136],\n",
      "         [1.0681],\n",
      "         [0.0350]]], device='cuda:0')\n",
      "tensor([[[9.2372],\n",
      "         [1.0778],\n",
      "         [0.0160]]], device='cuda:0')\n",
      "tensor([[[ 9.2156e+00],\n",
      "         [ 1.0645e+00],\n",
      "         [-4.8868e-03]]], device='cuda:0')\n",
      "tensor([[[9.2344],\n",
      "         [1.0894],\n",
      "         [0.0299]]], device='cuda:0')\n",
      "tensor([[[ 9.2451],\n",
      "         [ 1.0226],\n",
      "         [-0.0296]]], device='cuda:0')\n",
      "tensor([[[ 9.2281],\n",
      "         [ 1.0403],\n",
      "         [-0.0436]]], device='cuda:0')\n",
      "tensor([[[ 9.2248],\n",
      "         [ 1.0488],\n",
      "         [-0.0103]]], device='cuda:0')\n",
      "tensor([[[ 9.2188],\n",
      "         [ 1.0196],\n",
      "         [-0.0442]]], device='cuda:0')\n",
      "tensor([[[ 9.2290],\n",
      "         [ 1.0582],\n",
      "         [-0.0262]]], device='cuda:0')\n",
      "tensor([[[9.2395e+00],\n",
      "         [1.0703e+00],\n",
      "         [3.9413e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2269],\n",
      "         [ 1.0344],\n",
      "         [-0.0231]]], device='cuda:0')\n",
      "tensor([[[ 9.2238],\n",
      "         [ 1.0991],\n",
      "         [-0.0419]]], device='cuda:0')\n",
      "tensor([[[ 9.2205],\n",
      "         [ 1.0493],\n",
      "         [-0.0096]]], device='cuda:0')\n",
      "tensor([[[9.1982],\n",
      "         [1.0464],\n",
      "         [0.0304]]], device='cuda:0')\n",
      "tensor([[[ 9.2529],\n",
      "         [ 0.9917],\n",
      "         [-0.0409]]], device='cuda:0')\n",
      "tensor([[[9.2203],\n",
      "         [1.0538],\n",
      "         [0.0130]]], device='cuda:0')\n",
      "tensor([[[ 9.2018],\n",
      "         [ 1.0589],\n",
      "         [-0.0132]]], device='cuda:0')\n",
      "tensor([[[ 9.2491],\n",
      "         [ 1.0355],\n",
      "         [-0.0298]]], device='cuda:0')\n",
      "tensor([[[9.2395],\n",
      "         [0.9881],\n",
      "         [0.0137]]], device='cuda:0')\n",
      "tensor([[[ 9.2755],\n",
      "         [ 1.0567],\n",
      "         [-0.0162]]], device='cuda:0')\n",
      "tensor([[[ 9.2513],\n",
      "         [ 1.0366],\n",
      "         [-0.0204]]], device='cuda:0')\n",
      "tensor([[[ 9.2308],\n",
      "         [ 1.0374],\n",
      "         [-0.0101]]], device='cuda:0')\n",
      "tensor([[[ 9.2250],\n",
      "         [ 1.0605],\n",
      "         [-0.0209]]], device='cuda:0')\n",
      "tensor([[[ 9.2251],\n",
      "         [ 1.0234],\n",
      "         [-0.1025]]], device='cuda:0')\n",
      "tensor([[[ 9.2543],\n",
      "         [ 1.0440],\n",
      "         [-0.0141]]], device='cuda:0')\n",
      "tensor([[[ 9.2366],\n",
      "         [ 1.0622],\n",
      "         [-0.0119]]], device='cuda:0')\n",
      "tensor([[[ 9.2440],\n",
      "         [ 1.0545],\n",
      "         [-0.0254]]], device='cuda:0')\n",
      "tensor([[[ 9.2539],\n",
      "         [ 0.9849],\n",
      "         [-0.0409]]], device='cuda:0')\n",
      "tensor([[[ 9.2533],\n",
      "         [ 1.0308],\n",
      "         [-0.0536]]], device='cuda:0')\n",
      "tensor([[[ 9.2458],\n",
      "         [ 1.0274],\n",
      "         [-0.0302]]], device='cuda:0')\n",
      "tensor([[[ 9.2299],\n",
      "         [ 1.0571],\n",
      "         [-0.0168]]], device='cuda:0')\n",
      "tensor([[[ 9.2637],\n",
      "         [ 1.0325],\n",
      "         [-0.0109]]], device='cuda:0')\n",
      "tensor([[[ 9.2158e+00],\n",
      "         [ 1.0646e+00],\n",
      "         [-7.7170e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2627],\n",
      "         [ 1.0579],\n",
      "         [-0.0137]]], device='cuda:0')\n",
      "tensor([[[ 9.2173],\n",
      "         [ 1.0327],\n",
      "         [-0.0303]]], device='cuda:0')\n",
      "tensor([[[9.2275],\n",
      "         [0.9843],\n",
      "         [0.0442]]], device='cuda:0')\n",
      "tensor([[[9.2497e+00],\n",
      "         [1.0690e+00],\n",
      "         [3.8392e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2504],\n",
      "         [ 1.0385],\n",
      "         [-0.0107]]], device='cuda:0')\n",
      "tensor([[[ 9.2266e+00],\n",
      "         [ 1.0718e+00],\n",
      "         [-7.0047e-03]]], device='cuda:0')\n",
      "tensor([[[9.2121],\n",
      "         [1.0648],\n",
      "         [0.0156]]], device='cuda:0')\n",
      "tensor([[[ 9.2542],\n",
      "         [ 1.0572],\n",
      "         [-0.0108]]], device='cuda:0')\n",
      "tensor([[[ 9.2312],\n",
      "         [ 1.0628],\n",
      "         [-0.0615]]], device='cuda:0')\n",
      "tensor([[[ 9.2473],\n",
      "         [ 1.0486],\n",
      "         [-0.0343]]], device='cuda:0')\n",
      "tensor([[[ 9.2107],\n",
      "         [ 1.0263],\n",
      "         [-0.0323]]], device='cuda:0')\n",
      "tensor([[[9.2307],\n",
      "         [1.0481],\n",
      "         [0.0850]]], device='cuda:0')\n",
      "tensor([[[ 9.2264e+00],\n",
      "         [ 1.0545e+00],\n",
      "         [-8.3399e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2347],\n",
      "         [ 1.0552],\n",
      "         [-0.0161]]], device='cuda:0')\n",
      "tensor([[[ 9.2281],\n",
      "         [ 1.0632],\n",
      "         [-0.0205]]], device='cuda:0')\n",
      "tensor([[[ 9.2493],\n",
      "         [ 1.0640],\n",
      "         [-0.0158]]], device='cuda:0')\n",
      "tensor([[[ 9.2469],\n",
      "         [ 1.0668],\n",
      "         [-0.0296]]], device='cuda:0')\n",
      "tensor([[[ 9.2189],\n",
      "         [ 1.0156],\n",
      "         [-0.0263]]], device='cuda:0')\n",
      "tensor([[[9.2137],\n",
      "         [1.0486],\n",
      "         [0.0696]]], device='cuda:0')\n",
      "tensor([[[ 9.2434],\n",
      "         [ 1.0606],\n",
      "         [-0.0257]]], device='cuda:0')\n",
      "tensor([[[ 9.2493e+00],\n",
      "         [ 1.0719e+00],\n",
      "         [-2.2429e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2296],\n",
      "         [ 0.9882],\n",
      "         [-0.0415]]], device='cuda:0')\n",
      "tensor([[[ 9.2438],\n",
      "         [ 1.0233],\n",
      "         [-0.0803]]], device='cuda:0')\n",
      "tensor([[[ 9.2285],\n",
      "         [ 1.0462],\n",
      "         [-0.0461]]], device='cuda:0')\n",
      "tensor([[[9.2034e+00],\n",
      "         [1.0739e+00],\n",
      "         [9.3118e-04]]], device='cuda:0')\n",
      "tensor([[[ 9.2356],\n",
      "         [ 1.0328],\n",
      "         [-0.0105]]], device='cuda:0')\n",
      "tensor([[[9.2341e+00],\n",
      "         [1.0546e+00],\n",
      "         [1.7237e-03]]], device='cuda:0')\n",
      "tensor([[[9.2303],\n",
      "         [1.0598],\n",
      "         [0.0478]]], device='cuda:0')\n",
      "tensor([[[ 9.2610],\n",
      "         [ 1.0256],\n",
      "         [-0.0120]]], device='cuda:0')\n",
      "tensor([[[ 9.2319],\n",
      "         [ 1.0259],\n",
      "         [-0.0348]]], device='cuda:0')\n",
      "tensor([[[ 9.2250],\n",
      "         [ 1.0706],\n",
      "         [-0.0145]]], device='cuda:0')\n",
      "tensor([[[ 9.2404],\n",
      "         [ 1.0281],\n",
      "         [-0.0307]]], device='cuda:0')\n",
      "tensor([[[ 9.2783],\n",
      "         [ 1.0420],\n",
      "         [-0.0116]]], device='cuda:0')\n",
      "tensor([[[9.2475e+00],\n",
      "         [1.0555e+00],\n",
      "         [3.3762e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2506],\n",
      "         [ 1.0638],\n",
      "         [-0.0479]]], device='cuda:0')\n",
      "tensor([[[ 9.2392],\n",
      "         [ 1.0652],\n",
      "         [-0.0289]]], device='cuda:0')\n",
      "tensor([[[9.2281e+00],\n",
      "         [1.0534e+00],\n",
      "         [1.0347e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2502e+00],\n",
      "         [ 1.0872e+00],\n",
      "         [-8.9429e-04]]], device='cuda:0')\n",
      "tensor([[[9.1894],\n",
      "         [1.0728],\n",
      "         [0.0509]]], device='cuda:0')\n",
      "tensor([[[ 9.2697],\n",
      "         [ 1.0313],\n",
      "         [-0.0277]]], device='cuda:0')\n",
      "tensor([[[9.2246],\n",
      "         [1.0699],\n",
      "         [0.1091]]], device='cuda:0')\n",
      "tensor([[[9.2524e+00],\n",
      "         [1.0890e+00],\n",
      "         [7.0975e-03]]], device='cuda:0')\n",
      "tensor([[[9.1954],\n",
      "         [1.0639],\n",
      "         [0.0484]]], device='cuda:0')\n",
      "tensor([[[ 9.2271],\n",
      "         [ 1.0541],\n",
      "         [-0.0463]]], device='cuda:0')\n",
      "tensor([[[ 9.2638e+00],\n",
      "         [ 1.0672e+00],\n",
      "         [-6.8957e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2753e+00],\n",
      "         [ 1.0570e+00],\n",
      "         [-8.1544e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2386],\n",
      "         [ 1.0212],\n",
      "         [-0.0855]]], device='cuda:0')\n",
      "tensor([[[ 9.2457],\n",
      "         [ 1.0298],\n",
      "         [-0.0169]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9.2625],\n",
      "         [ 1.0300],\n",
      "         [-0.0154]]], device='cuda:0')\n",
      "tensor([[[ 9.2630],\n",
      "         [ 1.0404],\n",
      "         [-0.0106]]], device='cuda:0')\n",
      "tensor([[[ 9.2037],\n",
      "         [ 1.0037],\n",
      "         [-0.0126]]], device='cuda:0')\n",
      "tensor([[[ 9.2249],\n",
      "         [ 1.0930],\n",
      "         [-0.0526]]], device='cuda:0')\n",
      "tensor([[[9.2588e+00],\n",
      "         [1.0896e+00],\n",
      "         [7.6178e-03]]], device='cuda:0')\n",
      "tensor([[[9.1550],\n",
      "         [1.0426],\n",
      "         [0.0368]]], device='cuda:0')\n",
      "tensor([[[9.2696e+00],\n",
      "         [1.0504e+00],\n",
      "         [5.7971e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2412e+00],\n",
      "         [ 1.0586e+00],\n",
      "         [-8.8854e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2255],\n",
      "         [ 1.0409],\n",
      "         [-0.0195]]], device='cuda:0')\n",
      "tensor([[[ 9.2415],\n",
      "         [ 1.0633],\n",
      "         [-0.0732]]], device='cuda:0')\n",
      "tensor([[[9.2169],\n",
      "         [1.0630],\n",
      "         [0.0520]]], device='cuda:0')\n",
      "tensor([[[ 9.2335],\n",
      "         [ 1.0523],\n",
      "         [-0.0307]]], device='cuda:0')\n",
      "tensor([[[9.2753],\n",
      "         [1.0485],\n",
      "         [0.0119]]], device='cuda:0')\n",
      "tensor([[[ 9.2091],\n",
      "         [ 1.0271],\n",
      "         [-0.0310]]], device='cuda:0')\n",
      "tensor([[[ 9.2136e+00],\n",
      "         [ 1.0608e+00],\n",
      "         [-6.7107e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.1996e+00],\n",
      "         [ 1.0709e+00],\n",
      "         [-7.9996e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2482e+00],\n",
      "         [ 1.0668e+00],\n",
      "         [-3.8305e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2173],\n",
      "         [ 1.0584],\n",
      "         [-0.0340]]], device='cuda:0')\n",
      "tensor([[[ 9.2647],\n",
      "         [ 1.0699],\n",
      "         [-0.0415]]], device='cuda:0')\n",
      "tensor([[[ 9.2473],\n",
      "         [ 1.0730],\n",
      "         [-0.0194]]], device='cuda:0')\n",
      "tensor([[[ 9.2054],\n",
      "         [ 1.0450],\n",
      "         [-0.0343]]], device='cuda:0')\n",
      "tensor([[[ 9.2402],\n",
      "         [ 1.0457],\n",
      "         [-0.0121]]], device='cuda:0')\n",
      "tensor([[[ 9.2254e+00],\n",
      "         [ 1.0645e+00],\n",
      "         [-4.8194e-03]]], device='cuda:0')\n",
      "tensor([[[9.2553e+00],\n",
      "         [1.0615e+00],\n",
      "         [7.3387e-03]]], device='cuda:0')\n",
      "tensor([[[9.2169],\n",
      "         [1.0653],\n",
      "         [0.0245]]], device='cuda:0')\n",
      "tensor([[[9.2219],\n",
      "         [1.0460],\n",
      "         [0.0514]]], device='cuda:0')\n",
      "tensor([[[ 9.2314],\n",
      "         [ 1.0341],\n",
      "         [-0.0217]]], device='cuda:0')\n",
      "tensor([[[9.2045e+00],\n",
      "         [1.0548e+00],\n",
      "         [8.9851e-04]]], device='cuda:0')\n",
      "tensor([[[9.2205],\n",
      "         [1.0499],\n",
      "         [0.0169]]], device='cuda:0')\n",
      "tensor([[[9.2308],\n",
      "         [1.0548],\n",
      "         [0.0126]]], device='cuda:0')\n",
      "tensor([[[ 9.2303],\n",
      "         [ 1.0346],\n",
      "         [-0.0381]]], device='cuda:0')\n",
      "tensor([[[ 9.2290],\n",
      "         [ 1.0645],\n",
      "         [-0.0248]]], device='cuda:0')\n",
      "tensor([[[9.2574],\n",
      "         [1.0490],\n",
      "         [0.0114]]], device='cuda:0')\n",
      "tensor([[[ 9.2499],\n",
      "         [ 1.0641],\n",
      "         [-0.0175]]], device='cuda:0')\n",
      "tensor([[[ 9.2173],\n",
      "         [ 1.0011],\n",
      "         [-0.0130]]], device='cuda:0')\n",
      "tensor([[[ 9.2690],\n",
      "         [ 1.0541],\n",
      "         [-0.0106]]], device='cuda:0')\n",
      "tensor([[[ 9.2536e+00],\n",
      "         [ 1.0704e+00],\n",
      "         [-2.1240e-03]]], device='cuda:0')\n",
      "tensor([[[9.2218],\n",
      "         [1.0708],\n",
      "         [0.0514]]], device='cuda:0')\n",
      "tensor([[[9.2032],\n",
      "         [1.0758],\n",
      "         [0.0147]]], device='cuda:0')\n",
      "tensor([[[9.2199],\n",
      "         [1.1075],\n",
      "         [0.1814]]], device='cuda:0')\n",
      "tensor([[[ 9.2297],\n",
      "         [ 1.0608],\n",
      "         [-0.0185]]], device='cuda:0')\n",
      "tensor([[[ 9.1796],\n",
      "         [ 1.1870],\n",
      "         [-0.0322]]], device='cuda:0')\n",
      "tensor([[[ 9.2886],\n",
      "         [ 1.0732],\n",
      "         [-0.0416]]], device='cuda:0')\n",
      "tensor([[[ 9.2018],\n",
      "         [ 1.0589],\n",
      "         [-0.0132]]], device='cuda:0')\n",
      "tensor([[[9.2505e+00],\n",
      "         [1.0500e+00],\n",
      "         [3.7576e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2684],\n",
      "         [ 1.0483],\n",
      "         [-0.0398]]], device='cuda:0')\n",
      "tensor([[[ 9.2196e+00],\n",
      "         [ 1.0442e+00],\n",
      "         [-8.0847e-03]]], device='cuda:0')\n",
      "tensor([[[9.2568e+00],\n",
      "         [1.0481e+00],\n",
      "         [6.8682e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2166],\n",
      "         [ 0.9843],\n",
      "         [-0.0406]]], device='cuda:0')\n",
      "tensor([[[ 9.2032],\n",
      "         [ 1.0537],\n",
      "         [-0.0475]]], device='cuda:0')\n",
      "tensor([[[ 9.2345],\n",
      "         [ 1.0589],\n",
      "         [-0.0269]]], device='cuda:0')\n",
      "tensor([[[ 9.2411e+00],\n",
      "         [ 1.0634e+00],\n",
      "         [-4.6615e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2162],\n",
      "         [ 1.0440],\n",
      "         [-0.0127]]], device='cuda:0')\n",
      "tensor([[[ 9.2326],\n",
      "         [ 1.0842],\n",
      "         [-0.0487]]], device='cuda:0')\n",
      "tensor([[[9.2374e+00],\n",
      "         [1.0530e+00],\n",
      "         [5.1075e-04]]], device='cuda:0')\n",
      "tensor([[[ 9.2672],\n",
      "         [ 1.0525],\n",
      "         [-0.0274]]], device='cuda:0')\n",
      "tensor([[[ 9.2601],\n",
      "         [ 1.0383],\n",
      "         [-0.0115]]], device='cuda:0')\n",
      "tensor([[[ 9.2355e+00],\n",
      "         [ 1.0553e+00],\n",
      "         [-1.5377e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2427],\n",
      "         [ 1.0449],\n",
      "         [-0.0330]]], device='cuda:0')\n",
      "tensor([[[ 9.2528],\n",
      "         [ 1.0342],\n",
      "         [-0.0108]]], device='cuda:0')\n",
      "tensor([[[9.2580],\n",
      "         [1.0536],\n",
      "         [0.0163]]], device='cuda:0')\n",
      "tensor([[[9.1979],\n",
      "         [1.1065],\n",
      "         [0.1711]]], device='cuda:0')\n",
      "tensor([[[ 9.2258],\n",
      "         [ 1.0573],\n",
      "         [-0.0214]]], device='cuda:0')\n",
      "tensor([[[ 9.2367],\n",
      "         [ 1.0617],\n",
      "         [-0.0636]]], device='cuda:0')\n",
      "tensor([[[ 9.2394],\n",
      "         [ 1.0519],\n",
      "         [-0.0104]]], device='cuda:0')\n",
      "tensor([[[ 9.2645],\n",
      "         [ 1.0703],\n",
      "         [-0.0100]]], device='cuda:0')\n",
      "tensor([[[ 9.2074],\n",
      "         [ 1.0293],\n",
      "         [-0.0311]]], device='cuda:0')\n",
      "tensor([[[ 9.2376],\n",
      "         [ 1.0883],\n",
      "         [-0.0547]]], device='cuda:0')\n",
      "tensor([[[ 9.2318],\n",
      "         [ 1.0168],\n",
      "         [-0.0829]]], device='cuda:0')\n",
      "tensor([[[ 9.2476],\n",
      "         [ 1.0675],\n",
      "         [-0.0227]]], device='cuda:0')\n",
      "tensor([[[ 9.2412],\n",
      "         [ 1.0832],\n",
      "         [-0.0100]]], device='cuda:0')\n",
      "tensor([[[ 9.2374],\n",
      "         [ 1.0448],\n",
      "         [-0.0290]]], device='cuda:0')\n",
      "tensor([[[9.2379e+00],\n",
      "         [9.8693e-01],\n",
      "         [1.1314e-03]]], device='cuda:0')\n",
      "tensor([[[9.2144],\n",
      "         [1.1036],\n",
      "         [0.1706]]], device='cuda:0')\n",
      "tensor([[[ 9.2220],\n",
      "         [ 1.0431],\n",
      "         [-0.0136]]], device='cuda:0')\n",
      "tensor([[[ 9.2825],\n",
      "         [ 1.0710],\n",
      "         [-0.0355]]], device='cuda:0')\n",
      "tensor([[[9.2175e+00],\n",
      "         [1.0527e+00],\n",
      "         [5.8579e-05]]], device='cuda:0')\n",
      "tensor([[[ 9.2551e+00],\n",
      "         [ 1.0826e+00],\n",
      "         [-2.1335e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2291],\n",
      "         [ 1.0260],\n",
      "         [-0.0143]]], device='cuda:0')\n",
      "tensor([[[ 9.2133e+00],\n",
      "         [ 1.0473e+00],\n",
      "         [-8.5467e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2534],\n",
      "         [ 1.0460],\n",
      "         [-0.0132]]], device='cuda:0')\n",
      "tensor([[[9.2118],\n",
      "         [1.0892],\n",
      "         [0.0228]]], device='cuda:0')\n",
      "tensor([[[9.2312],\n",
      "         [1.0660],\n",
      "         [0.0349]]], device='cuda:0')\n",
      "tensor([[[ 9.2492],\n",
      "         [ 1.0502],\n",
      "         [-0.0476]]], device='cuda:0')\n",
      "tensor([[[ 9.2413],\n",
      "         [ 1.0599],\n",
      "         [-0.0216]]], device='cuda:0')\n",
      "tensor([[[ 9.2323],\n",
      "         [ 1.0867],\n",
      "         [-0.0517]]], device='cuda:0')\n",
      "tensor([[[9.2106e+00],\n",
      "         [1.0471e+00],\n",
      "         [7.4271e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2280],\n",
      "         [ 1.0495],\n",
      "         [-0.0493]]], device='cuda:0')\n",
      "tensor([[[ 9.2495],\n",
      "         [ 1.0727],\n",
      "         [-0.0225]]], device='cuda:0')\n",
      "tensor([[[ 9.1968],\n",
      "         [ 1.0538],\n",
      "         [-0.0128]]], device='cuda:0')\n",
      "tensor([[[ 9.2382e+00],\n",
      "         [ 1.0498e+00],\n",
      "         [-4.0073e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2235e+00],\n",
      "         [ 1.0568e+00],\n",
      "         [-8.9114e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2026],\n",
      "         [ 1.0557],\n",
      "         [-0.0337]]], device='cuda:0')\n",
      "tensor([[[ 9.2161],\n",
      "         [ 1.0658],\n",
      "         [-0.0204]]], device='cuda:0')\n",
      "tensor([[[ 9.2496],\n",
      "         [ 1.0281],\n",
      "         [-0.0560]]], device='cuda:0')\n",
      "tensor([[[ 9.2461],\n",
      "         [ 1.0689],\n",
      "         [-0.0348]]], device='cuda:0')\n",
      "tensor([[[ 9.2522e+00],\n",
      "         [ 1.0651e+00],\n",
      "         [-3.8546e-03]]], device='cuda:0')\n",
      "tensor([[[9.2317e+00],\n",
      "         [1.0541e+00],\n",
      "         [3.3251e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2380e+00],\n",
      "         [ 9.8629e-01],\n",
      "         [-2.0348e-03]]], device='cuda:0')\n",
      "tensor([[[9.2533],\n",
      "         [1.0484],\n",
      "         [0.0128]]], device='cuda:0')\n",
      "tensor([[[ 9.2545],\n",
      "         [ 1.0661],\n",
      "         [-0.0193]]], device='cuda:0')\n",
      "tensor([[[ 9.2676],\n",
      "         [ 1.0311],\n",
      "         [-0.0149]]], device='cuda:0')\n",
      "tensor([[[9.2367e+00],\n",
      "         [1.0542e+00],\n",
      "         [1.2316e-03]]], device='cuda:0')\n",
      "tensor([[[9.2051],\n",
      "         [1.0732],\n",
      "         [0.0467]]], device='cuda:0')\n",
      "tensor([[[ 9.2180],\n",
      "         [ 1.0659],\n",
      "         [-0.0218]]], device='cuda:0')\n",
      "tensor([[[ 9.2635],\n",
      "         [ 1.0838],\n",
      "         [-0.0517]]], device='cuda:0')\n",
      "tensor([[[ 9.2401],\n",
      "         [ 1.0922],\n",
      "         [-0.0484]]], device='cuda:0')\n",
      "tensor([[[ 9.2165],\n",
      "         [ 1.0607],\n",
      "         [-0.0377]]], device='cuda:0')\n",
      "tensor([[[9.2317],\n",
      "         [1.0610],\n",
      "         [0.0498]]], device='cuda:0')\n",
      "tensor([[[9.2370],\n",
      "         [1.0680],\n",
      "         [0.1557]]], device='cuda:0')\n",
      "tensor([[[ 9.2736],\n",
      "         [ 1.0711],\n",
      "         [-0.0218]]], device='cuda:0')\n",
      "tensor([[[ 9.2418],\n",
      "         [ 1.0713],\n",
      "         [-0.0098]]], device='cuda:0')\n",
      "tensor([[[9.2395],\n",
      "         [0.9881],\n",
      "         [0.0137]]], device='cuda:0')\n",
      "tensor([[[ 9.2551],\n",
      "         [ 1.0492],\n",
      "         [-0.0338]]], device='cuda:0')\n",
      "tensor([[[ 9.2236],\n",
      "         [ 1.0288],\n",
      "         [-0.0335]]], device='cuda:0')\n",
      "tensor([[[9.2249e+00],\n",
      "         [1.0516e+00],\n",
      "         [3.4474e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2287e+00],\n",
      "         [ 1.0000e+00],\n",
      "         [-4.1656e-03]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9.2079],\n",
      "         [ 1.0457],\n",
      "         [-0.0295]]], device='cuda:0')\n",
      "tensor([[[ 9.2428],\n",
      "         [ 1.0476],\n",
      "         [-0.0322]]], device='cuda:0')\n",
      "tensor([[[9.2193],\n",
      "         [1.0455],\n",
      "         [0.0542]]], device='cuda:0')\n",
      "tensor([[[ 9.2142],\n",
      "         [ 1.0662],\n",
      "         [-0.0198]]], device='cuda:0')\n",
      "tensor([[[ 9.2592],\n",
      "         [ 1.0466],\n",
      "         [-0.0106]]], device='cuda:0')\n",
      "tensor([[[ 9.2277],\n",
      "         [ 1.0370],\n",
      "         [-0.0119]]], device='cuda:0')\n",
      "tensor([[[ 9.2505],\n",
      "         [ 1.0715],\n",
      "         [-0.0351]]], device='cuda:0')\n",
      "tensor([[[ 9.2534],\n",
      "         [ 1.0660],\n",
      "         [-0.0355]]], device='cuda:0')\n",
      "tensor([[[ 9.2455],\n",
      "         [ 1.0640],\n",
      "         [-0.0125]]], device='cuda:0')\n",
      "tensor([[[ 9.2228],\n",
      "         [ 1.0278],\n",
      "         [-0.0254]]], device='cuda:0')\n",
      "tensor([[[ 9.2087],\n",
      "         [ 1.0862],\n",
      "         [-0.0556]]], device='cuda:0')\n",
      "tensor([[[ 9.2113],\n",
      "         [ 1.0468],\n",
      "         [-0.0357]]], device='cuda:0')\n",
      "tensor([[[ 9.2189],\n",
      "         [ 1.0596],\n",
      "         [-0.0257]]], device='cuda:0')\n",
      "tensor([[[ 9.2397],\n",
      "         [ 1.0324],\n",
      "         [-0.0598]]], device='cuda:0')\n",
      "tensor([[[ 9.2502],\n",
      "         [ 1.0589],\n",
      "         [-0.0292]]], device='cuda:0')\n",
      "tensor([[[ 9.2138],\n",
      "         [ 1.0284],\n",
      "         [-0.0349]]], device='cuda:0')\n",
      "tensor([[[ 9.2155],\n",
      "         [ 1.0330],\n",
      "         [-0.0229]]], device='cuda:0')\n",
      "tensor([[[ 9.2564],\n",
      "         [ 1.0936],\n",
      "         [-0.0430]]], device='cuda:0')\n",
      "tensor([[[ 9.2610],\n",
      "         [ 1.0055],\n",
      "         [-0.0127]]], device='cuda:0')\n",
      "tensor([[[ 9.2144],\n",
      "         [ 1.0366],\n",
      "         [-0.0146]]], device='cuda:0')\n",
      "tensor([[[ 9.2270],\n",
      "         [ 1.0525],\n",
      "         [-0.0123]]], device='cuda:0')\n",
      "tensor([[[ 9.2471],\n",
      "         [ 1.0209],\n",
      "         [-0.0322]]], device='cuda:0')\n",
      "tensor([[[9.2286],\n",
      "         [1.0426],\n",
      "         [0.0790]]], device='cuda:0')\n",
      "tensor([[[ 9.2357e+00],\n",
      "         [ 1.0504e+00],\n",
      "         [-7.0444e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2700],\n",
      "         [ 1.0600],\n",
      "         [-0.0367]]], device='cuda:0')\n",
      "tensor([[[ 9.2356],\n",
      "         [ 1.0287],\n",
      "         [-0.0171]]], device='cuda:0')\n",
      "tensor([[[ 9.2361],\n",
      "         [ 1.0640],\n",
      "         [-0.0242]]], device='cuda:0')\n",
      "tensor([[[ 9.2576],\n",
      "         [ 1.0692],\n",
      "         [-0.0227]]], device='cuda:0')\n",
      "tensor([[[ 9.2290],\n",
      "         [ 1.0664],\n",
      "         [-0.0122]]], device='cuda:0')\n",
      "tensor([[[9.2505e+00],\n",
      "         [1.0556e+00],\n",
      "         [3.1845e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2286],\n",
      "         [ 1.0511],\n",
      "         [-0.0640]]], device='cuda:0')\n",
      "tensor([[[ 9.2572],\n",
      "         [ 1.0631],\n",
      "         [-0.0246]]], device='cuda:0')\n",
      "tensor([[[9.1938],\n",
      "         [1.0693],\n",
      "         [0.0402]]], device='cuda:0')\n",
      "tensor([[[ 9.2412e+00],\n",
      "         [ 1.0699e+00],\n",
      "         [-3.2066e-04]]], device='cuda:0')\n",
      "tensor([[[ 9.2523],\n",
      "         [ 1.0589],\n",
      "         [-0.0372]]], device='cuda:0')\n",
      "tensor([[[ 9.2341],\n",
      "         [ 1.0753],\n",
      "         [-0.0401]]], device='cuda:0')\n",
      "tensor([[[ 9.2024e+00],\n",
      "         [ 9.9912e-01],\n",
      "         [-8.4023e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2590],\n",
      "         [ 1.0527],\n",
      "         [-0.0339]]], device='cuda:0')\n",
      "tensor([[[ 9.2316e+00],\n",
      "         [ 1.0634e+00],\n",
      "         [-4.5673e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2410],\n",
      "         [ 1.0632],\n",
      "         [-0.0228]]], device='cuda:0')\n",
      "tensor([[[9.2293],\n",
      "         [1.0481],\n",
      "         [0.0107]]], device='cuda:0')\n",
      "tensor([[[ 9.2241e+00],\n",
      "         [ 1.0531e+00],\n",
      "         [-2.7763e-03]]], device='cuda:0')\n",
      "tensor([[[9.2362],\n",
      "         [1.0510],\n",
      "         [0.0108]]], device='cuda:0')\n",
      "tensor([[[ 9.2324],\n",
      "         [ 1.0419],\n",
      "         [-0.0293]]], device='cuda:0')\n",
      "tensor([[[ 9.2427],\n",
      "         [ 1.0386],\n",
      "         [-0.0108]]], device='cuda:0')\n",
      "tensor([[[ 9.2492],\n",
      "         [ 1.0828],\n",
      "         [-0.0118]]], device='cuda:0')\n",
      "tensor([[[ 9.2576],\n",
      "         [ 1.0694],\n",
      "         [-0.0355]]], device='cuda:0')\n",
      "tensor([[[ 9.2218e+00],\n",
      "         [ 1.0033e+00],\n",
      "         [-2.7856e-03]]], device='cuda:0')\n",
      "tensor([[[9.2346e+00],\n",
      "         [1.0500e+00],\n",
      "         [4.1022e-04]]], device='cuda:0')\n",
      "tensor([[[ 9.2552],\n",
      "         [ 1.0370],\n",
      "         [-0.0192]]], device='cuda:0')\n",
      "tensor([[[9.2435],\n",
      "         [1.0725],\n",
      "         [0.0154]]], device='cuda:0')\n",
      "tensor([[[9.2415],\n",
      "         [1.0667],\n",
      "         [0.0926]]], device='cuda:0')\n",
      "tensor([[[ 9.2496],\n",
      "         [ 1.0575],\n",
      "         [-0.0243]]], device='cuda:0')\n",
      "tensor([[[ 9.2600],\n",
      "         [ 1.0678],\n",
      "         [-0.0200]]], device='cuda:0')\n",
      "tensor([[[ 9.2408],\n",
      "         [ 1.0694],\n",
      "         [-0.0357]]], device='cuda:0')\n",
      "tensor([[[ 9.2159e+00],\n",
      "         [ 1.0631e+00],\n",
      "         [-8.6113e-03]]], device='cuda:0')\n",
      "tensor([[[9.2216],\n",
      "         [1.0456],\n",
      "         [0.0527]]], device='cuda:0')\n",
      "tensor([[[9.2339],\n",
      "         [1.0471],\n",
      "         [0.0518]]], device='cuda:0')\n",
      "tensor([[[ 9.2408],\n",
      "         [ 1.0615],\n",
      "         [-0.0475]]], device='cuda:0')\n",
      "tensor([[[ 9.2290],\n",
      "         [ 1.0913],\n",
      "         [-0.0454]]], device='cuda:0')\n",
      "tensor([[[ 9.2122],\n",
      "         [ 1.0960],\n",
      "         [-0.0482]]], device='cuda:0')\n",
      "tensor([[[ 9.2625],\n",
      "         [ 1.0668],\n",
      "         [-0.0294]]], device='cuda:0')\n",
      "tensor([[[9.2183],\n",
      "         [1.1084],\n",
      "         [0.1810]]], device='cuda:0')\n",
      "tensor([[[9.2438],\n",
      "         [1.0075],\n",
      "         [0.0190]]], device='cuda:0')\n",
      "tensor([[[ 9.2307],\n",
      "         [ 1.0365],\n",
      "         [-0.0459]]], device='cuda:0')\n",
      "tensor([[[ 9.2317],\n",
      "         [ 1.0427],\n",
      "         [-0.0117]]], device='cuda:0')\n",
      "tensor([[[ 9.2791],\n",
      "         [ 1.0415],\n",
      "         [-0.0109]]], device='cuda:0')\n",
      "tensor([[[ 9.2360],\n",
      "         [ 1.0656],\n",
      "         [-0.0255]]], device='cuda:0')\n",
      "tensor([[[9.2207],\n",
      "         [1.0519],\n",
      "         [0.0093]]], device='cuda:0')\n",
      "tensor([[[ 9.2312],\n",
      "         [ 1.0644],\n",
      "         [-0.0156]]], device='cuda:0')\n",
      "tensor([[[ 9.2218],\n",
      "         [ 1.0591],\n",
      "         [-0.0195]]], device='cuda:0')\n",
      "tensor([[[ 9.2436e+00],\n",
      "         [ 1.0640e+00],\n",
      "         [-8.5339e-03]]], device='cuda:0')\n",
      "tensor([[[9.2161],\n",
      "         [1.0680],\n",
      "         [0.0351]]], device='cuda:0')\n",
      "tensor([[[ 9.2640],\n",
      "         [ 1.0701],\n",
      "         [-0.0308]]], device='cuda:0')\n",
      "tensor([[[ 9.2349e+00],\n",
      "         [ 1.0456e+00],\n",
      "         [-8.9533e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2309],\n",
      "         [ 1.0748],\n",
      "         [-0.0332]]], device='cuda:0')\n",
      "tensor([[[9.2312],\n",
      "         [1.0474],\n",
      "         [0.0556]]], device='cuda:0')\n",
      "tensor([[[ 9.2092],\n",
      "         [ 1.0321],\n",
      "         [-0.0551]]], device='cuda:0')\n",
      "tensor([[[9.2424],\n",
      "         [1.0671],\n",
      "         [0.0458]]], device='cuda:0')\n",
      "tensor([[[ 9.1906],\n",
      "         [ 1.0662],\n",
      "         [-0.0111]]], device='cuda:0')\n",
      "tensor([[[ 9.2629],\n",
      "         [ 1.0617],\n",
      "         [-0.0363]]], device='cuda:0')\n",
      "tensor([[[ 9.2525],\n",
      "         [ 1.0458],\n",
      "         [-0.0470]]], device='cuda:0')\n",
      "tensor([[[9.2451e+00],\n",
      "         [1.0885e+00],\n",
      "         [9.0270e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2372e+00],\n",
      "         [ 1.0487e+00],\n",
      "         [-4.3570e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.1704e+00],\n",
      "         [ 1.1791e+00],\n",
      "         [-2.4078e-03]]], device='cuda:0')\n",
      "tensor([[[9.2200],\n",
      "         [1.1085],\n",
      "         [0.1580]]], device='cuda:0')\n",
      "tensor([[[ 9.2526],\n",
      "         [ 1.0696],\n",
      "         [-0.0188]]], device='cuda:0')\n",
      "tensor([[[ 9.2337],\n",
      "         [ 1.0633],\n",
      "         [-0.0111]]], device='cuda:0')\n",
      "tensor([[[ 9.2041e+00],\n",
      "         [ 1.0772e+00],\n",
      "         [-5.6979e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2146],\n",
      "         [ 1.0639],\n",
      "         [-0.0221]]], device='cuda:0')\n",
      "tensor([[[9.1966],\n",
      "         [0.9814],\n",
      "         [0.0631]]], device='cuda:0')\n",
      "tensor([[[9.2416],\n",
      "         [1.0506],\n",
      "         [0.0138]]], device='cuda:0')\n",
      "tensor([[[9.2082e+00],\n",
      "         [1.0862e+00],\n",
      "         [2.5129e-03]]], device='cuda:0')\n",
      "tensor([[[9.2038],\n",
      "         [1.0674],\n",
      "         [0.0424]]], device='cuda:0')\n",
      "tensor([[[ 9.2519],\n",
      "         [ 1.0625],\n",
      "         [-0.0478]]], device='cuda:0')\n",
      "tensor([[[ 9.2398],\n",
      "         [ 1.0564],\n",
      "         [-0.0139]]], device='cuda:0')\n",
      "tensor([[[ 9.2339],\n",
      "         [ 1.0623],\n",
      "         [-0.0208]]], device='cuda:0')\n",
      "tensor([[[ 9.2458],\n",
      "         [ 1.0551],\n",
      "         [-0.0134]]], device='cuda:0')\n",
      "tensor([[[ 9.2457],\n",
      "         [ 1.0568],\n",
      "         [-0.0157]]], device='cuda:0')\n",
      "tensor([[[ 9.2231],\n",
      "         [ 1.0497],\n",
      "         [-0.0145]]], device='cuda:0')\n",
      "tensor([[[ 9.2196e+00],\n",
      "         [ 1.0532e+00],\n",
      "         [-6.2330e-03]]], device='cuda:0')\n",
      "tensor([[[9.2212],\n",
      "         [1.0719],\n",
      "         [0.0394]]], device='cuda:0')\n",
      "tensor([[[ 9.2058],\n",
      "         [ 1.0232],\n",
      "         [-0.0163]]], device='cuda:0')\n",
      "tensor([[[ 9.2243],\n",
      "         [ 1.0614],\n",
      "         [-0.0168]]], device='cuda:0')\n",
      "tensor([[[ 9.2509],\n",
      "         [ 1.0588],\n",
      "         [-0.0102]]], device='cuda:0')\n",
      "tensor([[[9.2518e+00],\n",
      "         [1.0677e+00],\n",
      "         [3.0205e-03]]], device='cuda:0')\n",
      "tensor([[[9.2305],\n",
      "         [1.0711],\n",
      "         [0.1199]]], device='cuda:0')\n",
      "tensor([[[9.2513],\n",
      "         [0.9823],\n",
      "         [0.0626]]], device='cuda:0')\n",
      "tensor([[[ 9.2214],\n",
      "         [ 1.0608],\n",
      "         [-0.0187]]], device='cuda:0')\n",
      "tensor([[[ 9.2510],\n",
      "         [ 1.0623],\n",
      "         [-0.0484]]], device='cuda:0')\n",
      "tensor([[[ 9.2393],\n",
      "         [ 1.0852],\n",
      "         [-0.0535]]], device='cuda:0')\n",
      "tensor([[[ 9.2408e+00],\n",
      "         [ 1.0654e+00],\n",
      "         [-4.7785e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2423e+00],\n",
      "         [ 1.0637e+00],\n",
      "         [-4.0552e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2396],\n",
      "         [ 1.0616],\n",
      "         [-0.0664]]], device='cuda:0')\n",
      "tensor([[[ 9.2346],\n",
      "         [ 1.0409],\n",
      "         [-0.0308]]], device='cuda:0')\n",
      "tensor([[[ 9.2397],\n",
      "         [ 1.0629],\n",
      "         [-0.0165]]], device='cuda:0')\n",
      "tensor([[[9.2056],\n",
      "         [1.0614],\n",
      "         [0.0245]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9.2292],\n",
      "         [ 1.0862],\n",
      "         [-0.0530]]], device='cuda:0')\n",
      "tensor([[[9.2247],\n",
      "         [1.0477],\n",
      "         [0.0134]]], device='cuda:0')\n",
      "tensor([[[ 9.2276],\n",
      "         [ 1.0418],\n",
      "         [-0.0150]]], device='cuda:0')\n",
      "tensor([[[9.2137],\n",
      "         [1.0617],\n",
      "         [0.0187]]], device='cuda:0')\n",
      "tensor([[[ 9.2433],\n",
      "         [ 1.0618],\n",
      "         [-0.0702]]], device='cuda:0')\n",
      "tensor([[[9.2443e+00],\n",
      "         [1.0537e+00],\n",
      "         [4.3889e-03]]], device='cuda:0')\n",
      "tensor([[[9.1957],\n",
      "         [1.0615],\n",
      "         [0.0472]]], device='cuda:0')\n",
      "tensor([[[ 9.2535],\n",
      "         [ 1.0592],\n",
      "         [-0.0171]]], device='cuda:0')\n",
      "tensor([[[ 9.2582],\n",
      "         [ 1.0364],\n",
      "         [-0.0434]]], device='cuda:0')\n",
      "tensor([[[ 9.2268],\n",
      "         [ 1.0258],\n",
      "         [-0.0336]]], device='cuda:0')\n",
      "tensor([[[ 9.2593],\n",
      "         [ 1.0376],\n",
      "         [-0.0201]]], device='cuda:0')\n",
      "tensor([[[ 9.2344],\n",
      "         [ 1.0272],\n",
      "         [-0.0361]]], device='cuda:0')\n",
      "tensor([[[ 9.2536],\n",
      "         [ 1.0513],\n",
      "         [-0.0103]]], device='cuda:0')\n",
      "tensor([[[ 9.2370],\n",
      "         [ 1.0368],\n",
      "         [-0.0367]]], device='cuda:0')\n",
      "tensor([[[ 9.2243],\n",
      "         [ 1.0575],\n",
      "         [-0.0279]]], device='cuda:0')\n",
      "tensor([[[ 9.2243],\n",
      "         [ 1.0395],\n",
      "         [-0.0103]]], device='cuda:0')\n",
      "tensor([[[ 9.2418],\n",
      "         [ 1.0615],\n",
      "         [-0.0258]]], device='cuda:0')\n",
      "tensor([[[ 9.2457],\n",
      "         [ 1.0574],\n",
      "         [-0.0132]]], device='cuda:0')\n",
      "tensor([[[ 9.1927e+00],\n",
      "         [ 1.0543e+00],\n",
      "         [-7.0592e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2355],\n",
      "         [ 1.0600],\n",
      "         [-0.0293]]], device='cuda:0')\n",
      "tensor([[[ 9.2186],\n",
      "         [ 1.0270],\n",
      "         [-0.0297]]], device='cuda:0')\n",
      "tensor([[[ 9.2169],\n",
      "         [ 1.0495],\n",
      "         [-0.0129]]], device='cuda:0')\n",
      "tensor([[[9.1935],\n",
      "         [1.0475],\n",
      "         [0.0587]]], device='cuda:0')\n",
      "tensor([[[ 9.2303],\n",
      "         [ 1.0511],\n",
      "         [-0.0224]]], device='cuda:0')\n",
      "tensor([[[ 9.2500],\n",
      "         [ 1.0277],\n",
      "         [-0.0525]]], device='cuda:0')\n",
      "tensor([[[9.2091],\n",
      "         [1.0497],\n",
      "         [0.0477]]], device='cuda:0')\n",
      "tensor([[[ 9.2541],\n",
      "         [ 1.0643],\n",
      "         [-0.0229]]], device='cuda:0')\n",
      "tensor([[[ 9.2327],\n",
      "         [ 1.0687],\n",
      "         [-0.0191]]], device='cuda:0')\n",
      "tensor([[[ 9.2026],\n",
      "         [ 1.0557],\n",
      "         [-0.0337]]], device='cuda:0')\n",
      "tensor([[[ 9.2247],\n",
      "         [ 1.0641],\n",
      "         [-0.0126]]], device='cuda:0')\n",
      "tensor([[[ 9.2477],\n",
      "         [ 1.0235],\n",
      "         [-0.0280]]], device='cuda:0')\n",
      "tensor([[[ 9.2470],\n",
      "         [ 1.0336],\n",
      "         [-0.0389]]], device='cuda:0')\n",
      "tensor([[[ 9.2278e+00],\n",
      "         [ 9.8896e-01],\n",
      "         [-1.8225e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2627],\n",
      "         [ 1.0660],\n",
      "         [-0.0205]]], device='cuda:0')\n",
      "tensor([[[ 9.2451],\n",
      "         [ 1.0642],\n",
      "         [-0.0127]]], device='cuda:0')\n",
      "tensor([[[ 9.2720],\n",
      "         [ 1.0563],\n",
      "         [-0.0258]]], device='cuda:0')\n",
      "tensor([[[ 9.2608],\n",
      "         [ 1.0688],\n",
      "         [-0.0225]]], device='cuda:0')\n",
      "tensor([[[ 9.2206],\n",
      "         [ 1.0520],\n",
      "         [-0.0301]]], device='cuda:0')\n",
      "tensor([[[ 9.2554],\n",
      "         [ 1.0678],\n",
      "         [-0.0228]]], device='cuda:0')\n",
      "tensor([[[ 9.2412],\n",
      "         [ 1.0511],\n",
      "         [-0.0473]]], device='cuda:0')\n",
      "tensor([[[9.2059],\n",
      "         [0.9796],\n",
      "         [0.0474]]], device='cuda:0')\n",
      "tensor([[[ 9.2331],\n",
      "         [ 1.0574],\n",
      "         [-0.0608]]], device='cuda:0')\n",
      "tensor([[[ 9.2203],\n",
      "         [ 1.0320],\n",
      "         [-0.0096]]], device='cuda:0')\n",
      "tensor([[[ 9.2067],\n",
      "         [ 1.0218],\n",
      "         [-0.0210]]], device='cuda:0')\n",
      "tensor([[[ 9.2576],\n",
      "         [ 1.0694],\n",
      "         [-0.0355]]], device='cuda:0')\n",
      "tensor([[[ 9.2565],\n",
      "         [ 1.0711],\n",
      "         [-0.0326]]], device='cuda:0')\n",
      "tensor([[[ 9.2430],\n",
      "         [ 1.0264],\n",
      "         [-0.0566]]], device='cuda:0')\n",
      "tensor([[[ 9.2057],\n",
      "         [ 1.0525],\n",
      "         [-0.0479]]], device='cuda:0')\n",
      "tensor([[[9.2641e+00],\n",
      "         [1.0698e+00],\n",
      "         [4.0035e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2505],\n",
      "         [ 1.0715],\n",
      "         [-0.0351]]], device='cuda:0')\n",
      "tensor([[[ 9.2247],\n",
      "         [ 1.0369],\n",
      "         [-0.0291]]], device='cuda:0')\n",
      "tensor([[[ 9.2475],\n",
      "         [ 1.0556],\n",
      "         [-0.0278]]], device='cuda:0')\n",
      "tensor([[[ 9.2285],\n",
      "         [ 1.0576],\n",
      "         [-0.0148]]], device='cuda:0')\n",
      "tensor([[[ 9.2487],\n",
      "         [ 0.9907],\n",
      "         [-0.0376]]], device='cuda:0')\n",
      "tensor([[[ 9.2525],\n",
      "         [ 1.0491],\n",
      "         [-0.0096]]], device='cuda:0')\n",
      "tensor([[[9.2163],\n",
      "         [1.0664],\n",
      "         [0.0356]]], device='cuda:0')\n",
      "tensor([[[ 9.2297],\n",
      "         [ 1.0384],\n",
      "         [-0.0283]]], device='cuda:0')\n",
      "tensor([[[ 9.2136],\n",
      "         [ 1.0735],\n",
      "         [-0.0309]]], device='cuda:0')\n",
      "tensor([[[ 9.2519],\n",
      "         [ 1.0505],\n",
      "         [-0.0099]]], device='cuda:0')\n",
      "tensor([[[ 9.2329e+00],\n",
      "         [ 1.0717e+00],\n",
      "         [-4.1800e-03]]], device='cuda:0')\n",
      "tensor([[[9.2217],\n",
      "         [1.0892],\n",
      "         [0.0304]]], device='cuda:0')\n",
      "tensor([[[ 9.2344],\n",
      "         [ 1.0457],\n",
      "         [-0.0344]]], device='cuda:0')\n",
      "tensor([[[9.2253],\n",
      "         [1.0527],\n",
      "         [0.0118]]], device='cuda:0')\n",
      "tensor([[[ 9.2582],\n",
      "         [ 1.0563],\n",
      "         [-0.0160]]], device='cuda:0')\n",
      "tensor([[[ 9.2367],\n",
      "         [ 1.0719],\n",
      "         [-0.0434]]], device='cuda:0')\n",
      "tensor([[[ 9.2236],\n",
      "         [ 1.0432],\n",
      "         [-0.0136]]], device='cuda:0')\n",
      "tensor([[[9.2169],\n",
      "         [1.0653],\n",
      "         [0.0245]]], device='cuda:0')\n",
      "tensor([[[ 9.2357],\n",
      "         [ 1.0563],\n",
      "         [-0.0152]]], device='cuda:0')\n",
      "tensor([[[ 9.2619],\n",
      "         [ 1.0569],\n",
      "         [-0.0258]]], device='cuda:0')\n",
      "tensor([[[ 9.2408],\n",
      "         [ 1.0426],\n",
      "         [-0.0339]]], device='cuda:0')\n",
      "tensor([[[ 9.2220],\n",
      "         [ 1.0718],\n",
      "         [-0.0340]]], device='cuda:0')\n",
      "tensor([[[9.2311e+00],\n",
      "         [9.8684e-01],\n",
      "         [5.8860e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2022],\n",
      "         [ 1.0463],\n",
      "         [-0.0444]]], device='cuda:0')\n",
      "tensor([[[ 9.2529],\n",
      "         [ 0.9917],\n",
      "         [-0.0409]]], device='cuda:0')\n",
      "tensor([[[ 9.2319],\n",
      "         [ 1.0511],\n",
      "         [-0.0226]]], device='cuda:0')\n",
      "tensor([[[ 9.2077],\n",
      "         [ 1.0534],\n",
      "         [-0.0343]]], device='cuda:0')\n",
      "tensor([[[ 9.2233],\n",
      "         [ 1.0207],\n",
      "         [-0.0916]]], device='cuda:0')\n",
      "tensor([[[ 9.2464],\n",
      "         [ 1.0921],\n",
      "         [-0.0482]]], device='cuda:0')\n",
      "tensor([[[ 9.2167],\n",
      "         [ 1.0573],\n",
      "         [-0.0295]]], device='cuda:0')\n",
      "tensor([[[ 9.2367],\n",
      "         [ 1.0569],\n",
      "         [-0.0276]]], device='cuda:0')\n",
      "tensor([[[ 9.2262e+00],\n",
      "         [ 1.0621e+00],\n",
      "         [-4.0088e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2659],\n",
      "         [ 1.0526],\n",
      "         [-0.0103]]], device='cuda:0')\n",
      "tensor([[[ 9.2585],\n",
      "         [ 1.0598],\n",
      "         [-0.0370]]], device='cuda:0')\n",
      "tensor([[[ 9.2449],\n",
      "         [ 1.0655],\n",
      "         [-0.0120]]], device='cuda:0')\n",
      "tensor([[[ 9.2315],\n",
      "         [ 1.0654],\n",
      "         [-0.0204]]], device='cuda:0')\n",
      "tensor([[[9.2312e+00],\n",
      "         [1.0524e+00],\n",
      "         [4.4782e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2442],\n",
      "         [ 1.0529],\n",
      "         [-0.0457]]], device='cuda:0')\n",
      "tensor([[[ 9.2372],\n",
      "         [ 1.0187],\n",
      "         [-0.0744]]], device='cuda:0')\n",
      "tensor([[[ 9.2197],\n",
      "         [ 1.0493],\n",
      "         [-0.0330]]], device='cuda:0')\n",
      "tensor([[[ 9.2218],\n",
      "         [ 1.0461],\n",
      "         [-0.0146]]], device='cuda:0')\n",
      "tensor([[[9.2442e+00],\n",
      "         [1.0557e+00],\n",
      "         [3.9907e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2480],\n",
      "         [ 1.0606],\n",
      "         [-0.0210]]], device='cuda:0')\n",
      "tensor([[[ 9.2554],\n",
      "         [ 1.0521],\n",
      "         [-0.0339]]], device='cuda:0')\n",
      "tensor([[[ 9.2322],\n",
      "         [ 1.0865],\n",
      "         [-0.0527]]], device='cuda:0')\n",
      "tensor([[[ 9.2415],\n",
      "         [ 1.0389],\n",
      "         [-0.0147]]], device='cuda:0')\n",
      "tensor([[[ 9.2413],\n",
      "         [ 1.0298],\n",
      "         [-0.0521]]], device='cuda:0')\n",
      "tensor([[[ 9.2551],\n",
      "         [ 0.9858],\n",
      "         [-0.0403]]], device='cuda:0')\n",
      "tensor([[[ 9.2410],\n",
      "         [ 1.0291],\n",
      "         [-0.0288]]], device='cuda:0')\n",
      "tensor([[[ 9.2541],\n",
      "         [ 1.0658],\n",
      "         [-0.0195]]], device='cuda:0')\n",
      "tensor([[[ 9.2723],\n",
      "         [ 1.0079],\n",
      "         [-0.0120]]], device='cuda:0')\n",
      "tensor([[[ 9.2255],\n",
      "         [ 1.0957],\n",
      "         [-0.0492]]], device='cuda:0')\n",
      "tensor([[[ 9.2162],\n",
      "         [ 1.0605],\n",
      "         [-0.0217]]], device='cuda:0')\n",
      "tensor([[[ 9.2054],\n",
      "         [ 1.0880],\n",
      "         [-0.0511]]], device='cuda:0')\n",
      "tensor([[[ 9.2388],\n",
      "         [ 1.0571],\n",
      "         [-0.0227]]], device='cuda:0')\n",
      "tensor([[[ 9.2587],\n",
      "         [ 1.0245],\n",
      "         [-0.0553]]], device='cuda:0')\n",
      "tensor([[[ 9.2289],\n",
      "         [ 1.0629],\n",
      "         [-0.0152]]], device='cuda:0')\n",
      "tensor([[[ 9.2454e+00],\n",
      "         [ 1.0540e+00],\n",
      "         [-2.6125e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2273],\n",
      "         [ 1.0406],\n",
      "         [-0.0108]]], device='cuda:0')\n",
      "tensor([[[ 9.2229],\n",
      "         [ 1.0490],\n",
      "         [-0.0231]]], device='cuda:0')\n",
      "tensor([[[ 9.2465e+00],\n",
      "         [ 1.0596e+00],\n",
      "         [-8.5830e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2545],\n",
      "         [ 1.0232],\n",
      "         [-0.0353]]], device='cuda:0')\n",
      "tensor([[[ 9.2405],\n",
      "         [ 1.0609],\n",
      "         [-0.0363]]], device='cuda:0')\n",
      "tensor([[[ 9.2060],\n",
      "         [ 1.0568],\n",
      "         [-0.0350]]], device='cuda:0')\n",
      "tensor([[[ 9.2561],\n",
      "         [ 1.0055],\n",
      "         [-0.0108]]], device='cuda:0')\n",
      "tensor([[[ 9.2552],\n",
      "         [ 1.0481],\n",
      "         [-0.0474]]], device='cuda:0')\n",
      "tensor([[[ 9.2444],\n",
      "         [ 1.0244],\n",
      "         [-0.0352]]], device='cuda:0')\n",
      "tensor([[[ 9.2440],\n",
      "         [ 1.0637],\n",
      "         [-0.0476]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9.2276e+00],\n",
      "         [ 1.0536e+00],\n",
      "         [-1.1060e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2198],\n",
      "         [ 1.0253],\n",
      "         [-0.0566]]], device='cuda:0')\n",
      "tensor([[[ 9.2268],\n",
      "         [ 1.0349],\n",
      "         [-0.0393]]], device='cuda:0')\n",
      "tensor([[[ 9.2332],\n",
      "         [ 1.0207],\n",
      "         [-0.0238]]], device='cuda:0')\n",
      "tensor([[[ 9.2364],\n",
      "         [ 1.0653],\n",
      "         [-0.0617]]], device='cuda:0')\n",
      "tensor([[[ 9.2559],\n",
      "         [ 1.0624],\n",
      "         [-0.0190]]], device='cuda:0')\n",
      "tensor([[[9.2056],\n",
      "         [1.1038],\n",
      "         [0.1550]]], device='cuda:0')\n",
      "tensor([[[9.2032],\n",
      "         [0.9791],\n",
      "         [0.0454]]], device='cuda:0')\n",
      "tensor([[[ 9.2063],\n",
      "         [ 1.0643],\n",
      "         [-0.0262]]], device='cuda:0')\n",
      "tensor([[[9.2041],\n",
      "         [1.0660],\n",
      "         [0.0371]]], device='cuda:0')\n",
      "tensor([[[9.2170],\n",
      "         [1.0460],\n",
      "         [0.0551]]], device='cuda:0')\n",
      "tensor([[[ 9.2364],\n",
      "         [ 1.0653],\n",
      "         [-0.0617]]], device='cuda:0')\n",
      "tensor([[[ 9.2172],\n",
      "         [ 1.0537],\n",
      "         [-0.0143]]], device='cuda:0')\n",
      "tensor([[[ 9.2321],\n",
      "         [ 1.0468],\n",
      "         [-0.0093]]], device='cuda:0')\n",
      "tensor([[[ 9.2328],\n",
      "         [ 1.0723],\n",
      "         [-0.0417]]], device='cuda:0')\n",
      "tensor([[[ 9.2565],\n",
      "         [ 0.9825],\n",
      "         [-0.0393]]], device='cuda:0')\n",
      "tensor([[[ 9.2334],\n",
      "         [ 1.0324],\n",
      "         [-0.0140]]], device='cuda:0')\n",
      "tensor([[[ 9.2428],\n",
      "         [ 1.0553],\n",
      "         [-0.0276]]], device='cuda:0')\n",
      "tensor([[[9.2549],\n",
      "         [1.0563],\n",
      "         [0.0129]]], device='cuda:0')\n",
      "tensor([[[9.2520],\n",
      "         [1.0719],\n",
      "         [0.0166]]], device='cuda:0')\n",
      "tensor([[[ 9.2305],\n",
      "         [ 1.0321],\n",
      "         [-0.0277]]], device='cuda:0')\n",
      "tensor([[[ 9.2215],\n",
      "         [ 1.0297],\n",
      "         [-0.0297]]], device='cuda:0')\n",
      "tensor([[[9.2347],\n",
      "         [1.0467],\n",
      "         [0.0540]]], device='cuda:0')\n",
      "tensor([[[ 9.2542],\n",
      "         [ 1.0656],\n",
      "         [-0.0330]]], device='cuda:0')\n",
      "tensor([[[ 9.2438],\n",
      "         [ 1.0668],\n",
      "         [-0.0186]]], device='cuda:0')\n",
      "tensor([[[ 9.2158],\n",
      "         [ 1.0203],\n",
      "         [-0.0106]]], device='cuda:0')\n",
      "tensor([[[ 9.2333e+00],\n",
      "         [ 1.0478e+00],\n",
      "         [-5.3382e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2345],\n",
      "         [ 1.0553],\n",
      "         [-0.0166]]], device='cuda:0')\n",
      "tensor([[[ 9.2133e+00],\n",
      "         [ 1.0473e+00],\n",
      "         [-8.5467e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2453],\n",
      "         [ 1.0285],\n",
      "         [-0.0142]]], device='cuda:0')\n",
      "tensor([[[ 9.2256],\n",
      "         [ 1.0494],\n",
      "         [-0.0476]]], device='cuda:0')\n",
      "tensor([[[ 9.2455],\n",
      "         [ 1.0764],\n",
      "         [-0.0408]]], device='cuda:0')\n",
      "tensor([[[ 9.2412e+00],\n",
      "         [ 1.0586e+00],\n",
      "         [-8.8854e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2440],\n",
      "         [ 1.0416],\n",
      "         [-0.0260]]], device='cuda:0')\n",
      "tensor([[[ 9.2323],\n",
      "         [ 1.0463],\n",
      "         [-0.0113]]], device='cuda:0')\n",
      "tensor([[[ 9.2440],\n",
      "         [ 1.0637],\n",
      "         [-0.0476]]], device='cuda:0')\n",
      "tensor([[[ 9.2291],\n",
      "         [ 1.0632],\n",
      "         [-0.0123]]], device='cuda:0')\n",
      "tensor([[[ 9.2547],\n",
      "         [ 1.0534],\n",
      "         [-0.0281]]], device='cuda:0')\n",
      "tensor([[[9.2116],\n",
      "         [1.0714],\n",
      "         [0.0102]]], device='cuda:0')\n",
      "tensor([[[ 9.2457],\n",
      "         [ 1.0575],\n",
      "         [-0.0178]]], device='cuda:0')\n",
      "tensor([[[ 9.2359],\n",
      "         [ 1.0695],\n",
      "         [-0.0385]]], device='cuda:0')\n",
      "tensor([[[ 9.2189],\n",
      "         [ 1.0596],\n",
      "         [-0.0257]]], device='cuda:0')\n",
      "tensor([[[ 9.2135e+00],\n",
      "         [ 1.0628e+00],\n",
      "         [-2.7667e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2304],\n",
      "         [ 1.0680],\n",
      "         [-0.0198]]], device='cuda:0')\n",
      "tensor([[[ 9.2526],\n",
      "         [ 1.0511],\n",
      "         [-0.0113]]], device='cuda:0')\n",
      "tensor([[[ 9.2406],\n",
      "         [ 1.0522],\n",
      "         [-0.0476]]], device='cuda:0')\n",
      "tensor([[[ 9.2357],\n",
      "         [ 1.0293],\n",
      "         [-0.0364]]], device='cuda:0')\n",
      "tensor([[[ 9.2319],\n",
      "         [ 1.0259],\n",
      "         [-0.0348]]], device='cuda:0')\n",
      "tensor([[[ 9.2476],\n",
      "         [ 1.0603],\n",
      "         [-0.0362]]], device='cuda:0')\n",
      "tensor([[[ 9.2685],\n",
      "         [ 1.0346],\n",
      "         [-0.0302]]], device='cuda:0')\n",
      "tensor([[[ 9.2215],\n",
      "         [ 1.0590],\n",
      "         [-0.0388]]], device='cuda:0')\n",
      "tensor([[[ 9.2662],\n",
      "         [ 1.0607],\n",
      "         [-0.0370]]], device='cuda:0')\n",
      "tensor([[[ 9.2273e+00],\n",
      "         [ 1.0586e+00],\n",
      "         [-9.1476e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2676],\n",
      "         [ 1.0311],\n",
      "         [-0.0149]]], device='cuda:0')\n",
      "tensor([[[ 9.2380],\n",
      "         [ 1.0308],\n",
      "         [-0.0252]]], device='cuda:0')\n",
      "tensor([[[ 9.2236],\n",
      "         [ 1.0035],\n",
      "         [-0.0131]]], device='cuda:0')\n",
      "tensor([[[ 9.2214],\n",
      "         [ 1.0347],\n",
      "         [-0.0223]]], device='cuda:0')\n",
      "tensor([[[ 9.2627],\n",
      "         [ 1.0397],\n",
      "         [-0.0445]]], device='cuda:0')\n",
      "tensor([[[9.2034],\n",
      "         [1.0616],\n",
      "         [0.0204]]], device='cuda:0')\n",
      "tensor([[[ 9.2393],\n",
      "         [ 1.0591],\n",
      "         [-0.0685]]], device='cuda:0')\n",
      "tensor([[[9.1924],\n",
      "         [1.0465],\n",
      "         [0.0539]]], device='cuda:0')\n",
      "tensor([[[ 9.2375],\n",
      "         [ 1.0614],\n",
      "         [-0.0163]]], device='cuda:0')\n",
      "tensor([[[ 9.2150],\n",
      "         [ 1.0509],\n",
      "         [-0.0362]]], device='cuda:0')\n",
      "tensor([[[ 9.2295],\n",
      "         [ 1.0537],\n",
      "         [-0.0530]]], device='cuda:0')\n",
      "tensor([[[9.2041],\n",
      "         [1.0660],\n",
      "         [0.0371]]], device='cuda:0')\n",
      "tensor([[[9.2128],\n",
      "         [1.0610],\n",
      "         [0.0225]]], device='cuda:0')\n",
      "tensor([[[ 9.2359],\n",
      "         [ 1.0352],\n",
      "         [-0.0207]]], device='cuda:0')\n",
      "tensor([[[ 9.2820],\n",
      "         [ 1.0730],\n",
      "         [-0.0191]]], device='cuda:0')\n",
      "tensor([[[ 9.2384e+00],\n",
      "         [ 1.0637e+00],\n",
      "         [-7.7783e-03]]], device='cuda:0')\n",
      "tensor([[[9.2472],\n",
      "         [1.0696],\n",
      "         [0.0153]]], device='cuda:0')\n",
      "tensor([[[9.2462e+00],\n",
      "         [1.0698e+00],\n",
      "         [3.1106e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2413],\n",
      "         [ 1.0722],\n",
      "         [-0.0334]]], device='cuda:0')\n",
      "tensor([[[ 9.2534],\n",
      "         [ 1.0460],\n",
      "         [-0.0132]]], device='cuda:0')\n",
      "tensor([[[ 9.2739],\n",
      "         [ 1.0545],\n",
      "         [-0.0096]]], device='cuda:0')\n",
      "tensor([[[ 9.2192],\n",
      "         [ 1.0445],\n",
      "         [-0.0355]]], device='cuda:0')\n",
      "tensor([[[ 9.1970],\n",
      "         [ 1.0332],\n",
      "         [-0.0225]]], device='cuda:0')\n",
      "tensor([[[ 9.2528],\n",
      "         [ 1.0524],\n",
      "         [-0.0341]]], device='cuda:0')\n",
      "tensor([[[ 9.2089],\n",
      "         [ 1.0770],\n",
      "         [-0.0351]]], device='cuda:0')\n",
      "tensor([[[ 9.2305],\n",
      "         [ 1.0014],\n",
      "         [-0.0102]]], device='cuda:0')\n",
      "tensor([[[ 9.2674],\n",
      "         [ 1.0684],\n",
      "         [-0.0218]]], device='cuda:0')\n",
      "tensor([[[9.2451e+00],\n",
      "         [1.0632e+00],\n",
      "         [9.1300e-04]]], device='cuda:0')\n",
      "tensor([[[ 9.2039],\n",
      "         [ 1.0641],\n",
      "         [-0.0139]]], device='cuda:0')\n",
      "tensor([[[ 9.2718],\n",
      "         [ 1.0610],\n",
      "         [-0.0256]]], device='cuda:0')\n",
      "tensor([[[9.2284],\n",
      "         [1.0677],\n",
      "         [0.0344]]], device='cuda:0')\n",
      "tensor([[[ 9.2372],\n",
      "         [ 1.0393],\n",
      "         [-0.0215]]], device='cuda:0')\n",
      "tensor([[[ 9.2376],\n",
      "         [ 1.0402],\n",
      "         [-0.0189]]], device='cuda:0')\n",
      "tensor([[[ 9.2408],\n",
      "         [ 1.0512],\n",
      "         [-0.0335]]], device='cuda:0')\n",
      "tensor([[[ 9.2165],\n",
      "         [ 1.0532],\n",
      "         [-0.0478]]], device='cuda:0')\n",
      "tensor([[[9.2301e+00],\n",
      "         [9.9100e-01],\n",
      "         [1.1586e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2423],\n",
      "         [ 1.0561],\n",
      "         [-0.0163]]], device='cuda:0')\n",
      "tensor([[[ 9.2396e+00],\n",
      "         [ 1.0717e+00],\n",
      "         [-5.5842e-03]]], device='cuda:0')\n",
      "tensor([[[9.2357],\n",
      "         [1.0905],\n",
      "         [0.0108]]], device='cuda:0')\n",
      "tensor([[[ 9.2401],\n",
      "         [ 1.0265],\n",
      "         [-0.0301]]], device='cuda:0')\n",
      "tensor([[[9.2300],\n",
      "         [1.0469],\n",
      "         [0.0128]]], device='cuda:0')\n",
      "tensor([[[ 9.2579],\n",
      "         [ 1.0258],\n",
      "         [-0.0126]]], device='cuda:0')\n",
      "tensor([[[ 9.2457e+00],\n",
      "         [ 1.0626e+00],\n",
      "         [-7.7889e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2409e+00],\n",
      "         [ 1.0730e+00],\n",
      "         [-6.1434e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2367e+00],\n",
      "         [ 1.0714e+00],\n",
      "         [-6.6080e-03]]], device='cuda:0')\n",
      "tensor([[[9.2312],\n",
      "         [1.1014],\n",
      "         [0.1857]]], device='cuda:0')\n",
      "tensor([[[9.2597e+00],\n",
      "         [1.0529e+00],\n",
      "         [3.1489e-03]]], device='cuda:0')\n",
      "tensor([[[9.2259],\n",
      "         [1.0628],\n",
      "         [0.0191]]], device='cuda:0')\n",
      "tensor([[[ 9.2227],\n",
      "         [ 1.0543],\n",
      "         [-0.0144]]], device='cuda:0')\n",
      "tensor([[[ 9.1726],\n",
      "         [ 1.0361],\n",
      "         [-0.0448]]], device='cuda:0')\n",
      "tensor([[[ 9.2336],\n",
      "         [ 1.0659],\n",
      "         [-0.0671]]], device='cuda:0')\n",
      "tensor([[[ 9.2461],\n",
      "         [ 1.0930],\n",
      "         [-0.0453]]], device='cuda:0')\n",
      "tensor([[[ 9.2433],\n",
      "         [ 1.0633],\n",
      "         [-0.0254]]], device='cuda:0')\n",
      "tensor([[[9.2296],\n",
      "         [1.0614],\n",
      "         [0.0484]]], device='cuda:0')\n",
      "tensor([[[ 9.2036],\n",
      "         [ 1.0631],\n",
      "         [-0.0264]]], device='cuda:0')\n",
      "tensor([[[ 9.2053],\n",
      "         [ 1.0484],\n",
      "         [-0.0094]]], device='cuda:0')\n",
      "tensor([[[ 9.2580],\n",
      "         [ 1.0634],\n",
      "         [-0.0313]]], device='cuda:0')\n",
      "tensor([[[ 9.2466],\n",
      "         [ 1.0549],\n",
      "         [-0.0428]]], device='cuda:0')\n",
      "tensor([[[ 9.2225e+00],\n",
      "         [ 1.0622e+00],\n",
      "         [-3.5746e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2167],\n",
      "         [ 1.0422],\n",
      "         [-0.0139]]], device='cuda:0')\n",
      "tensor([[[ 9.2429],\n",
      "         [ 1.0608],\n",
      "         [-0.0202]]], device='cuda:0')\n",
      "tensor([[[ 9.2369],\n",
      "         [ 1.0319],\n",
      "         [-0.0154]]], device='cuda:0')\n",
      "tensor([[[ 9.2269],\n",
      "         [ 1.0689],\n",
      "         [-0.0227]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9.2304],\n",
      "         [ 1.0292],\n",
      "         [-0.0345]]], device='cuda:0')\n",
      "tensor([[[ 9.2460],\n",
      "         [ 1.0537],\n",
      "         [-0.0156]]], device='cuda:0')\n",
      "tensor([[[9.2172],\n",
      "         [1.0717],\n",
      "         [0.0490]]], device='cuda:0')\n",
      "tensor([[[9.2035],\n",
      "         [1.0456],\n",
      "         [0.0522]]], device='cuda:0')\n",
      "tensor([[[ 9.2282],\n",
      "         [ 1.0595],\n",
      "         [-0.0286]]], device='cuda:0')\n",
      "tensor([[[ 9.2410e+00],\n",
      "         [ 1.0657e+00],\n",
      "         [-4.0897e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2590],\n",
      "         [ 1.0532],\n",
      "         [-0.0341]]], device='cuda:0')\n",
      "tensor([[[ 9.2533e+00],\n",
      "         [ 1.0581e+00],\n",
      "         [-7.5602e-03]]], device='cuda:0')\n",
      "tensor([[[9.2286],\n",
      "         [1.0426],\n",
      "         [0.0790]]], device='cuda:0')\n",
      "tensor([[[9.2378e+00],\n",
      "         [1.0469e+00],\n",
      "         [3.3045e-05]]], device='cuda:0')\n",
      "tensor([[[ 9.2511],\n",
      "         [ 1.0581],\n",
      "         [-0.0250]]], device='cuda:0')\n",
      "tensor([[[ 9.2099e+00],\n",
      "         [ 1.0489e+00],\n",
      "         [-4.3976e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2076],\n",
      "         [ 1.0228],\n",
      "         [-0.0138]]], device='cuda:0')\n",
      "tensor([[[9.2303],\n",
      "         [1.0599],\n",
      "         [0.0475]]], device='cuda:0')\n",
      "tensor([[[ 9.2365],\n",
      "         [ 1.0601],\n",
      "         [-0.0180]]], device='cuda:0')\n",
      "tensor([[[9.2462e+00],\n",
      "         [1.0858e+00],\n",
      "         [5.1105e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2356],\n",
      "         [ 1.0558],\n",
      "         [-0.0419]]], device='cuda:0')\n",
      "tensor([[[ 9.2412],\n",
      "         [ 1.0623],\n",
      "         [-0.0260]]], device='cuda:0')\n",
      "tensor([[[ 9.2533],\n",
      "         [ 1.0259],\n",
      "         [-0.0242]]], device='cuda:0')\n",
      "tensor([[[ 9.1974e+00],\n",
      "         [ 1.0706e+00],\n",
      "         [-5.4913e-03]]], device='cuda:0')\n",
      "tensor([[[9.2217e+00],\n",
      "         [1.0532e+00],\n",
      "         [1.0392e-04]]], device='cuda:0')\n",
      "tensor([[[ 9.2694],\n",
      "         [ 1.0363],\n",
      "         [-0.0384]]], device='cuda:0')\n",
      "tensor([[[ 9.2499],\n",
      "         [ 1.0542],\n",
      "         [-0.0282]]], device='cuda:0')\n",
      "tensor([[[9.2136],\n",
      "         [1.0647],\n",
      "         [0.0320]]], device='cuda:0')\n",
      "tensor([[[ 9.2589],\n",
      "         [ 1.0632],\n",
      "         [-0.0197]]], device='cuda:0')\n",
      "tensor([[[ 9.2022],\n",
      "         [ 1.0463],\n",
      "         [-0.0444]]], device='cuda:0')\n",
      "tensor([[[ 9.2355],\n",
      "         [ 1.0447],\n",
      "         [-0.0118]]], device='cuda:0')\n",
      "tensor([[[ 9.2214],\n",
      "         [ 1.0347],\n",
      "         [-0.0223]]], device='cuda:0')\n",
      "tensor([[[ 9.2326],\n",
      "         [ 1.0299],\n",
      "         [-0.0340]]], device='cuda:0')\n",
      "tensor([[[ 9.2123],\n",
      "         [ 1.0650],\n",
      "         [-0.0676]]], device='cuda:0')\n",
      "tensor([[[ 9.2914],\n",
      "         [ 1.0699],\n",
      "         [-0.0197]]], device='cuda:0')\n",
      "tensor([[[ 9.2298],\n",
      "         [ 1.0715],\n",
      "         [-0.0109]]], device='cuda:0')\n",
      "tensor([[[9.2548],\n",
      "         [1.0505],\n",
      "         [0.0130]]], device='cuda:0')\n",
      "tensor([[[ 9.2492],\n",
      "         [ 1.0502],\n",
      "         [-0.0476]]], device='cuda:0')\n",
      "tensor([[[ 9.2333],\n",
      "         [ 1.0630],\n",
      "         [-0.0641]]], device='cuda:0')\n",
      "tensor([[[9.1949],\n",
      "         [1.0459],\n",
      "         [0.0529]]], device='cuda:0')\n",
      "tensor([[[ 9.2277],\n",
      "         [ 1.0526],\n",
      "         [-0.0289]]], device='cuda:0')\n",
      "tensor([[[ 9.2165],\n",
      "         [ 1.0607],\n",
      "         [-0.0377]]], device='cuda:0')\n",
      "tensor([[[9.1763],\n",
      "         [1.1065],\n",
      "         [0.1662]]], device='cuda:0')\n",
      "tensor([[[9.1934],\n",
      "         [1.0674],\n",
      "         [0.0902]]], device='cuda:0')\n",
      "tensor([[[ 9.2156],\n",
      "         [ 1.0257],\n",
      "         [-0.0247]]], device='cuda:0')\n",
      "tensor([[[ 9.2485],\n",
      "         [ 1.0640],\n",
      "         [-0.0124]]], device='cuda:0')\n",
      "tensor([[[ 9.2451],\n",
      "         [ 1.0943],\n",
      "         [-0.0482]]], device='cuda:0')\n",
      "tensor([[[ 9.2406],\n",
      "         [ 1.0522],\n",
      "         [-0.0476]]], device='cuda:0')\n",
      "tensor([[[ 9.1950e+00],\n",
      "         [ 1.0391e+00],\n",
      "         [-2.1790e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2436],\n",
      "         [ 1.0574],\n",
      "         [-0.0368]]], device='cuda:0')\n",
      "tensor([[[ 9.2342],\n",
      "         [ 1.0305],\n",
      "         [-0.0284]]], device='cuda:0')\n",
      "tensor([[[ 9.2807],\n",
      "         [ 1.0618],\n",
      "         [-0.0253]]], device='cuda:0')\n",
      "tensor([[[ 9.2370],\n",
      "         [ 1.0572],\n",
      "         [-0.0139]]], device='cuda:0')\n",
      "tensor([[[ 9.2210],\n",
      "         [ 1.0442],\n",
      "         [-0.0327]]], device='cuda:0')\n",
      "tensor([[[9.2290e+00],\n",
      "         [1.0910e+00],\n",
      "         [9.5777e-04]]], device='cuda:0')\n",
      "tensor([[[ 9.2246],\n",
      "         [ 1.0225],\n",
      "         [-0.0313]]], device='cuda:0')\n",
      "tensor([[[ 9.2420e+00],\n",
      "         [ 1.0644e+00],\n",
      "         [-4.8132e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2733],\n",
      "         [ 1.0640],\n",
      "         [-0.0476]]], device='cuda:0')\n",
      "tensor([[[ 9.2471],\n",
      "         [ 1.0518],\n",
      "         [-0.0126]]], device='cuda:0')\n",
      "tensor([[[ 9.2379],\n",
      "         [ 1.0858],\n",
      "         [-0.0527]]], device='cuda:0')\n",
      "tensor([[[ 9.1998],\n",
      "         [ 1.0454],\n",
      "         [-0.0147]]], device='cuda:0')\n",
      "tensor([[[ 9.2116],\n",
      "         [ 1.1700],\n",
      "         [-0.0095]]], device='cuda:0')\n",
      "tensor([[[ 9.2236],\n",
      "         [ 1.0668],\n",
      "         [-0.0098]]], device='cuda:0')\n",
      "tensor([[[9.2053],\n",
      "         [1.0661],\n",
      "         [0.0148]]], device='cuda:0')\n",
      "tensor([[[ 9.2438],\n",
      "         [ 1.0523],\n",
      "         [-0.0102]]], device='cuda:0')\n",
      "tensor([[[9.2161],\n",
      "         [1.0696],\n",
      "         [0.0391]]], device='cuda:0')\n",
      "tensor([[[ 9.2450],\n",
      "         [ 0.9943],\n",
      "         [-0.0354]]], device='cuda:0')\n",
      "tensor([[[9.2194],\n",
      "         [0.9763],\n",
      "         [0.0173]]], device='cuda:0')\n",
      "tensor([[[ 9.2492e+00],\n",
      "         [ 1.0617e+00],\n",
      "         [-4.9525e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.1927e+00],\n",
      "         [ 1.0543e+00],\n",
      "         [-7.0592e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2349],\n",
      "         [ 1.0569],\n",
      "         [-0.0248]]], device='cuda:0')\n",
      "tensor([[[ 9.2522],\n",
      "         [ 1.0271],\n",
      "         [-0.0144]]], device='cuda:0')\n",
      "tensor([[[9.2249],\n",
      "         [1.0577],\n",
      "         [0.0113]]], device='cuda:0')\n",
      "tensor([[[ 9.2271],\n",
      "         [ 1.1018],\n",
      "         [-0.0547]]], device='cuda:0')\n",
      "tensor([[[ 9.2600],\n",
      "         [ 1.0262],\n",
      "         [-0.0536]]], device='cuda:0')\n",
      "tensor([[[ 9.2165],\n",
      "         [ 1.0327],\n",
      "         [-0.0321]]], device='cuda:0')\n",
      "tensor([[[ 9.1859],\n",
      "         [ 1.0325],\n",
      "         [-0.0259]]], device='cuda:0')\n",
      "tensor([[[ 9.2259],\n",
      "         [ 1.0281],\n",
      "         [-0.0324]]], device='cuda:0')\n",
      "tensor([[[9.2289],\n",
      "         [1.0631],\n",
      "         [0.0471]]], device='cuda:0')\n",
      "tensor([[[ 9.2292],\n",
      "         [ 1.0862],\n",
      "         [-0.0530]]], device='cuda:0')\n",
      "tensor([[[ 9.2375],\n",
      "         [ 1.0602],\n",
      "         [-0.0211]]], device='cuda:0')\n",
      "tensor([[[ 9.2319],\n",
      "         [ 1.0339],\n",
      "         [-0.0290]]], device='cuda:0')\n",
      "tensor([[[9.2184],\n",
      "         [1.0718],\n",
      "         [0.0417]]], device='cuda:0')\n",
      "tensor([[[9.2115],\n",
      "         [1.0683],\n",
      "         [0.0450]]], device='cuda:0')\n",
      "tensor([[[9.2129],\n",
      "         [1.0723],\n",
      "         [0.0991]]], device='cuda:0')\n",
      "tensor([[[ 9.2187],\n",
      "         [ 1.0559],\n",
      "         [-0.0160]]], device='cuda:0')\n",
      "tensor([[[ 9.2472],\n",
      "         [ 1.0565],\n",
      "         [-0.0263]]], device='cuda:0')\n",
      "tensor([[[ 9.2186],\n",
      "         [ 1.0565],\n",
      "         [-0.0205]]], device='cuda:0')\n",
      "tensor([[[ 9.2355],\n",
      "         [ 1.0551],\n",
      "         [-0.0146]]], device='cuda:0')\n",
      "tensor([[[ 9.2450],\n",
      "         [ 1.0284],\n",
      "         [-0.0360]]], device='cuda:0')\n",
      "tensor([[[9.2253e+00],\n",
      "         [1.0691e+00],\n",
      "         [1.8136e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2319],\n",
      "         [ 1.0652],\n",
      "         [-0.0261]]], device='cuda:0')\n",
      "tensor([[[ 9.2435],\n",
      "         [ 1.0708],\n",
      "         [-0.0424]]], device='cuda:0')\n",
      "tensor([[[ 9.2401],\n",
      "         [ 1.0268],\n",
      "         [-0.0300]]], device='cuda:0')\n",
      "tensor([[[9.2228e+00],\n",
      "         [1.0506e+00],\n",
      "         [3.6329e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2370],\n",
      "         [ 1.0636],\n",
      "         [-0.0610]]], device='cuda:0')\n",
      "tensor([[[ 9.2526],\n",
      "         [ 1.0266],\n",
      "         [-0.0551]]], device='cuda:0')\n",
      "tensor([[[ 9.2502],\n",
      "         [ 1.0589],\n",
      "         [-0.0292]]], device='cuda:0')\n",
      "tensor([[[ 9.2464],\n",
      "         [ 1.0582],\n",
      "         [-0.0131]]], device='cuda:0')\n",
      "tensor([[[ 9.2137],\n",
      "         [ 1.1078],\n",
      "         [-0.0373]]], device='cuda:0')\n",
      "tensor([[[9.2403],\n",
      "         [1.0454],\n",
      "         [0.0526]]], device='cuda:0')\n",
      "tensor([[[ 9.2110],\n",
      "         [ 1.0330],\n",
      "         [-0.0246]]], device='cuda:0')\n",
      "tensor([[[ 9.2089],\n",
      "         [ 1.0483],\n",
      "         [-0.0100]]], device='cuda:0')\n",
      "tensor([[[ 9.2257e+00],\n",
      "         [ 1.1729e+00],\n",
      "         [-3.5632e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2420],\n",
      "         [ 1.0429],\n",
      "         [-0.0452]]], device='cuda:0')\n",
      "tensor([[[ 9.2430],\n",
      "         [ 1.0392],\n",
      "         [-0.0106]]], device='cuda:0')\n",
      "tensor([[[ 9.2309],\n",
      "         [ 1.0308],\n",
      "         [-0.0173]]], device='cuda:0')\n",
      "tensor([[[ 9.2361],\n",
      "         [ 0.9846],\n",
      "         [-0.0431]]], device='cuda:0')\n",
      "tensor([[[9.2334e+00],\n",
      "         [1.0661e+00],\n",
      "         [3.7062e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2398e+00],\n",
      "         [ 1.0694e+00],\n",
      "         [-5.9959e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2317],\n",
      "         [ 1.0427],\n",
      "         [-0.0117]]], device='cuda:0')\n",
      "tensor([[[9.2632],\n",
      "         [1.0704],\n",
      "         [0.0176]]], device='cuda:0')\n",
      "tensor([[[ 9.2427],\n",
      "         [ 1.0675],\n",
      "         [-0.0203]]], device='cuda:0')\n",
      "tensor([[[9.2178],\n",
      "         [1.1082],\n",
      "         [0.1811]]], device='cuda:0')\n",
      "tensor([[[ 9.2493],\n",
      "         [ 1.0611],\n",
      "         [-0.0176]]], device='cuda:0')\n",
      "tensor([[[ 9.2456],\n",
      "         [ 1.0494],\n",
      "         [-0.0383]]], device='cuda:0')\n",
      "tensor([[[ 9.2278e+00],\n",
      "         [ 9.8896e-01],\n",
      "         [-1.8225e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2319e+00],\n",
      "         [ 1.0516e+00],\n",
      "         [-7.1589e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2103],\n",
      "         [ 1.0478],\n",
      "         [-0.0101]]], device='cuda:0')\n",
      "tensor([[[ 9.2408],\n",
      "         [ 1.0593],\n",
      "         [-0.0177]]], device='cuda:0')\n",
      "tensor([[[ 9.2124e+00],\n",
      "         [ 1.0629e+00],\n",
      "         [-6.8709e-03]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 9.2542],\n",
      "         [ 1.0721],\n",
      "         [-0.0421]]], device='cuda:0')\n",
      "tensor([[[ 9.2512],\n",
      "         [ 1.0586],\n",
      "         [-0.0473]]], device='cuda:0')\n",
      "tensor([[[ 9.2405],\n",
      "         [ 1.0562],\n",
      "         [-0.0104]]], device='cuda:0')\n",
      "tensor([[[9.2074],\n",
      "         [1.0880],\n",
      "         [0.0100]]], device='cuda:0')\n",
      "tensor([[[ 9.2406],\n",
      "         [ 1.0522],\n",
      "         [-0.0476]]], device='cuda:0')\n",
      "tensor([[[ 9.2055],\n",
      "         [ 1.0321],\n",
      "         [-0.0266]]], device='cuda:0')\n",
      "tensor([[[ 9.2358],\n",
      "         [ 1.0475],\n",
      "         [-0.0150]]], device='cuda:0')\n",
      "tensor([[[ 9.2109],\n",
      "         [ 1.0300],\n",
      "         [-0.0109]]], device='cuda:0')\n",
      "tensor([[[ 9.2226e+00],\n",
      "         [ 1.0517e+00],\n",
      "         [-4.1870e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2291],\n",
      "         [ 1.0236],\n",
      "         [-0.0816]]], device='cuda:0')\n",
      "tensor([[[ 9.2086],\n",
      "         [ 1.0635],\n",
      "         [-0.0098]]], device='cuda:0')\n",
      "tensor([[[ 9.2005e+00],\n",
      "         [ 1.1687e+00],\n",
      "         [-4.8547e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2441],\n",
      "         [ 1.0695],\n",
      "         [-0.0226]]], device='cuda:0')\n",
      "tensor([[[ 9.2348],\n",
      "         [ 1.0560],\n",
      "         [-0.0286]]], device='cuda:0')\n",
      "tensor([[[9.1763],\n",
      "         [1.0507],\n",
      "         [0.0713]]], device='cuda:0')\n",
      "tensor([[[ 9.2341],\n",
      "         [ 1.0753],\n",
      "         [-0.0401]]], device='cuda:0')\n",
      "tensor([[[ 9.2406],\n",
      "         [ 1.0522],\n",
      "         [-0.0476]]], device='cuda:0')\n",
      "tensor([[[ 9.2458],\n",
      "         [ 1.0274],\n",
      "         [-0.0302]]], device='cuda:0')\n",
      "tensor([[[ 9.2546],\n",
      "         [ 1.0957],\n",
      "         [-0.0441]]], device='cuda:0')\n",
      "tensor([[[ 9.2407e+00],\n",
      "         [ 1.0686e+00],\n",
      "         [-7.3677e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2287],\n",
      "         [ 1.0445],\n",
      "         [-0.0336]]], device='cuda:0')\n",
      "tensor([[[ 9.2422],\n",
      "         [ 1.0422],\n",
      "         [-0.0112]]], device='cuda:0')\n",
      "tensor([[[ 9.2400],\n",
      "         [ 1.0558],\n",
      "         [-0.0306]]], device='cuda:0')\n",
      "tensor([[[ 9.2393],\n",
      "         [ 1.0526],\n",
      "         [-0.0310]]], device='cuda:0')\n",
      "tensor([[[ 9.1746],\n",
      "         [ 1.0443],\n",
      "         [-0.0125]]], device='cuda:0')\n",
      "tensor([[[ 9.2365],\n",
      "         [ 1.0384],\n",
      "         [-0.0143]]], device='cuda:0')\n",
      "tensor([[[ 9.2511],\n",
      "         [ 1.0380],\n",
      "         [-0.0193]]], device='cuda:0')\n",
      "tensor([[[ 9.2437],\n",
      "         [ 1.0291],\n",
      "         [-0.0243]]], device='cuda:0')\n",
      "tensor([[[ 9.2447],\n",
      "         [ 1.0509],\n",
      "         [-0.0153]]], device='cuda:0')\n",
      "tensor([[[9.2184e+00],\n",
      "         [1.0502e+00],\n",
      "         [8.9025e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2517],\n",
      "         [ 1.0442],\n",
      "         [-0.0325]]], device='cuda:0')\n",
      "tensor([[[ 9.2707],\n",
      "         [ 1.0461],\n",
      "         [-0.0139]]], device='cuda:0')\n",
      "tensor([[[ 9.2293],\n",
      "         [ 1.0532],\n",
      "         [-0.0312]]], device='cuda:0')\n",
      "tensor([[[ 9.2516],\n",
      "         [ 1.0588],\n",
      "         [-0.0364]]], device='cuda:0')\n",
      "tensor([[[9.2475e+00],\n",
      "         [1.0716e+00],\n",
      "         [4.2270e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2305],\n",
      "         [ 0.9799],\n",
      "         [-0.0410]]], device='cuda:0')\n",
      "tensor([[[ 9.2620],\n",
      "         [ 0.9915],\n",
      "         [-0.0336]]], device='cuda:0')\n",
      "tensor([[[ 9.2192],\n",
      "         [ 1.0193],\n",
      "         [-0.0183]]], device='cuda:0')\n",
      "tensor([[[9.2253],\n",
      "         [1.0543],\n",
      "         [0.0882]]], device='cuda:0')\n",
      "tensor([[[ 9.2384],\n",
      "         [ 1.0625],\n",
      "         [-0.0168]]], device='cuda:0')\n",
      "tensor([[[9.2151],\n",
      "         [1.0516],\n",
      "         [0.0513]]], device='cuda:0')\n",
      "tensor([[[9.2107],\n",
      "         [1.0717],\n",
      "         [0.0463]]], device='cuda:0')\n",
      "tensor([[[9.2166],\n",
      "         [1.0733],\n",
      "         [0.0470]]], device='cuda:0')\n",
      "tensor([[[ 9.2533],\n",
      "         [ 1.0641],\n",
      "         [-0.0237]]], device='cuda:0')\n",
      "tensor([[[ 9.2263],\n",
      "         [ 1.0603],\n",
      "         [-0.0267]]], device='cuda:0')\n",
      "tensor([[[ 9.2189],\n",
      "         [ 1.0596],\n",
      "         [-0.0257]]], device='cuda:0')\n",
      "tensor([[[ 9.2160],\n",
      "         [ 1.0495],\n",
      "         [-0.0109]]], device='cuda:0')\n",
      "tensor([[[ 9.2316],\n",
      "         [ 1.0318],\n",
      "         [-0.0187]]], device='cuda:0')\n",
      "tensor([[[ 9.2122],\n",
      "         [ 1.0785],\n",
      "         [-0.0460]]], device='cuda:0')\n",
      "tensor([[[ 9.2347],\n",
      "         [ 1.0646],\n",
      "         [-0.0191]]], device='cuda:0')\n",
      "tensor([[[ 9.2746],\n",
      "         [ 1.0702],\n",
      "         [-0.0202]]], device='cuda:0')\n",
      "tensor([[[9.1989],\n",
      "         [1.0712],\n",
      "         [0.1048]]], device='cuda:0')\n",
      "tensor([[[ 9.2081e+00],\n",
      "         [ 1.0662e+00],\n",
      "         [-2.7785e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2448],\n",
      "         [ 1.0849],\n",
      "         [-0.0529]]], device='cuda:0')\n",
      "tensor([[[ 9.2118],\n",
      "         [ 1.0423],\n",
      "         [-0.0290]]], device='cuda:0')\n",
      "tensor([[[ 9.2412],\n",
      "         [ 1.0663],\n",
      "         [-0.0218]]], device='cuda:0')\n",
      "tensor([[[9.2294e+00],\n",
      "         [1.0528e+00],\n",
      "         [2.1380e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2396],\n",
      "         [ 1.0631],\n",
      "         [-0.0459]]], device='cuda:0')\n",
      "tensor([[[ 9.2514e+00],\n",
      "         [ 1.0648e+00],\n",
      "         [-8.5674e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.2178e+00],\n",
      "         [ 1.0615e+00],\n",
      "         [-3.0396e-04]]], device='cuda:0')\n",
      "tensor([[[ 9.2600],\n",
      "         [ 1.0600],\n",
      "         [-0.0171]]], device='cuda:0')\n",
      "tensor([[[9.2434],\n",
      "         [1.0754],\n",
      "         [0.0180]]], device='cuda:0')\n",
      "tensor([[[9.2233],\n",
      "         [1.0707],\n",
      "         [0.0893]]], device='cuda:0')\n",
      "tensor([[[9.2135],\n",
      "         [1.0516],\n",
      "         [0.0624]]], device='cuda:0')\n",
      "tensor([[[ 9.2406e+00],\n",
      "         [ 1.0614e+00],\n",
      "         [-5.5004e-03]]], device='cuda:0')\n",
      "tensor([[[9.2941],\n",
      "         [1.0498],\n",
      "         [0.0118]]], device='cuda:0')\n",
      "tensor([[[ 9.2656],\n",
      "         [ 1.0499],\n",
      "         [-0.0115]]], device='cuda:0')\n",
      "tensor([[[1.0504],\n",
      "         [8.2549],\n",
      "         [1.0027]]], device='cuda:0')\n",
      "tensor([[[1.0474],\n",
      "         [8.2783],\n",
      "         [0.9971]]], device='cuda:0')\n",
      "tensor([[[1.0395],\n",
      "         [8.2590],\n",
      "         [1.0434]]], device='cuda:0')\n",
      "tensor([[[1.0598],\n",
      "         [8.1864],\n",
      "         [1.0337]]], device='cuda:0')\n",
      "tensor([[[1.0105],\n",
      "         [8.3504],\n",
      "         [1.0582]]], device='cuda:0')\n",
      "tensor([[[1.0273],\n",
      "         [8.2435],\n",
      "         [1.0339]]], device='cuda:0')\n",
      "tensor([[[1.0127],\n",
      "         [8.2950],\n",
      "         [1.0533]]], device='cuda:0')\n",
      "tensor([[[1.0308],\n",
      "         [8.2507],\n",
      "         [1.0628]]], device='cuda:0')\n",
      "tensor([[[0.9996],\n",
      "         [8.1950],\n",
      "         [0.9776]]], device='cuda:0')\n",
      "tensor([[[1.0221],\n",
      "         [8.2810],\n",
      "         [1.0617]]], device='cuda:0')\n",
      "tensor([[[1.0177],\n",
      "         [8.2220],\n",
      "         [1.0303]]], device='cuda:0')\n",
      "tensor([[[1.0403],\n",
      "         [8.2709],\n",
      "         [1.0326]]], device='cuda:0')\n",
      "tensor([[[0.9795],\n",
      "         [8.2247],\n",
      "         [1.0332]]], device='cuda:0')\n",
      "tensor([[[1.0743],\n",
      "         [8.2702],\n",
      "         [1.0365]]], device='cuda:0')\n",
      "tensor([[[0.9965],\n",
      "         [8.2162],\n",
      "         [1.0305]]], device='cuda:0')\n",
      "tensor([[[1.0510],\n",
      "         [8.2527],\n",
      "         [1.0253]]], device='cuda:0')\n",
      "tensor([[[1.0529],\n",
      "         [8.2324],\n",
      "         [0.9763]]], device='cuda:0')\n",
      "tensor([[[1.0466],\n",
      "         [8.2437],\n",
      "         [0.9810]]], device='cuda:0')\n",
      "tensor([[[1.0471],\n",
      "         [8.2450],\n",
      "         [1.0467]]], device='cuda:0')\n",
      "tensor([[[1.0256],\n",
      "         [8.2583],\n",
      "         [1.0336]]], device='cuda:0')\n",
      "tensor([[[1.0241],\n",
      "         [8.2152],\n",
      "         [1.0366]]], device='cuda:0')\n",
      "tensor([[[1.0275],\n",
      "         [8.2828],\n",
      "         [0.9981]]], device='cuda:0')\n",
      "tensor([[[1.0495],\n",
      "         [8.2317],\n",
      "         [1.0320]]], device='cuda:0')\n",
      "tensor([[[1.0394],\n",
      "         [8.2552],\n",
      "         [1.0084]]], device='cuda:0')\n",
      "tensor([[[1.0650],\n",
      "         [8.2327],\n",
      "         [1.0423]]], device='cuda:0')\n",
      "tensor([[[1.0626],\n",
      "         [8.2508],\n",
      "         [1.0463]]], device='cuda:0')\n",
      "tensor([[[1.0551],\n",
      "         [8.2554],\n",
      "         [0.9928]]], device='cuda:0')\n",
      "tensor([[[1.0390],\n",
      "         [8.2465],\n",
      "         [1.0223]]], device='cuda:0')\n",
      "tensor([[[1.0228],\n",
      "         [8.3279],\n",
      "         [0.9891]]], device='cuda:0')\n",
      "tensor([[[1.0558],\n",
      "         [8.1947],\n",
      "         [1.0826]]], device='cuda:0')\n",
      "tensor([[[1.0484],\n",
      "         [8.3116],\n",
      "         [1.0176]]], device='cuda:0')\n",
      "tensor([[[1.0426],\n",
      "         [8.2468],\n",
      "         [1.0587]]], device='cuda:0')\n",
      "tensor([[[1.0150],\n",
      "         [8.2688],\n",
      "         [1.0589]]], device='cuda:0')\n",
      "tensor([[[1.0499],\n",
      "         [8.1982],\n",
      "         [1.0499]]], device='cuda:0')\n",
      "tensor([[[1.0465],\n",
      "         [8.3135],\n",
      "         [1.0037]]], device='cuda:0')\n",
      "tensor([[[1.0238],\n",
      "         [7.5585],\n",
      "         [1.0218]]], device='cuda:0')\n",
      "tensor([[[0.9787],\n",
      "         [8.2982],\n",
      "         [1.1059]]], device='cuda:0')\n",
      "tensor([[[1.0596],\n",
      "         [8.3481],\n",
      "         [1.0506]]], device='cuda:0')\n",
      "tensor([[[1.0530],\n",
      "         [8.3245],\n",
      "         [1.0627]]], device='cuda:0')\n",
      "tensor([[[1.0316],\n",
      "         [8.2622],\n",
      "         [1.0485]]], device='cuda:0')\n",
      "tensor([[[1.0165],\n",
      "         [8.3781],\n",
      "         [1.0789]]], device='cuda:0')\n",
      "tensor([[[1.0300],\n",
      "         [8.2856],\n",
      "         [1.0437]]], device='cuda:0')\n",
      "tensor([[[1.0429],\n",
      "         [8.2342],\n",
      "         [1.0642]]], device='cuda:0')\n",
      "tensor([[[1.0524],\n",
      "         [8.2206],\n",
      "         [1.0651]]], device='cuda:0')\n",
      "tensor([[[1.0479],\n",
      "         [8.3311],\n",
      "         [1.0181]]], device='cuda:0')\n",
      "tensor([[[1.0038],\n",
      "         [8.2482],\n",
      "         [1.0591]]], device='cuda:0')\n",
      "tensor([[[0.9954],\n",
      "         [8.2799],\n",
      "         [1.0508]]], device='cuda:0')\n",
      "tensor([[[1.0166],\n",
      "         [8.3002],\n",
      "         [1.0753]]], device='cuda:0')\n",
      "tensor([[[1.0445],\n",
      "         [8.2611],\n",
      "         [1.0768]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0523],\n",
      "         [8.2175],\n",
      "         [1.0005]]], device='cuda:0')\n",
      "tensor([[[1.0525],\n",
      "         [8.2384],\n",
      "         [1.0180]]], device='cuda:0')\n",
      "tensor([[[1.0795],\n",
      "         [8.2271],\n",
      "         [1.0338]]], device='cuda:0')\n",
      "tensor([[[1.0054],\n",
      "         [8.2458],\n",
      "         [1.0754]]], device='cuda:0')\n",
      "tensor([[[1.0499],\n",
      "         [8.1891],\n",
      "         [8.0941]]], device='cuda:0')\n",
      "tensor([[[1.0242],\n",
      "         [8.3016],\n",
      "         [1.0638]]], device='cuda:0')\n",
      "tensor([[[1.0336],\n",
      "         [8.2677],\n",
      "         [1.0678]]], device='cuda:0')\n",
      "tensor([[[1.0349],\n",
      "         [8.2791],\n",
      "         [0.9642]]], device='cuda:0')\n",
      "tensor([[[1.0525],\n",
      "         [8.2063],\n",
      "         [1.0495]]], device='cuda:0')\n",
      "tensor([[[1.0402],\n",
      "         [8.2279],\n",
      "         [1.0651]]], device='cuda:0')\n",
      "tensor([[[1.0153],\n",
      "         [8.2695],\n",
      "         [1.0262]]], device='cuda:0')\n",
      "tensor([[[1.0584],\n",
      "         [8.2792],\n",
      "         [1.1287]]], device='cuda:0')\n",
      "tensor([[[1.0461],\n",
      "         [8.2649],\n",
      "         [1.0042]]], device='cuda:0')\n",
      "tensor([[[1.0093],\n",
      "         [8.2111],\n",
      "         [1.0366]]], device='cuda:0')\n",
      "tensor([[[1.0091],\n",
      "         [8.2873],\n",
      "         [1.0374]]], device='cuda:0')\n",
      "tensor([[[1.0362],\n",
      "         [8.2353],\n",
      "         [1.0255]]], device='cuda:0')\n",
      "tensor([[[0.8932],\n",
      "         [8.3095],\n",
      "         [1.0655]]], device='cuda:0')\n",
      "tensor([[[1.0153],\n",
      "         [8.2392],\n",
      "         [1.0377]]], device='cuda:0')\n",
      "tensor([[[1.0345],\n",
      "         [8.2381],\n",
      "         [1.0606]]], device='cuda:0')\n",
      "tensor([[[0.9837],\n",
      "         [8.2972],\n",
      "         [1.0078]]], device='cuda:0')\n",
      "tensor([[[1.0241],\n",
      "         [7.3422],\n",
      "         [0.9422]]], device='cuda:0')\n",
      "tensor([[[1.0221],\n",
      "         [8.2617],\n",
      "         [1.0729]]], device='cuda:0')\n",
      "tensor([[[0.9947],\n",
      "         [8.3329],\n",
      "         [1.0329]]], device='cuda:0')\n",
      "tensor([[[1.0062],\n",
      "         [8.2887],\n",
      "         [1.0309]]], device='cuda:0')\n",
      "tensor([[[1.0211],\n",
      "         [8.3129],\n",
      "         [1.0238]]], device='cuda:0')\n",
      "tensor([[[1.0354],\n",
      "         [8.2414],\n",
      "         [1.0606]]], device='cuda:0')\n",
      "tensor([[[0.9767],\n",
      "         [8.2565],\n",
      "         [1.1023]]], device='cuda:0')\n",
      "tensor([[[1.0098],\n",
      "         [8.2913],\n",
      "         [1.0436]]], device='cuda:0')\n",
      "tensor([[[1.0327],\n",
      "         [8.3265],\n",
      "         [0.9926]]], device='cuda:0')\n",
      "tensor([[[1.0217],\n",
      "         [8.3279],\n",
      "         [0.9843]]], device='cuda:0')\n",
      "tensor([[[1.0633],\n",
      "         [8.2821],\n",
      "         [1.0156]]], device='cuda:0')\n",
      "tensor([[[1.0419],\n",
      "         [8.2285],\n",
      "         [1.0373]]], device='cuda:0')\n",
      "tensor([[[1.0070],\n",
      "         [8.2663],\n",
      "         [0.9782]]], device='cuda:0')\n",
      "tensor([[[1.0464],\n",
      "         [8.2822],\n",
      "         [1.0347]]], device='cuda:0')\n",
      "tensor([[[1.0735],\n",
      "         [8.2285],\n",
      "         [1.0927]]], device='cuda:0')\n",
      "tensor([[[1.0385],\n",
      "         [8.2714],\n",
      "         [0.9675]]], device='cuda:0')\n",
      "tensor([[[1.0397],\n",
      "         [8.3001],\n",
      "         [1.0524]]], device='cuda:0')\n",
      "tensor([[[1.0386],\n",
      "         [8.2163],\n",
      "         [1.0368]]], device='cuda:0')\n",
      "tensor([[[0.9986],\n",
      "         [8.2802],\n",
      "         [1.0016]]], device='cuda:0')\n",
      "tensor([[[1.0577],\n",
      "         [8.1505],\n",
      "         [1.0397]]], device='cuda:0')\n",
      "tensor([[[1.0356],\n",
      "         [8.2769],\n",
      "         [1.0035]]], device='cuda:0')\n",
      "tensor([[[1.4391],\n",
      "         [6.5206],\n",
      "         [1.2485]]], device='cuda:0')\n",
      "tensor([[[1.0528],\n",
      "         [8.2317],\n",
      "         [0.9913]]], device='cuda:0')\n",
      "tensor([[[1.0401],\n",
      "         [8.3209],\n",
      "         [0.9932]]], device='cuda:0')\n",
      "tensor([[[1.0213],\n",
      "         [8.3570],\n",
      "         [1.0516]]], device='cuda:0')\n",
      "tensor([[[1.0884],\n",
      "         [8.2523],\n",
      "         [1.0513]]], device='cuda:0')\n",
      "tensor([[[0.9917],\n",
      "         [8.2928],\n",
      "         [1.0579]]], device='cuda:0')\n",
      "tensor([[[2.6752],\n",
      "         [6.2267],\n",
      "         [2.0591]]], device='cuda:0')\n",
      "tensor([[[1.0323],\n",
      "         [8.2835],\n",
      "         [1.0728]]], device='cuda:0')\n",
      "tensor([[[1.0616],\n",
      "         [8.2149],\n",
      "         [1.0153]]], device='cuda:0')\n",
      "tensor([[[1.0549],\n",
      "         [8.3351],\n",
      "         [1.0297]]], device='cuda:0')\n",
      "tensor([[[1.0605],\n",
      "         [6.1582],\n",
      "         [1.0549]]], device='cuda:0')\n",
      "tensor([[[1.0055],\n",
      "         [8.3275],\n",
      "         [1.0158]]], device='cuda:0')\n",
      "tensor([[[1.0230],\n",
      "         [8.2694],\n",
      "         [1.0530]]], device='cuda:0')\n",
      "tensor([[[1.0744],\n",
      "         [8.2682],\n",
      "         [0.9713]]], device='cuda:0')\n",
      "tensor([[[1.0337],\n",
      "         [8.2795],\n",
      "         [1.0258]]], device='cuda:0')\n",
      "tensor([[[1.0333],\n",
      "         [8.2675],\n",
      "         [1.0251]]], device='cuda:0')\n",
      "tensor([[[1.0198],\n",
      "         [8.2744],\n",
      "         [1.0526]]], device='cuda:0')\n",
      "tensor([[[1.0717],\n",
      "         [8.2925],\n",
      "         [0.9864]]], device='cuda:0')\n",
      "tensor([[[1.0224],\n",
      "         [8.2516],\n",
      "         [1.0021]]], device='cuda:0')\n",
      "tensor([[[1.0501],\n",
      "         [8.2037],\n",
      "         [1.0130]]], device='cuda:0')\n",
      "tensor([[[1.0633],\n",
      "         [8.2658],\n",
      "         [0.9947]]], device='cuda:0')\n",
      "tensor([[[1.0457],\n",
      "         [8.2690],\n",
      "         [0.9898]]], device='cuda:0')\n",
      "tensor([[[1.0303],\n",
      "         [8.2176],\n",
      "         [1.0234]]], device='cuda:0')\n",
      "tensor([[[1.0336],\n",
      "         [8.2352],\n",
      "         [1.0193]]], device='cuda:0')\n",
      "tensor([[[1.0254],\n",
      "         [8.2436],\n",
      "         [1.0299]]], device='cuda:0')\n",
      "tensor([[[1.0727],\n",
      "         [8.1997],\n",
      "         [1.0427]]], device='cuda:0')\n",
      "tensor([[[1.0232],\n",
      "         [8.2273],\n",
      "         [1.0488]]], device='cuda:0')\n",
      "tensor([[[1.0279],\n",
      "         [8.1766],\n",
      "         [1.0312]]], device='cuda:0')\n",
      "tensor([[[1.0325],\n",
      "         [8.2902],\n",
      "         [1.0238]]], device='cuda:0')\n",
      "tensor([[[1.0177],\n",
      "         [8.2958],\n",
      "         [1.0499]]], device='cuda:0')\n",
      "tensor([[[0.9832],\n",
      "         [8.3761],\n",
      "         [1.0893]]], device='cuda:0')\n",
      "tensor([[[0.9979],\n",
      "         [8.2705],\n",
      "         [1.0679]]], device='cuda:0')\n",
      "tensor([[[1.0418],\n",
      "         [8.3000],\n",
      "         [1.0501]]], device='cuda:0')\n",
      "tensor([[[1.0354],\n",
      "         [8.2570],\n",
      "         [1.0082]]], device='cuda:0')\n",
      "tensor([[[1.0292],\n",
      "         [8.3404],\n",
      "         [1.0643]]], device='cuda:0')\n",
      "tensor([[[1.0325],\n",
      "         [8.3081],\n",
      "         [1.0419]]], device='cuda:0')\n",
      "tensor([[[1.0120],\n",
      "         [8.2986],\n",
      "         [1.0168]]], device='cuda:0')\n",
      "tensor([[[0.9971],\n",
      "         [7.5311],\n",
      "         [1.0562]]], device='cuda:0')\n",
      "tensor([[[1.0195],\n",
      "         [8.3434],\n",
      "         [1.0490]]], device='cuda:0')\n",
      "tensor([[[1.0267],\n",
      "         [8.2743],\n",
      "         [1.0453]]], device='cuda:0')\n",
      "tensor([[[1.0360],\n",
      "         [8.2756],\n",
      "         [0.9851]]], device='cuda:0')\n",
      "tensor([[[1.0273],\n",
      "         [8.2271],\n",
      "         [1.0599]]], device='cuda:0')\n",
      "tensor([[[1.1199],\n",
      "         [8.1952],\n",
      "         [0.9794]]], device='cuda:0')\n",
      "tensor([[[1.0425],\n",
      "         [8.2834],\n",
      "         [1.1094]]], device='cuda:0')\n",
      "tensor([[[1.0446],\n",
      "         [8.2309],\n",
      "         [1.0196]]], device='cuda:0')\n",
      "tensor([[[0.9594],\n",
      "         [8.2545],\n",
      "         [1.0369]]], device='cuda:0')\n",
      "tensor([[[1.0402],\n",
      "         [8.2592],\n",
      "         [1.0411]]], device='cuda:0')\n",
      "tensor([[[1.0689],\n",
      "         [8.3511],\n",
      "         [1.0031]]], device='cuda:0')\n",
      "tensor([[[1.0621],\n",
      "         [8.2282],\n",
      "         [1.0792]]], device='cuda:0')\n",
      "tensor([[[0.9923],\n",
      "         [8.2815],\n",
      "         [0.9817]]], device='cuda:0')\n",
      "tensor([[[1.0285],\n",
      "         [8.1823],\n",
      "         [1.0248]]], device='cuda:0')\n",
      "tensor([[[1.0486],\n",
      "         [8.1943],\n",
      "         [1.0449]]], device='cuda:0')\n",
      "tensor([[[1.0150],\n",
      "         [8.2507],\n",
      "         [1.0349]]], device='cuda:0')\n",
      "tensor([[[1.0135],\n",
      "         [8.3500],\n",
      "         [1.0357]]], device='cuda:0')\n",
      "tensor([[[1.0484],\n",
      "         [8.2649],\n",
      "         [0.9746]]], device='cuda:0')\n",
      "tensor([[[0.9872],\n",
      "         [8.2472],\n",
      "         [1.0951]]], device='cuda:0')\n",
      "tensor([[[1.0494],\n",
      "         [8.1720],\n",
      "         [1.0690]]], device='cuda:0')\n",
      "tensor([[[1.0115],\n",
      "         [8.2757],\n",
      "         [1.0415]]], device='cuda:0')\n",
      "tensor([[[1.0324],\n",
      "         [8.2006],\n",
      "         [0.9911]]], device='cuda:0')\n",
      "tensor([[[0.9747],\n",
      "         [8.3045],\n",
      "         [1.3428]]], device='cuda:0')\n",
      "tensor([[[1.0667],\n",
      "         [8.3573],\n",
      "         [1.0456]]], device='cuda:0')\n",
      "tensor([[[1.0868],\n",
      "         [8.2479],\n",
      "         [1.0173]]], device='cuda:0')\n",
      "tensor([[[1.0351],\n",
      "         [8.3015],\n",
      "         [0.9750]]], device='cuda:0')\n",
      "tensor([[[1.0142],\n",
      "         [8.2140],\n",
      "         [1.0802]]], device='cuda:0')\n",
      "tensor([[[1.0078],\n",
      "         [8.1779],\n",
      "         [1.0826]]], device='cuda:0')\n",
      "tensor([[[1.0334],\n",
      "         [8.1956],\n",
      "         [1.0696]]], device='cuda:0')\n",
      "tensor([[[1.0579],\n",
      "         [8.2535],\n",
      "         [1.0585]]], device='cuda:0')\n",
      "tensor([[[1.0424],\n",
      "         [8.2689],\n",
      "         [1.0381]]], device='cuda:0')\n",
      "tensor([[[1.0481],\n",
      "         [8.2281],\n",
      "         [1.0002]]], device='cuda:0')\n",
      "tensor([[[1.0227],\n",
      "         [8.3194],\n",
      "         [1.0394]]], device='cuda:0')\n",
      "tensor([[[1.0465],\n",
      "         [8.3074],\n",
      "         [1.0520]]], device='cuda:0')\n",
      "tensor([[[1.0131],\n",
      "         [8.3412],\n",
      "         [1.0718]]], device='cuda:0')\n",
      "tensor([[[1.0443],\n",
      "         [8.2481],\n",
      "         [1.0724]]], device='cuda:0')\n",
      "tensor([[[1.0278],\n",
      "         [8.2991],\n",
      "         [1.0469]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0249],\n",
      "         [8.2161],\n",
      "         [1.0124]]], device='cuda:0')\n",
      "tensor([[[1.0143],\n",
      "         [8.2849],\n",
      "         [1.0089]]], device='cuda:0')\n",
      "tensor([[[1.0054],\n",
      "         [7.4581],\n",
      "         [1.0175]]], device='cuda:0')\n",
      "tensor([[[0.9981],\n",
      "         [8.2295],\n",
      "         [1.0374]]], device='cuda:0')\n",
      "tensor([[[1.0383],\n",
      "         [8.3029],\n",
      "         [1.0058]]], device='cuda:0')\n",
      "tensor([[[1.0313],\n",
      "         [8.2591],\n",
      "         [0.9712]]], device='cuda:0')\n",
      "tensor([[[1.0164],\n",
      "         [8.2049],\n",
      "         [8.1443]]], device='cuda:0')\n",
      "tensor([[[1.0241],\n",
      "         [8.2759],\n",
      "         [0.9996]]], device='cuda:0')\n",
      "tensor([[[1.0196],\n",
      "         [8.2363],\n",
      "         [1.0453]]], device='cuda:0')\n",
      "tensor([[[1.0411],\n",
      "         [8.2583],\n",
      "         [1.0592]]], device='cuda:0')\n",
      "tensor([[[1.0110],\n",
      "         [8.3142],\n",
      "         [1.0162]]], device='cuda:0')\n",
      "tensor([[[1.0360],\n",
      "         [8.2861],\n",
      "         [1.0205]]], device='cuda:0')\n",
      "tensor([[[1.0247],\n",
      "         [8.2463],\n",
      "         [1.0182]]], device='cuda:0')\n",
      "tensor([[[1.0181],\n",
      "         [8.3261],\n",
      "         [1.0205]]], device='cuda:0')\n",
      "tensor([[[1.0198],\n",
      "         [8.2735],\n",
      "         [1.0559]]], device='cuda:0')\n",
      "tensor([[[1.0068],\n",
      "         [8.2522],\n",
      "         [1.0691]]], device='cuda:0')\n",
      "tensor([[[1.0491],\n",
      "         [8.2373],\n",
      "         [1.0424]]], device='cuda:0')\n",
      "tensor([[[1.0110],\n",
      "         [8.2101],\n",
      "         [1.0839]]], device='cuda:0')\n",
      "tensor([[[1.0441],\n",
      "         [8.2749],\n",
      "         [1.0633]]], device='cuda:0')\n",
      "tensor([[[1.0625],\n",
      "         [8.2474],\n",
      "         [0.9912]]], device='cuda:0')\n",
      "tensor([[[1.0434],\n",
      "         [8.3648],\n",
      "         [1.0519]]], device='cuda:0')\n",
      "tensor([[[1.0188],\n",
      "         [8.3055],\n",
      "         [1.0563]]], device='cuda:0')\n",
      "tensor([[[1.0605],\n",
      "         [8.2788],\n",
      "         [1.0177]]], device='cuda:0')\n",
      "tensor([[[1.0493],\n",
      "         [8.2561],\n",
      "         [1.0213]]], device='cuda:0')\n",
      "tensor([[[0.9973],\n",
      "         [8.2284],\n",
      "         [1.0349]]], device='cuda:0')\n",
      "tensor([[[1.0157],\n",
      "         [8.1996],\n",
      "         [1.0200]]], device='cuda:0')\n",
      "tensor([[[1.0410],\n",
      "         [8.2567],\n",
      "         [1.0530]]], device='cuda:0')\n",
      "tensor([[[1.0344],\n",
      "         [8.2854],\n",
      "         [1.0170]]], device='cuda:0')\n",
      "tensor([[[1.0539],\n",
      "         [8.3598],\n",
      "         [1.0697]]], device='cuda:0')\n",
      "tensor([[[1.0470],\n",
      "         [8.2186],\n",
      "         [0.9989]]], device='cuda:0')\n",
      "tensor([[[0.9970],\n",
      "         [8.2470],\n",
      "         [1.0484]]], device='cuda:0')\n",
      "tensor([[[1.0454],\n",
      "         [8.2669],\n",
      "         [0.9892]]], device='cuda:0')\n",
      "tensor([[[1.0331],\n",
      "         [8.2533],\n",
      "         [1.0307]]], device='cuda:0')\n",
      "tensor([[[1.0167],\n",
      "         [8.2729],\n",
      "         [1.0690]]], device='cuda:0')\n",
      "tensor([[[1.0251],\n",
      "         [8.2257],\n",
      "         [1.0289]]], device='cuda:0')\n",
      "tensor([[[1.0138],\n",
      "         [8.2754],\n",
      "         [1.0628]]], device='cuda:0')\n",
      "tensor([[[1.0427],\n",
      "         [8.2698],\n",
      "         [1.0282]]], device='cuda:0')\n",
      "tensor([[[1.0220],\n",
      "         [8.2524],\n",
      "         [1.0404]]], device='cuda:0')\n",
      "tensor([[[1.0362],\n",
      "         [8.2362],\n",
      "         [1.0533]]], device='cuda:0')\n",
      "tensor([[[1.0335],\n",
      "         [8.3425],\n",
      "         [1.0258]]], device='cuda:0')\n",
      "tensor([[[1.0234],\n",
      "         [8.2305],\n",
      "         [1.0429]]], device='cuda:0')\n",
      "tensor([[[0.9752],\n",
      "         [8.3075],\n",
      "         [1.1127]]], device='cuda:0')\n",
      "tensor([[[1.0495],\n",
      "         [8.2563],\n",
      "         [0.9993]]], device='cuda:0')\n",
      "tensor([[[1.0217],\n",
      "         [8.2541],\n",
      "         [8.1213]]], device='cuda:0')\n",
      "tensor([[[1.0501],\n",
      "         [8.2810],\n",
      "         [1.0295]]], device='cuda:0')\n",
      "tensor([[[1.0326],\n",
      "         [8.3366],\n",
      "         [1.0542]]], device='cuda:0')\n",
      "tensor([[[1.0691],\n",
      "         [8.2006],\n",
      "         [1.1162]]], device='cuda:0')\n",
      "tensor([[[1.0217],\n",
      "         [8.2528],\n",
      "         [1.0254]]], device='cuda:0')\n",
      "tensor([[[1.0710],\n",
      "         [8.1366],\n",
      "         [1.0673]]], device='cuda:0')\n",
      "tensor([[[1.0415],\n",
      "         [8.3043],\n",
      "         [1.0291]]], device='cuda:0')\n",
      "tensor([[[1.0513],\n",
      "         [8.1611],\n",
      "         [1.0728]]], device='cuda:0')\n",
      "tensor([[[1.0192],\n",
      "         [8.2938],\n",
      "         [1.0445]]], device='cuda:0')\n",
      "tensor([[[1.0167],\n",
      "         [8.2278],\n",
      "         [1.0287]]], device='cuda:0')\n",
      "tensor([[[1.0324],\n",
      "         [8.2344],\n",
      "         [1.0154]]], device='cuda:0')\n",
      "tensor([[[1.0273],\n",
      "         [8.2678],\n",
      "         [1.0367]]], device='cuda:0')\n",
      "tensor([[[1.0334],\n",
      "         [8.2491],\n",
      "         [1.0240]]], device='cuda:0')\n",
      "tensor([[[1.0418],\n",
      "         [8.2883],\n",
      "         [1.0098]]], device='cuda:0')\n",
      "tensor([[[0.9965],\n",
      "         [8.2325],\n",
      "         [1.0704]]], device='cuda:0')\n",
      "tensor([[[1.0466],\n",
      "         [8.2614],\n",
      "         [1.0338]]], device='cuda:0')\n",
      "tensor([[[0.9971],\n",
      "         [8.3199],\n",
      "         [1.0736]]], device='cuda:0')\n",
      "tensor([[[1.0301],\n",
      "         [8.2651],\n",
      "         [1.0532]]], device='cuda:0')\n",
      "tensor([[[1.0561],\n",
      "         [8.2091],\n",
      "         [1.0963]]], device='cuda:0')\n",
      "tensor([[[0.9959],\n",
      "         [8.3262],\n",
      "         [1.0522]]], device='cuda:0')\n",
      "tensor([[[1.0295],\n",
      "         [8.2126],\n",
      "         [1.0306]]], device='cuda:0')\n",
      "tensor([[[1.0112],\n",
      "         [8.2514],\n",
      "         [1.0641]]], device='cuda:0')\n",
      "tensor([[[1.0180],\n",
      "         [8.2400],\n",
      "         [8.1203]]], device='cuda:0')\n",
      "tensor([[[1.0121],\n",
      "         [8.2416],\n",
      "         [1.0537]]], device='cuda:0')\n",
      "tensor([[[1.0406],\n",
      "         [8.2443],\n",
      "         [1.0654]]], device='cuda:0')\n",
      "tensor([[[1.0443],\n",
      "         [7.9407],\n",
      "         [1.0435]]], device='cuda:0')\n",
      "tensor([[[1.0137],\n",
      "         [8.2256],\n",
      "         [1.3028]]], device='cuda:0')\n",
      "tensor([[[1.0361],\n",
      "         [8.2299],\n",
      "         [1.0205]]], device='cuda:0')\n",
      "tensor([[[1.0357],\n",
      "         [8.3074],\n",
      "         [1.0282]]], device='cuda:0')\n",
      "tensor([[[1.0395],\n",
      "         [8.2795],\n",
      "         [1.0360]]], device='cuda:0')\n",
      "tensor([[[1.0502],\n",
      "         [8.2296],\n",
      "         [1.0583]]], device='cuda:0')\n",
      "tensor([[[1.0400],\n",
      "         [8.3259],\n",
      "         [1.0531]]], device='cuda:0')\n",
      "tensor([[[1.0002],\n",
      "         [8.3000],\n",
      "         [1.0229]]], device='cuda:0')\n",
      "tensor([[[1.0227],\n",
      "         [8.3045],\n",
      "         [1.0540]]], device='cuda:0')\n",
      "tensor([[[1.0245],\n",
      "         [8.2675],\n",
      "         [1.0695]]], device='cuda:0')\n",
      "tensor([[[1.0324],\n",
      "         [8.2684],\n",
      "         [1.0115]]], device='cuda:0')\n",
      "tensor([[[1.0428],\n",
      "         [8.2315],\n",
      "         [1.0116]]], device='cuda:0')\n",
      "tensor([[[1.0386],\n",
      "         [8.2347],\n",
      "         [1.0714]]], device='cuda:0')\n",
      "tensor([[[1.0176],\n",
      "         [8.3707],\n",
      "         [1.0609]]], device='cuda:0')\n",
      "tensor([[[1.0027],\n",
      "         [8.2715],\n",
      "         [1.0339]]], device='cuda:0')\n",
      "tensor([[[1.0406],\n",
      "         [8.3364],\n",
      "         [1.0188]]], device='cuda:0')\n",
      "tensor([[[1.0357],\n",
      "         [8.2954],\n",
      "         [1.0099]]], device='cuda:0')\n",
      "tensor([[[1.0153],\n",
      "         [8.2307],\n",
      "         [1.0540]]], device='cuda:0')\n",
      "tensor([[[1.0495],\n",
      "         [8.2608],\n",
      "         [0.9666]]], device='cuda:0')\n",
      "tensor([[[1.0607],\n",
      "         [8.2248],\n",
      "         [1.0308]]], device='cuda:0')\n",
      "tensor([[[1.0449],\n",
      "         [8.2833],\n",
      "         [1.0552]]], device='cuda:0')\n",
      "tensor([[[1.0456],\n",
      "         [8.3775],\n",
      "         [1.0389]]], device='cuda:0')\n",
      "tensor([[[1.0286],\n",
      "         [8.2906],\n",
      "         [0.9715]]], device='cuda:0')\n",
      "tensor([[[1.0250],\n",
      "         [8.2560],\n",
      "         [0.9944]]], device='cuda:0')\n",
      "tensor([[[1.0270],\n",
      "         [8.3458],\n",
      "         [1.0752]]], device='cuda:0')\n",
      "tensor([[[1.0085],\n",
      "         [8.2491],\n",
      "         [1.0460]]], device='cuda:0')\n",
      "tensor([[[1.0336],\n",
      "         [8.2321],\n",
      "         [1.0190]]], device='cuda:0')\n",
      "tensor([[[1.0323],\n",
      "         [8.2107],\n",
      "         [1.0412]]], device='cuda:0')\n",
      "tensor([[[1.0197],\n",
      "         [8.3034],\n",
      "         [1.0496]]], device='cuda:0')\n",
      "tensor([[[1.0270],\n",
      "         [8.1928],\n",
      "         [1.0049]]], device='cuda:0')\n",
      "tensor([[[1.0498],\n",
      "         [8.2550],\n",
      "         [1.0692]]], device='cuda:0')\n",
      "tensor([[[1.0314],\n",
      "         [8.2427],\n",
      "         [1.0272]]], device='cuda:0')\n",
      "tensor([[[1.0278],\n",
      "         [8.2300],\n",
      "         [1.0833]]], device='cuda:0')\n",
      "tensor([[[1.0260],\n",
      "         [8.3111],\n",
      "         [1.0063]]], device='cuda:0')\n",
      "tensor([[[1.0156],\n",
      "         [8.3273],\n",
      "         [0.9785]]], device='cuda:0')\n",
      "tensor([[[0.9905],\n",
      "         [8.2594],\n",
      "         [1.0494]]], device='cuda:0')\n",
      "tensor([[[1.0301],\n",
      "         [8.2708],\n",
      "         [1.0332]]], device='cuda:0')\n",
      "tensor([[[1.0776],\n",
      "         [8.2681],\n",
      "         [0.9987]]], device='cuda:0')\n",
      "tensor([[[1.0469],\n",
      "         [8.2985],\n",
      "         [0.9798]]], device='cuda:0')\n",
      "tensor([[[0.9726],\n",
      "         [8.2778],\n",
      "         [1.0188]]], device='cuda:0')\n",
      "tensor([[[1.0365],\n",
      "         [8.2692],\n",
      "         [0.9857]]], device='cuda:0')\n",
      "tensor([[[1.0228],\n",
      "         [8.2070],\n",
      "         [1.0360]]], device='cuda:0')\n",
      "tensor([[[1.0119],\n",
      "         [7.7546],\n",
      "         [1.0341]]], device='cuda:0')\n",
      "tensor([[[1.0398],\n",
      "         [8.2644],\n",
      "         [1.0782]]], device='cuda:0')\n",
      "tensor([[[0.9894],\n",
      "         [8.2655],\n",
      "         [0.9985]]], device='cuda:0')\n",
      "tensor([[[1.0369],\n",
      "         [8.2793],\n",
      "         [1.0592]]], device='cuda:0')\n",
      "tensor([[[1.0373],\n",
      "         [8.2311],\n",
      "         [0.9691]]], device='cuda:0')\n",
      "tensor([[[1.0133],\n",
      "         [8.2780],\n",
      "         [0.9858]]], device='cuda:0')\n",
      "tensor([[[1.0410],\n",
      "         [8.2092],\n",
      "         [1.0092]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0161],\n",
      "         [8.3078],\n",
      "         [1.0736]]], device='cuda:0')\n",
      "tensor([[[1.0131],\n",
      "         [8.2730],\n",
      "         [0.9857]]], device='cuda:0')\n",
      "tensor([[[1.0225],\n",
      "         [8.1958],\n",
      "         [1.0089]]], device='cuda:0')\n",
      "tensor([[[1.0332],\n",
      "         [8.2286],\n",
      "         [1.0651]]], device='cuda:0')\n",
      "tensor([[[1.0140],\n",
      "         [8.2799],\n",
      "         [1.0282]]], device='cuda:0')\n",
      "tensor([[[1.0206],\n",
      "         [8.1931],\n",
      "         [1.0621]]], device='cuda:0')\n",
      "tensor([[[1.0367],\n",
      "         [8.2282],\n",
      "         [1.0265]]], device='cuda:0')\n",
      "tensor([[[1.0271],\n",
      "         [8.2766],\n",
      "         [0.9840]]], device='cuda:0')\n",
      "tensor([[[1.0440],\n",
      "         [8.2082],\n",
      "         [1.0600]]], device='cuda:0')\n",
      "tensor([[[1.0378],\n",
      "         [8.2693],\n",
      "         [1.0320]]], device='cuda:0')\n",
      "tensor([[[1.0691],\n",
      "         [8.2090],\n",
      "         [1.0201]]], device='cuda:0')\n",
      "tensor([[[1.0515],\n",
      "         [8.2552],\n",
      "         [1.0169]]], device='cuda:0')\n",
      "tensor([[[1.0366],\n",
      "         [8.2852],\n",
      "         [1.0187]]], device='cuda:0')\n",
      "tensor([[[1.0082],\n",
      "         [8.2111],\n",
      "         [1.0199]]], device='cuda:0')\n",
      "tensor([[[1.0376],\n",
      "         [8.2288],\n",
      "         [1.1342]]], device='cuda:0')\n",
      "tensor([[[1.0119],\n",
      "         [8.2642],\n",
      "         [1.0686]]], device='cuda:0')\n",
      "tensor([[[1.0355],\n",
      "         [8.2898],\n",
      "         [1.0756]]], device='cuda:0')\n",
      "tensor([[[1.0205],\n",
      "         [8.2595],\n",
      "         [1.0544]]], device='cuda:0')\n",
      "tensor([[[1.0507],\n",
      "         [8.2671],\n",
      "         [1.0165]]], device='cuda:0')\n",
      "tensor([[[1.0061],\n",
      "         [8.2197],\n",
      "         [1.0294]]], device='cuda:0')\n",
      "tensor([[[1.0192],\n",
      "         [8.2226],\n",
      "         [1.0329]]], device='cuda:0')\n",
      "tensor([[[1.0309],\n",
      "         [8.3355],\n",
      "         [1.0058]]], device='cuda:0')\n",
      "tensor([[[1.0073],\n",
      "         [8.2889],\n",
      "         [1.0003]]], device='cuda:0')\n",
      "tensor([[[1.0314],\n",
      "         [8.2338],\n",
      "         [1.0087]]], device='cuda:0')\n",
      "tensor([[[1.0570],\n",
      "         [8.3433],\n",
      "         [1.0578]]], device='cuda:0')\n",
      "tensor([[[1.0704],\n",
      "         [8.1988],\n",
      "         [1.0873]]], device='cuda:0')\n",
      "tensor([[[1.0297],\n",
      "         [8.2933],\n",
      "         [1.0485]]], device='cuda:0')\n",
      "tensor([[[1.0185],\n",
      "         [8.2772],\n",
      "         [1.0196]]], device='cuda:0')\n",
      "tensor([[[1.0541],\n",
      "         [8.2707],\n",
      "         [1.0207]]], device='cuda:0')\n",
      "tensor([[[1.0435],\n",
      "         [8.3325],\n",
      "         [1.0457]]], device='cuda:0')\n",
      "tensor([[[1.0871],\n",
      "         [8.2462],\n",
      "         [1.0252]]], device='cuda:0')\n",
      "tensor([[[1.0448],\n",
      "         [8.3037],\n",
      "         [1.0713]]], device='cuda:0')\n",
      "tensor([[[1.0347],\n",
      "         [8.2340],\n",
      "         [1.0448]]], device='cuda:0')\n",
      "tensor([[[1.0471],\n",
      "         [8.2821],\n",
      "         [1.0062]]], device='cuda:0')\n",
      "tensor([[[0.9536],\n",
      "         [6.9521],\n",
      "         [1.0002]]], device='cuda:0')\n",
      "tensor([[[1.0000],\n",
      "         [8.2238],\n",
      "         [1.0589]]], device='cuda:0')\n",
      "tensor([[[1.0495],\n",
      "         [8.2773],\n",
      "         [1.0176]]], device='cuda:0')\n",
      "tensor([[[1.0813],\n",
      "         [8.2575],\n",
      "         [1.4365]]], device='cuda:0')\n",
      "tensor([[[1.0024],\n",
      "         [8.3007],\n",
      "         [1.0334]]], device='cuda:0')\n",
      "tensor([[[1.0443],\n",
      "         [8.2532],\n",
      "         [1.0487]]], device='cuda:0')\n",
      "tensor([[[1.0377],\n",
      "         [8.1920],\n",
      "         [1.0064]]], device='cuda:0')\n",
      "tensor([[[1.0295],\n",
      "         [8.2530],\n",
      "         [1.0177]]], device='cuda:0')\n",
      "tensor([[[1.0486],\n",
      "         [8.2171],\n",
      "         [1.0221]]], device='cuda:0')\n",
      "tensor([[[1.0493],\n",
      "         [8.2833],\n",
      "         [1.1102]]], device='cuda:0')\n",
      "tensor([[[0.9997],\n",
      "         [8.1781],\n",
      "         [1.0309]]], device='cuda:0')\n",
      "tensor([[[1.0392],\n",
      "         [8.2337],\n",
      "         [1.0248]]], device='cuda:0')\n",
      "tensor([[[1.0413],\n",
      "         [8.2015],\n",
      "         [1.0167]]], device='cuda:0')\n",
      "tensor([[[1.0430],\n",
      "         [8.2571],\n",
      "         [1.0155]]], device='cuda:0')\n",
      "tensor([[[1.0181],\n",
      "         [8.2532],\n",
      "         [8.1519]]], device='cuda:0')\n",
      "tensor([[[1.0188],\n",
      "         [8.2704],\n",
      "         [1.0346]]], device='cuda:0')\n",
      "tensor([[[1.0141],\n",
      "         [8.2140],\n",
      "         [1.0533]]], device='cuda:0')\n",
      "tensor([[[0.9772],\n",
      "         [8.3524],\n",
      "         [1.0226]]], device='cuda:0')\n",
      "tensor([[[1.0644],\n",
      "         [8.3308],\n",
      "         [1.0224]]], device='cuda:0')\n",
      "tensor([[[1.0505],\n",
      "         [8.2726],\n",
      "         [1.0816]]], device='cuda:0')\n",
      "tensor([[[1.0303],\n",
      "         [8.2213],\n",
      "         [1.0142]]], device='cuda:0')\n",
      "tensor([[[1.0584],\n",
      "         [8.3602],\n",
      "         [1.0920]]], device='cuda:0')\n",
      "tensor([[[1.0415],\n",
      "         [8.1820],\n",
      "         [1.0642]]], device='cuda:0')\n",
      "tensor([[[1.0278],\n",
      "         [8.2578],\n",
      "         [1.0367]]], device='cuda:0')\n",
      "tensor([[[1.0376],\n",
      "         [8.2433],\n",
      "         [1.0284]]], device='cuda:0')\n",
      "tensor([[[1.0265],\n",
      "         [8.2865],\n",
      "         [1.0156]]], device='cuda:0')\n",
      "tensor([[[1.0103],\n",
      "         [8.2780],\n",
      "         [1.0527]]], device='cuda:0')\n",
      "tensor([[[1.0437],\n",
      "         [8.3338],\n",
      "         [1.0464]]], device='cuda:0')\n",
      "tensor([[[1.0387],\n",
      "         [8.2271],\n",
      "         [0.9750]]], device='cuda:0')\n",
      "tensor([[[1.0385],\n",
      "         [8.2623],\n",
      "         [0.9798]]], device='cuda:0')\n",
      "tensor([[[1.0437],\n",
      "         [8.2144],\n",
      "         [1.0430]]], device='cuda:0')\n",
      "tensor([[[1.0401],\n",
      "         [8.2749],\n",
      "         [1.0114]]], device='cuda:0')\n",
      "tensor([[[1.0228],\n",
      "         [8.2683],\n",
      "         [1.0019]]], device='cuda:0')\n",
      "tensor([[[1.0310],\n",
      "         [8.2992],\n",
      "         [1.0172]]], device='cuda:0')\n",
      "tensor([[[1.0905],\n",
      "         [8.2560],\n",
      "         [0.9687]]], device='cuda:0')\n",
      "tensor([[[1.0081],\n",
      "         [8.1898],\n",
      "         [1.0236]]], device='cuda:0')\n",
      "tensor([[[1.0316],\n",
      "         [8.3346],\n",
      "         [1.0187]]], device='cuda:0')\n",
      "tensor([[[1.0710],\n",
      "         [8.2191],\n",
      "         [1.0435]]], device='cuda:0')\n",
      "tensor([[[0.9949],\n",
      "         [8.2689],\n",
      "         [1.0232]]], device='cuda:0')\n",
      "tensor([[[1.0357],\n",
      "         [8.2575],\n",
      "         [0.9807]]], device='cuda:0')\n",
      "tensor([[[0.9783],\n",
      "         [7.4904],\n",
      "         [1.0614]]], device='cuda:0')\n",
      "tensor([[[0.8687],\n",
      "         [7.6685],\n",
      "         [1.0881]]], device='cuda:0')\n",
      "tensor([[[1.0422],\n",
      "         [8.2479],\n",
      "         [1.0153]]], device='cuda:0')\n",
      "tensor([[[0.9909],\n",
      "         [8.2476],\n",
      "         [8.1498]]], device='cuda:0')\n",
      "tensor([[[1.0183],\n",
      "         [8.3095],\n",
      "         [1.0470]]], device='cuda:0')\n",
      "tensor([[[1.0560],\n",
      "         [8.3456],\n",
      "         [1.0037]]], device='cuda:0')\n",
      "tensor([[[0.9999],\n",
      "         [8.1631],\n",
      "         [0.9879]]], device='cuda:0')\n",
      "tensor([[[1.0159],\n",
      "         [8.2696],\n",
      "         [1.0560]]], device='cuda:0')\n",
      "tensor([[[1.0548],\n",
      "         [8.2602],\n",
      "         [1.0136]]], device='cuda:0')\n",
      "tensor([[[1.0138],\n",
      "         [8.2702],\n",
      "         [1.0068]]], device='cuda:0')\n",
      "tensor([[[1.0592],\n",
      "         [8.2092],\n",
      "         [1.0555]]], device='cuda:0')\n",
      "tensor([[[1.0511],\n",
      "         [8.2333],\n",
      "         [1.0047]]], device='cuda:0')\n",
      "tensor([[[1.0449],\n",
      "         [8.2304],\n",
      "         [1.0906]]], device='cuda:0')\n",
      "tensor([[[1.0228],\n",
      "         [8.2325],\n",
      "         [1.0075]]], device='cuda:0')\n",
      "tensor([[[0.9881],\n",
      "         [8.2838],\n",
      "         [1.0686]]], device='cuda:0')\n",
      "tensor([[[1.0570],\n",
      "         [8.2272],\n",
      "         [0.9883]]], device='cuda:0')\n",
      "tensor([[[1.0199],\n",
      "         [8.2856],\n",
      "         [1.0451]]], device='cuda:0')\n",
      "tensor([[[1.0065],\n",
      "         [8.2628],\n",
      "         [1.0991]]], device='cuda:0')\n",
      "tensor([[[1.0465],\n",
      "         [8.2253],\n",
      "         [1.0186]]], device='cuda:0')\n",
      "tensor([[[1.0227],\n",
      "         [8.2383],\n",
      "         [1.0376]]], device='cuda:0')\n",
      "tensor([[[1.0242],\n",
      "         [8.2516],\n",
      "         [1.0340]]], device='cuda:0')\n",
      "tensor([[[1.0607],\n",
      "         [8.2568],\n",
      "         [1.0300]]], device='cuda:0')\n",
      "tensor([[[1.0241],\n",
      "         [8.2896],\n",
      "         [1.0280]]], device='cuda:0')\n",
      "tensor([[[0.9931],\n",
      "         [7.3163],\n",
      "         [0.9983]]], device='cuda:0')\n",
      "tensor([[[1.0099],\n",
      "         [8.2332],\n",
      "         [1.0187]]], device='cuda:0')\n",
      "tensor([[[1.0180],\n",
      "         [8.2327],\n",
      "         [1.0664]]], device='cuda:0')\n",
      "tensor([[[1.0366],\n",
      "         [8.3310],\n",
      "         [1.0572]]], device='cuda:0')\n",
      "tensor([[[1.0407],\n",
      "         [8.3561],\n",
      "         [1.0319]]], device='cuda:0')\n",
      "tensor([[[0.9842],\n",
      "         [8.3293],\n",
      "         [1.0386]]], device='cuda:0')\n",
      "tensor([[[0.9906],\n",
      "         [8.2389],\n",
      "         [1.0785]]], device='cuda:0')\n",
      "tensor([[[1.0129],\n",
      "         [8.2852],\n",
      "         [1.0678]]], device='cuda:0')\n",
      "tensor([[[1.0213],\n",
      "         [8.1299],\n",
      "         [1.0445]]], device='cuda:0')\n",
      "tensor([[[1.0490],\n",
      "         [8.2808],\n",
      "         [1.0053]]], device='cuda:0')\n",
      "tensor([[[1.0297],\n",
      "         [8.2758],\n",
      "         [0.9768]]], device='cuda:0')\n",
      "tensor([[[1.0233],\n",
      "         [8.2408],\n",
      "         [1.0312]]], device='cuda:0')\n",
      "tensor([[[1.0490],\n",
      "         [8.2340],\n",
      "         [1.0676]]], device='cuda:0')\n",
      "tensor([[[1.0437],\n",
      "         [8.2420],\n",
      "         [1.0274]]], device='cuda:0')\n",
      "tensor([[[1.0164],\n",
      "         [8.2544],\n",
      "         [1.0366]]], device='cuda:0')\n",
      "tensor([[[1.0276],\n",
      "         [8.2496],\n",
      "         [1.0639]]], device='cuda:0')\n",
      "tensor([[[1.0175],\n",
      "         [8.2739],\n",
      "         [1.0758]]], device='cuda:0')\n",
      "tensor([[[1.0137],\n",
      "         [8.2523],\n",
      "         [1.0045]]], device='cuda:0')\n",
      "tensor([[[1.0262],\n",
      "         [8.2923],\n",
      "         [1.0495]]], device='cuda:0')\n",
      "tensor([[[1.0348],\n",
      "         [8.2279],\n",
      "         [1.0462]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0258],\n",
      "         [8.2569],\n",
      "         [1.0129]]], device='cuda:0')\n",
      "tensor([[[1.0560],\n",
      "         [8.2121],\n",
      "         [1.0519]]], device='cuda:0')\n",
      "tensor([[[1.0481],\n",
      "         [8.1939],\n",
      "         [1.0380]]], device='cuda:0')\n",
      "tensor([[[1.0722],\n",
      "         [8.2461],\n",
      "         [1.0327]]], device='cuda:0')\n",
      "tensor([[[1.0223],\n",
      "         [8.3088],\n",
      "         [1.0427]]], device='cuda:0')\n",
      "tensor([[[1.0283],\n",
      "         [8.2567],\n",
      "         [1.0545]]], device='cuda:0')\n",
      "tensor([[[0.9974],\n",
      "         [8.1808],\n",
      "         [1.0585]]], device='cuda:0')\n",
      "tensor([[[1.0398],\n",
      "         [8.3087],\n",
      "         [1.0577]]], device='cuda:0')\n",
      "tensor([[[1.0069],\n",
      "         [8.3035],\n",
      "         [1.0232]]], device='cuda:0')\n",
      "tensor([[[1.0510],\n",
      "         [8.3015],\n",
      "         [1.0410]]], device='cuda:0')\n",
      "tensor([[[1.0277],\n",
      "         [8.2460],\n",
      "         [1.0242]]], device='cuda:0')\n",
      "tensor([[[0.9782],\n",
      "         [8.1949],\n",
      "         [1.0724]]], device='cuda:0')\n",
      "tensor([[[0.9966],\n",
      "         [8.2333],\n",
      "         [1.0641]]], device='cuda:0')\n",
      "tensor([[[1.0686],\n",
      "         [8.3404],\n",
      "         [1.0449]]], device='cuda:0')\n",
      "tensor([[[1.0523],\n",
      "         [8.2342],\n",
      "         [1.0440]]], device='cuda:0')\n",
      "tensor([[[1.0448],\n",
      "         [8.3102],\n",
      "         [0.9977]]], device='cuda:0')\n",
      "tensor([[[1.0408],\n",
      "         [8.2213],\n",
      "         [1.0373]]], device='cuda:0')\n",
      "tensor([[[1.0250],\n",
      "         [8.2428],\n",
      "         [1.0565]]], device='cuda:0')\n",
      "tensor([[[1.0396],\n",
      "         [8.2409],\n",
      "         [1.0294]]], device='cuda:0')\n",
      "tensor([[[1.0418],\n",
      "         [8.2587],\n",
      "         [1.0417]]], device='cuda:0')\n",
      "tensor([[[1.0457],\n",
      "         [8.2512],\n",
      "         [1.0296]]], device='cuda:0')\n",
      "tensor([[[1.0104],\n",
      "         [8.2184],\n",
      "         [1.0517]]], device='cuda:0')\n",
      "tensor([[[1.0168],\n",
      "         [8.2327],\n",
      "         [1.0626]]], device='cuda:0')\n",
      "tensor([[[1.0263],\n",
      "         [8.2810],\n",
      "         [1.1445]]], device='cuda:0')\n",
      "tensor([[[1.0373],\n",
      "         [8.3026],\n",
      "         [1.0533]]], device='cuda:0')\n",
      "tensor([[[1.0188],\n",
      "         [8.2335],\n",
      "         [1.0393]]], device='cuda:0')\n",
      "tensor([[[1.0259],\n",
      "         [8.3053],\n",
      "         [1.0552]]], device='cuda:0')\n",
      "tensor([[[1.0310],\n",
      "         [8.2764],\n",
      "         [1.0242]]], device='cuda:0')\n",
      "tensor([[[1.0177],\n",
      "         [8.2218],\n",
      "         [0.9958]]], device='cuda:0')\n",
      "tensor([[[1.0465],\n",
      "         [8.2964],\n",
      "         [1.0756]]], device='cuda:0')\n",
      "tensor([[[1.0515],\n",
      "         [8.2103],\n",
      "         [1.0376]]], device='cuda:0')\n",
      "tensor([[[1.0987],\n",
      "         [8.1645],\n",
      "         [0.9582]]], device='cuda:0')\n",
      "tensor([[[1.0350],\n",
      "         [8.2691],\n",
      "         [1.0492]]], device='cuda:0')\n",
      "tensor([[[1.0264],\n",
      "         [8.2178],\n",
      "         [1.0638]]], device='cuda:0')\n",
      "tensor([[[1.0139],\n",
      "         [8.2144],\n",
      "         [1.0073]]], device='cuda:0')\n",
      "tensor([[[1.0383],\n",
      "         [8.3297],\n",
      "         [0.9767]]], device='cuda:0')\n",
      "tensor([[[1.0057],\n",
      "         [8.2444],\n",
      "         [1.0476]]], device='cuda:0')\n",
      "tensor([[[1.0301],\n",
      "         [8.2574],\n",
      "         [1.0539]]], device='cuda:0')\n",
      "tensor([[[1.0328],\n",
      "         [8.2144],\n",
      "         [1.1343]]], device='cuda:0')\n",
      "tensor([[[1.0157],\n",
      "         [8.2931],\n",
      "         [1.0208]]], device='cuda:0')\n",
      "tensor([[[1.0318],\n",
      "         [8.2478],\n",
      "         [1.0290]]], device='cuda:0')\n",
      "tensor([[[1.0256],\n",
      "         [8.2703],\n",
      "         [1.0658]]], device='cuda:0')\n",
      "tensor([[[1.0251],\n",
      "         [8.2735],\n",
      "         [1.0633]]], device='cuda:0')\n",
      "tensor([[[1.0498],\n",
      "         [8.2310],\n",
      "         [1.0609]]], device='cuda:0')\n",
      "tensor([[[1.0412],\n",
      "         [8.2507],\n",
      "         [1.0127]]], device='cuda:0')\n",
      "tensor([[[1.0180],\n",
      "         [8.2865],\n",
      "         [1.0132]]], device='cuda:0')\n",
      "tensor([[[1.0393],\n",
      "         [8.2318],\n",
      "         [1.0768]]], device='cuda:0')\n",
      "tensor([[[1.0356],\n",
      "         [8.2964],\n",
      "         [1.0631]]], device='cuda:0')\n",
      "tensor([[[1.0360],\n",
      "         [8.2960],\n",
      "         [1.0379]]], device='cuda:0')\n",
      "tensor([[[1.0487],\n",
      "         [8.2405],\n",
      "         [0.9947]]], device='cuda:0')\n",
      "tensor([[[0.9304],\n",
      "         [8.2647],\n",
      "         [1.0459]]], device='cuda:0')\n",
      "tensor([[[1.0182],\n",
      "         [8.3407],\n",
      "         [1.0165]]], device='cuda:0')\n",
      "tensor([[[1.0435],\n",
      "         [8.3056],\n",
      "         [1.0295]]], device='cuda:0')\n",
      "tensor([[[1.0261],\n",
      "         [8.2144],\n",
      "         [1.1026]]], device='cuda:0')\n",
      "tensor([[[0.9993],\n",
      "         [8.2129],\n",
      "         [1.0813]]], device='cuda:0')\n",
      "tensor([[[1.0377],\n",
      "         [8.2543],\n",
      "         [1.0382]]], device='cuda:0')\n",
      "tensor([[[1.0479],\n",
      "         [8.2268],\n",
      "         [1.0027]]], device='cuda:0')\n",
      "tensor([[[1.0205],\n",
      "         [8.2099],\n",
      "         [1.0486]]], device='cuda:0')\n",
      "tensor([[[1.0875],\n",
      "         [8.1826],\n",
      "         [1.0514]]], device='cuda:0')\n",
      "tensor([[[1.0352],\n",
      "         [8.2350],\n",
      "         [1.0131]]], device='cuda:0')\n",
      "tensor([[[0.9784],\n",
      "         [8.2575],\n",
      "         [1.0133]]], device='cuda:0')\n",
      "tensor([[[1.0276],\n",
      "         [8.2785],\n",
      "         [1.0297]]], device='cuda:0')\n",
      "tensor([[[0.9816],\n",
      "         [6.7434],\n",
      "         [0.9851]]], device='cuda:0')\n",
      "tensor([[[0.9852],\n",
      "         [8.2855],\n",
      "         [1.0958]]], device='cuda:0')\n",
      "tensor([[[1.0393],\n",
      "         [8.2781],\n",
      "         [0.9718]]], device='cuda:0')\n",
      "tensor([[[1.0328],\n",
      "         [8.2901],\n",
      "         [1.0302]]], device='cuda:0')\n",
      "tensor([[[1.0205],\n",
      "         [8.3452],\n",
      "         [1.0252]]], device='cuda:0')\n",
      "tensor([[[1.0302],\n",
      "         [8.2298],\n",
      "         [1.0043]]], device='cuda:0')\n",
      "tensor([[[1.0008],\n",
      "         [8.2326],\n",
      "         [1.0830]]], device='cuda:0')\n",
      "tensor([[[1.0007],\n",
      "         [8.2458],\n",
      "         [1.0868]]], device='cuda:0')\n",
      "tensor([[[1.0290],\n",
      "         [8.2508],\n",
      "         [1.0074]]], device='cuda:0')\n",
      "tensor([[[1.0452],\n",
      "         [8.2617],\n",
      "         [1.0595]]], device='cuda:0')\n",
      "tensor([[[1.0581],\n",
      "         [8.2334],\n",
      "         [1.0434]]], device='cuda:0')\n",
      "tensor([[[1.0539],\n",
      "         [8.3186],\n",
      "         [1.0311]]], device='cuda:0')\n",
      "tensor([[[1.0310],\n",
      "         [8.2466],\n",
      "         [1.0797]]], device='cuda:0')\n",
      "tensor([[[1.0121],\n",
      "         [8.2318],\n",
      "         [1.0369]]], device='cuda:0')\n",
      "tensor([[[1.0228],\n",
      "         [8.2970],\n",
      "         [1.0109]]], device='cuda:0')\n",
      "tensor([[[1.0539],\n",
      "         [8.2086],\n",
      "         [0.9929]]], device='cuda:0')\n",
      "tensor([[[1.0437],\n",
      "         [8.2581],\n",
      "         [0.9882]]], device='cuda:0')\n",
      "tensor([[[1.0271],\n",
      "         [8.2851],\n",
      "         [1.0029]]], device='cuda:0')\n",
      "tensor([[[1.0229],\n",
      "         [8.2817],\n",
      "         [0.9919]]], device='cuda:0')\n",
      "tensor([[[1.0282],\n",
      "         [8.2737],\n",
      "         [1.0087]]], device='cuda:0')\n",
      "tensor([[[1.0146],\n",
      "         [8.2702],\n",
      "         [1.0210]]], device='cuda:0')\n",
      "tensor([[[1.0364],\n",
      "         [8.2216],\n",
      "         [0.9664]]], device='cuda:0')\n",
      "tensor([[[0.9523],\n",
      "         [7.1805],\n",
      "         [0.9348]]], device='cuda:0')\n",
      "tensor([[[1.0176],\n",
      "         [8.2774],\n",
      "         [1.0381]]], device='cuda:0')\n",
      "tensor([[[1.0326],\n",
      "         [8.2964],\n",
      "         [1.0000]]], device='cuda:0')\n",
      "tensor([[[1.0107],\n",
      "         [8.2658],\n",
      "         [1.0670]]], device='cuda:0')\n",
      "tensor([[[1.0270],\n",
      "         [8.3088],\n",
      "         [1.0299]]], device='cuda:0')\n",
      "tensor([[[1.0468],\n",
      "         [8.2509],\n",
      "         [1.0069]]], device='cuda:0')\n",
      "tensor([[[1.0255],\n",
      "         [8.2314],\n",
      "         [0.9935]]], device='cuda:0')\n",
      "tensor([[[1.6790],\n",
      "         [5.9730],\n",
      "         [1.7562]]], device='cuda:0')\n",
      "tensor([[[1.0457],\n",
      "         [8.2477],\n",
      "         [1.1063]]], device='cuda:0')\n",
      "tensor([[[1.0049],\n",
      "         [8.2557],\n",
      "         [1.0325]]], device='cuda:0')\n",
      "tensor([[[1.0310],\n",
      "         [8.2993],\n",
      "         [1.0253]]], device='cuda:0')\n",
      "tensor([[[0.9801],\n",
      "         [8.1964],\n",
      "         [1.0546]]], device='cuda:0')\n",
      "tensor([[[1.0458],\n",
      "         [8.1917],\n",
      "         [0.9815]]], device='cuda:0')\n",
      "tensor([[[1.0208],\n",
      "         [8.3060],\n",
      "         [1.0231]]], device='cuda:0')\n",
      "tensor([[[1.0906],\n",
      "         [8.2615],\n",
      "         [0.9949]]], device='cuda:0')\n",
      "tensor([[[1.0641],\n",
      "         [8.2559],\n",
      "         [1.0187]]], device='cuda:0')\n",
      "tensor([[[1.0131],\n",
      "         [8.2563],\n",
      "         [1.0447]]], device='cuda:0')\n",
      "tensor([[[1.0392],\n",
      "         [8.3009],\n",
      "         [1.0631]]], device='cuda:0')\n",
      "tensor([[[1.0547],\n",
      "         [8.2802],\n",
      "         [1.0012]]], device='cuda:0')\n",
      "tensor([[[1.0456],\n",
      "         [8.1973],\n",
      "         [1.0663]]], device='cuda:0')\n",
      "tensor([[[1.0295],\n",
      "         [8.2458],\n",
      "         [1.0600]]], device='cuda:0')\n",
      "tensor([[[0.9963],\n",
      "         [8.2641],\n",
      "         [1.0653]]], device='cuda:0')\n",
      "tensor([[[1.0521],\n",
      "         [8.2273],\n",
      "         [1.0024]]], device='cuda:0')\n",
      "tensor([[[1.0408],\n",
      "         [8.3121],\n",
      "         [1.0396]]], device='cuda:0')\n",
      "tensor([[[0.9940],\n",
      "         [8.2934],\n",
      "         [1.0442]]], device='cuda:0')\n",
      "tensor([[[1.0122],\n",
      "         [8.2193],\n",
      "         [1.0740]]], device='cuda:0')\n",
      "tensor([[[1.0164],\n",
      "         [8.2936],\n",
      "         [1.0168]]], device='cuda:0')\n",
      "tensor([[[1.0428],\n",
      "         [8.2119],\n",
      "         [1.0311]]], device='cuda:0')\n",
      "tensor([[[1.0381],\n",
      "         [8.3188],\n",
      "         [1.0039]]], device='cuda:0')\n",
      "tensor([[[1.0035],\n",
      "         [8.3643],\n",
      "         [1.0893]]], device='cuda:0')\n",
      "tensor([[[1.0110],\n",
      "         [8.2557],\n",
      "         [1.0554]]], device='cuda:0')\n",
      "tensor([[[1.0224],\n",
      "         [8.2500],\n",
      "         [1.0439]]], device='cuda:0')\n",
      "tensor([[[1.0014],\n",
      "         [8.3089],\n",
      "         [1.0204]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0236],\n",
      "         [8.2921],\n",
      "         [1.0121]]], device='cuda:0')\n",
      "tensor([[[1.0135],\n",
      "         [8.1932],\n",
      "         [1.0602]]], device='cuda:0')\n",
      "tensor([[[1.0545],\n",
      "         [8.2346],\n",
      "         [1.0155]]], device='cuda:0')\n",
      "tensor([[[1.0532],\n",
      "         [8.2841],\n",
      "         [1.0802]]], device='cuda:0')\n",
      "tensor([[[1.0503],\n",
      "         [8.2048],\n",
      "         [0.9911]]], device='cuda:0')\n",
      "tensor([[[1.0429],\n",
      "         [8.2320],\n",
      "         [0.9735]]], device='cuda:0')\n",
      "tensor([[[1.0428],\n",
      "         [8.2716],\n",
      "         [1.0179]]], device='cuda:0')\n",
      "tensor([[[1.0678],\n",
      "         [8.3296],\n",
      "         [0.9899]]], device='cuda:0')\n",
      "tensor([[[0.9914],\n",
      "         [8.3396],\n",
      "         [1.0223]]], device='cuda:0')\n",
      "tensor([[[1.0247],\n",
      "         [8.1883],\n",
      "         [1.0077]]], device='cuda:0')\n",
      "tensor([[[1.0026],\n",
      "         [8.2493],\n",
      "         [1.0681]]], device='cuda:0')\n",
      "tensor([[[1.0090],\n",
      "         [8.2435],\n",
      "         [1.0714]]], device='cuda:0')\n",
      "tensor([[[1.0510],\n",
      "         [8.2628],\n",
      "         [1.0156]]], device='cuda:0')\n",
      "tensor([[[1.0375],\n",
      "         [8.2333],\n",
      "         [1.0316]]], device='cuda:0')\n",
      "tensor([[[1.0523],\n",
      "         [8.2178],\n",
      "         [1.0741]]], device='cuda:0')\n",
      "tensor([[[0.9880],\n",
      "         [8.3230],\n",
      "         [1.0194]]], device='cuda:0')\n",
      "tensor([[[1.0558],\n",
      "         [8.3571],\n",
      "         [0.9812]]], device='cuda:0')\n",
      "tensor([[[1.0278],\n",
      "         [8.2631],\n",
      "         [1.0658]]], device='cuda:0')\n",
      "tensor([[[1.0557],\n",
      "         [8.2707],\n",
      "         [0.9866]]], device='cuda:0')\n",
      "tensor([[[0.9603],\n",
      "         [8.3564],\n",
      "         [1.0302]]], device='cuda:0')\n",
      "tensor([[[1.0455],\n",
      "         [7.3961],\n",
      "         [0.9886]]], device='cuda:0')\n",
      "tensor([[[1.0113],\n",
      "         [8.3039],\n",
      "         [1.0185]]], device='cuda:0')\n",
      "tensor([[[1.0054],\n",
      "         [8.2354],\n",
      "         [1.0324]]], device='cuda:0')\n",
      "tensor([[[1.0315],\n",
      "         [8.2388],\n",
      "         [0.9816]]], device='cuda:0')\n",
      "tensor([[[1.0041],\n",
      "         [8.1550],\n",
      "         [1.0830]]], device='cuda:0')\n",
      "tensor([[[1.0795],\n",
      "         [8.2420],\n",
      "         [1.0029]]], device='cuda:0')\n",
      "tensor([[[1.0057],\n",
      "         [8.3558],\n",
      "         [1.0116]]], device='cuda:0')\n",
      "tensor([[[1.0970],\n",
      "         [8.2120],\n",
      "         [1.0585]]], device='cuda:0')\n",
      "tensor([[[1.0276],\n",
      "         [8.2522],\n",
      "         [1.0107]]], device='cuda:0')\n",
      "tensor([[[1.0309],\n",
      "         [8.3348],\n",
      "         [1.0243]]], device='cuda:0')\n",
      "tensor([[[1.0685],\n",
      "         [8.2030],\n",
      "         [0.9898]]], device='cuda:0')\n",
      "tensor([[[1.0192],\n",
      "         [8.2530],\n",
      "         [1.0101]]], device='cuda:0')\n",
      "tensor([[[2.0015],\n",
      "         [5.6726],\n",
      "         [2.0777]]], device='cuda:0')\n",
      "tensor([[[0.9922],\n",
      "         [8.2914],\n",
      "         [1.0253]]], device='cuda:0')\n",
      "tensor([[[1.0238],\n",
      "         [8.3925],\n",
      "         [1.0847]]], device='cuda:0')\n",
      "tensor([[[1.0280],\n",
      "         [8.2491],\n",
      "         [1.0205]]], device='cuda:0')\n",
      "tensor([[[1.0496],\n",
      "         [8.1606],\n",
      "         [1.0813]]], device='cuda:0')\n",
      "tensor([[[1.0440],\n",
      "         [8.1825],\n",
      "         [1.0411]]], device='cuda:0')\n",
      "tensor([[[1.0574],\n",
      "         [8.2341],\n",
      "         [1.0474]]], device='cuda:0')\n",
      "tensor([[[1.0087],\n",
      "         [8.2451],\n",
      "         [1.0431]]], device='cuda:0')\n",
      "tensor([[[0.9214],\n",
      "         [8.2639],\n",
      "         [0.9898]]], device='cuda:0')\n",
      "tensor([[[1.0240],\n",
      "         [8.2468],\n",
      "         [1.0619]]], device='cuda:0')\n",
      "tensor([[[1.0209],\n",
      "         [8.2987],\n",
      "         [1.0443]]], device='cuda:0')\n",
      "tensor([[[1.0602],\n",
      "         [8.2550],\n",
      "         [1.0507]]], device='cuda:0')\n",
      "tensor([[[1.0374],\n",
      "         [8.1820],\n",
      "         [1.0117]]], device='cuda:0')\n",
      "tensor([[[1.0259],\n",
      "         [8.2543],\n",
      "         [0.9726]]], device='cuda:0')\n",
      "tensor([[[1.0395],\n",
      "         [8.1745],\n",
      "         [1.0184]]], device='cuda:0')\n",
      "tensor([[[1.0227],\n",
      "         [8.2122],\n",
      "         [1.0436]]], device='cuda:0')\n",
      "tensor([[[1.0263],\n",
      "         [8.2362],\n",
      "         [1.0313]]], device='cuda:0')\n",
      "tensor([[[1.0149],\n",
      "         [8.2294],\n",
      "         [1.0541]]], device='cuda:0')\n",
      "tensor([[[1.0420],\n",
      "         [8.2329],\n",
      "         [1.0401]]], device='cuda:0')\n",
      "tensor([[[1.0422],\n",
      "         [8.2925],\n",
      "         [1.0249]]], device='cuda:0')\n",
      "tensor([[[1.0248],\n",
      "         [8.2673],\n",
      "         [1.0273]]], device='cuda:0')\n",
      "tensor([[[1.0538],\n",
      "         [8.3136],\n",
      "         [1.0385]]], device='cuda:0')\n",
      "tensor([[[0.9739],\n",
      "         [8.3428],\n",
      "         [1.0929]]], device='cuda:0')\n",
      "tensor([[[1.0389],\n",
      "         [8.2673],\n",
      "         [1.0228]]], device='cuda:0')\n",
      "tensor([[[1.0347],\n",
      "         [8.2531],\n",
      "         [1.0093]]], device='cuda:0')\n",
      "tensor([[[1.0488],\n",
      "         [8.2433],\n",
      "         [1.0747]]], device='cuda:0')\n",
      "tensor([[[1.0481],\n",
      "         [8.2567],\n",
      "         [1.1184]]], device='cuda:0')\n",
      "tensor([[[1.0279],\n",
      "         [8.2572],\n",
      "         [1.0234]]], device='cuda:0')\n",
      "tensor([[[1.0355],\n",
      "         [8.2832],\n",
      "         [1.0365]]], device='cuda:0')\n",
      "tensor([[[1.0389],\n",
      "         [8.3112],\n",
      "         [1.0114]]], device='cuda:0')\n",
      "tensor([[[1.0324],\n",
      "         [8.2442],\n",
      "         [1.0517]]], device='cuda:0')\n",
      "tensor([[[1.0299],\n",
      "         [8.1899],\n",
      "         [1.0350]]], device='cuda:0')\n",
      "tensor([[[1.0424],\n",
      "         [8.2577],\n",
      "         [1.0099]]], device='cuda:0')\n",
      "tensor([[[1.0206],\n",
      "         [8.2806],\n",
      "         [0.9437]]], device='cuda:0')\n",
      "tensor([[[1.0260],\n",
      "         [8.3626],\n",
      "         [1.0906]]], device='cuda:0')\n",
      "tensor([[[0.9716],\n",
      "         [8.2364],\n",
      "         [1.0687]]], device='cuda:0')\n",
      "tensor([[[1.0438],\n",
      "         [8.2803],\n",
      "         [0.9694]]], device='cuda:0')\n",
      "tensor([[[1.0283],\n",
      "         [8.2125],\n",
      "         [0.9920]]], device='cuda:0')\n",
      "tensor([[[1.0492],\n",
      "         [8.2338],\n",
      "         [0.9970]]], device='cuda:0')\n",
      "tensor([[[1.0184],\n",
      "         [8.2761],\n",
      "         [1.0032]]], device='cuda:0')\n",
      "tensor([[[1.0247],\n",
      "         [8.2460],\n",
      "         [1.0496]]], device='cuda:0')\n",
      "tensor([[[1.0301],\n",
      "         [8.2236],\n",
      "         [1.0181]]], device='cuda:0')\n",
      "tensor([[[1.0187],\n",
      "         [8.2213],\n",
      "         [0.9931]]], device='cuda:0')\n",
      "tensor([[[1.0405],\n",
      "         [8.3140],\n",
      "         [0.9872]]], device='cuda:0')\n",
      "tensor([[[1.0552],\n",
      "         [8.2096],\n",
      "         [1.0464]]], device='cuda:0')\n",
      "tensor([[[1.0312],\n",
      "         [8.2614],\n",
      "         [0.9940]]], device='cuda:0')\n",
      "tensor([[[1.3430],\n",
      "         [5.9928],\n",
      "         [1.2761]]], device='cuda:0')\n",
      "tensor([[[1.0302],\n",
      "         [8.2521],\n",
      "         [1.0691]]], device='cuda:0')\n",
      "tensor([[[1.0412],\n",
      "         [8.2335],\n",
      "         [1.0521]]], device='cuda:0')\n",
      "tensor([[[1.0080],\n",
      "         [8.2606],\n",
      "         [1.0409]]], device='cuda:0')\n",
      "tensor([[[1.0443],\n",
      "         [8.2171],\n",
      "         [1.0054]]], device='cuda:0')\n",
      "tensor([[[0.9934],\n",
      "         [8.2638],\n",
      "         [1.0196]]], device='cuda:0')\n",
      "tensor([[[1.0923],\n",
      "         [8.3321],\n",
      "         [1.0127]]], device='cuda:0')\n",
      "tensor([[[1.0224],\n",
      "         [8.2891],\n",
      "         [0.9792]]], device='cuda:0')\n",
      "tensor([[[1.0410],\n",
      "         [8.2539],\n",
      "         [1.0341]]], device='cuda:0')\n",
      "tensor([[[1.0562],\n",
      "         [8.3077],\n",
      "         [1.0348]]], device='cuda:0')\n",
      "tensor([[[1.0461],\n",
      "         [8.2114],\n",
      "         [1.0153]]], device='cuda:0')\n",
      "tensor([[[1.0528],\n",
      "         [8.1978],\n",
      "         [1.0008]]], device='cuda:0')\n",
      "tensor([[[1.0501],\n",
      "         [8.1970],\n",
      "         [0.9992]]], device='cuda:0')\n",
      "tensor([[[1.0161],\n",
      "         [8.2833],\n",
      "         [1.0449]]], device='cuda:0')\n",
      "tensor([[[1.0225],\n",
      "         [8.2285],\n",
      "         [1.0524]]], device='cuda:0')\n",
      "tensor([[[1.0370],\n",
      "         [8.3307],\n",
      "         [1.0506]]], device='cuda:0')\n",
      "tensor([[[1.0559],\n",
      "         [8.2767],\n",
      "         [1.0581]]], device='cuda:0')\n",
      "tensor([[[1.0224],\n",
      "         [8.2461],\n",
      "         [1.0566]]], device='cuda:0')\n",
      "tensor([[[1.0215],\n",
      "         [8.2852],\n",
      "         [1.0448]]], device='cuda:0')\n",
      "tensor([[[1.0043],\n",
      "         [8.2117],\n",
      "         [1.0629]]], device='cuda:0')\n",
      "tensor([[[1.0687],\n",
      "         [8.3090],\n",
      "         [1.0229]]], device='cuda:0')\n",
      "tensor([[[1.0533],\n",
      "         [8.3096],\n",
      "         [0.9847]]], device='cuda:0')\n",
      "tensor([[[1.0386],\n",
      "         [8.2571],\n",
      "         [1.0427]]], device='cuda:0')\n",
      "tensor([[[1.0076],\n",
      "         [8.2542],\n",
      "         [1.0180]]], device='cuda:0')\n",
      "tensor([[[1.0093],\n",
      "         [8.2139],\n",
      "         [8.1891]]], device='cuda:0')\n",
      "tensor([[[1.0391],\n",
      "         [8.3047],\n",
      "         [1.0735]]], device='cuda:0')\n",
      "tensor([[[1.0306],\n",
      "         [8.2272],\n",
      "         [1.0351]]], device='cuda:0')\n",
      "tensor([[[1.0048],\n",
      "         [8.3732],\n",
      "         [1.0697]]], device='cuda:0')\n",
      "tensor([[[1.0429],\n",
      "         [8.2577],\n",
      "         [1.0285]]], device='cuda:0')\n",
      "tensor([[[0.9744],\n",
      "         [8.2899],\n",
      "         [1.0608]]], device='cuda:0')\n",
      "tensor([[[1.0050],\n",
      "         [8.2003],\n",
      "         [1.0561]]], device='cuda:0')\n",
      "tensor([[[1.0228],\n",
      "         [8.2495],\n",
      "         [1.0354]]], device='cuda:0')\n",
      "tensor([[[1.0179],\n",
      "         [8.2727],\n",
      "         [1.0152]]], device='cuda:0')\n",
      "tensor([[[1.0678],\n",
      "         [8.3584],\n",
      "         [1.0567]]], device='cuda:0')\n",
      "tensor([[[1.0297],\n",
      "         [8.2585],\n",
      "         [1.0217]]], device='cuda:0')\n",
      "tensor([[[1.0245],\n",
      "         [8.2083],\n",
      "         [1.0527]]], device='cuda:0')\n",
      "tensor([[[1.0579],\n",
      "         [8.2776],\n",
      "         [0.9578]]], device='cuda:0')\n",
      "tensor([[[1.0112],\n",
      "         [8.2549],\n",
      "         [1.0232]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0255],\n",
      "         [8.2659],\n",
      "         [1.0241]]], device='cuda:0')\n",
      "tensor([[[1.0365],\n",
      "         [8.2642],\n",
      "         [1.0107]]], device='cuda:0')\n",
      "tensor([[[0.9551],\n",
      "         [8.1931],\n",
      "         [0.9817]]], device='cuda:0')\n",
      "tensor([[[1.0413],\n",
      "         [8.2419],\n",
      "         [1.0149]]], device='cuda:0')\n",
      "tensor([[[1.0587],\n",
      "         [8.2285],\n",
      "         [1.0847]]], device='cuda:0')\n",
      "tensor([[[1.0504],\n",
      "         [8.2846],\n",
      "         [1.0139]]], device='cuda:0')\n",
      "tensor([[[1.0357],\n",
      "         [8.2150],\n",
      "         [1.0106]]], device='cuda:0')\n",
      "tensor([[[1.0182],\n",
      "         [8.3304],\n",
      "         [1.0375]]], device='cuda:0')\n",
      "tensor([[[1.0063],\n",
      "         [8.2919],\n",
      "         [1.0380]]], device='cuda:0')\n",
      "tensor([[[1.0582],\n",
      "         [8.2874],\n",
      "         [1.0326]]], device='cuda:0')\n",
      "tensor([[[1.0191],\n",
      "         [8.3124],\n",
      "         [1.0749]]], device='cuda:0')\n",
      "tensor([[[1.0170],\n",
      "         [8.2260],\n",
      "         [1.0330]]], device='cuda:0')\n",
      "tensor([[[1.0456],\n",
      "         [8.2133],\n",
      "         [1.0206]]], device='cuda:0')\n",
      "tensor([[[1.0640],\n",
      "         [8.2426],\n",
      "         [1.0262]]], device='cuda:0')\n",
      "tensor([[[1.0612],\n",
      "         [8.2100],\n",
      "         [1.0089]]], device='cuda:0')\n",
      "tensor([[[1.0346],\n",
      "         [8.2010],\n",
      "         [1.0523]]], device='cuda:0')\n",
      "tensor([[[1.0447],\n",
      "         [8.2030],\n",
      "         [1.0152]]], device='cuda:0')\n",
      "tensor([[[0.9954],\n",
      "         [8.2406],\n",
      "         [1.0437]]], device='cuda:0')\n",
      "tensor([[[1.0050],\n",
      "         [8.2362],\n",
      "         [1.0351]]], device='cuda:0')\n",
      "tensor([[[0.9961],\n",
      "         [8.3150],\n",
      "         [1.0669]]], device='cuda:0')\n",
      "tensor([[[1.0552],\n",
      "         [8.2278],\n",
      "         [1.0247]]], device='cuda:0')\n",
      "tensor([[[1.0321],\n",
      "         [8.2712],\n",
      "         [1.0265]]], device='cuda:0')\n",
      "tensor([[[1.0184],\n",
      "         [8.2756],\n",
      "         [1.0073]]], device='cuda:0')\n",
      "tensor([[[1.0299],\n",
      "         [8.2459],\n",
      "         [1.0502]]], device='cuda:0')\n",
      "tensor([[[1.0445],\n",
      "         [8.2790],\n",
      "         [1.0350]]], device='cuda:0')\n",
      "tensor([[[1.0548],\n",
      "         [8.3245],\n",
      "         [1.0086]]], device='cuda:0')\n",
      "tensor([[[0.9793],\n",
      "         [8.2456],\n",
      "         [1.0725]]], device='cuda:0')\n",
      "tensor([[[1.0151],\n",
      "         [8.2673],\n",
      "         [1.0013]]], device='cuda:0')\n",
      "tensor([[[1.0120],\n",
      "         [8.2449],\n",
      "         [0.9854]]], device='cuda:0')\n",
      "tensor([[[1.0280],\n",
      "         [8.2616],\n",
      "         [1.0328]]], device='cuda:0')\n",
      "tensor([[[1.0171],\n",
      "         [8.2261],\n",
      "         [1.0207]]], device='cuda:0')\n",
      "tensor([[[1.0230],\n",
      "         [8.3317],\n",
      "         [1.1269]]], device='cuda:0')\n",
      "tensor([[[1.0481],\n",
      "         [8.3399],\n",
      "         [1.0327]]], device='cuda:0')\n",
      "tensor([[[1.0529],\n",
      "         [8.2605],\n",
      "         [1.0392]]], device='cuda:0')\n",
      "tensor([[[1.0637],\n",
      "         [8.2755],\n",
      "         [1.0415]]], device='cuda:0')\n",
      "tensor([[[0.9935],\n",
      "         [7.3840],\n",
      "         [0.9984]]], device='cuda:0')\n",
      "tensor([[[1.0258],\n",
      "         [8.3384],\n",
      "         [1.1216]]], device='cuda:0')\n",
      "tensor([[[1.0278],\n",
      "         [8.2233],\n",
      "         [1.0114]]], device='cuda:0')\n",
      "tensor([[[1.0524],\n",
      "         [8.1481],\n",
      "         [1.0172]]], device='cuda:0')\n",
      "tensor([[[1.0412],\n",
      "         [8.2604],\n",
      "         [1.0117]]], device='cuda:0')\n",
      "tensor([[[1.0336],\n",
      "         [8.2929],\n",
      "         [1.0315]]], device='cuda:0')\n",
      "tensor([[[1.0448],\n",
      "         [8.2938],\n",
      "         [0.9991]]], device='cuda:0')\n",
      "tensor([[[1.0485],\n",
      "         [8.2271],\n",
      "         [1.0390]]], device='cuda:0')\n",
      "tensor([[[1.0199],\n",
      "         [8.2372],\n",
      "         [1.0428]]], device='cuda:0')\n",
      "tensor([[[1.0240],\n",
      "         [8.2737],\n",
      "         [1.0197]]], device='cuda:0')\n",
      "tensor([[[1.0052],\n",
      "         [8.2099],\n",
      "         [1.0331]]], device='cuda:0')\n",
      "tensor([[[1.0440],\n",
      "         [8.2516],\n",
      "         [1.0783]]], device='cuda:0')\n",
      "tensor([[[1.0355],\n",
      "         [8.2833],\n",
      "         [1.0280]]], device='cuda:0')\n",
      "tensor([[[0.9787],\n",
      "         [8.2343],\n",
      "         [1.0607]]], device='cuda:0')\n",
      "tensor([[[0.9877],\n",
      "         [8.2884],\n",
      "         [1.0470]]], device='cuda:0')\n",
      "tensor([[[1.0254],\n",
      "         [8.2125],\n",
      "         [0.9999]]], device='cuda:0')\n",
      "tensor([[[1.0005],\n",
      "         [8.2406],\n",
      "         [1.0415]]], device='cuda:0')\n",
      "tensor([[[1.0173],\n",
      "         [8.1965],\n",
      "         [1.0526]]], device='cuda:0')\n",
      "tensor([[[1.0398],\n",
      "         [8.2568],\n",
      "         [1.0158]]], device='cuda:0')\n",
      "tensor([[[1.0423],\n",
      "         [8.2392],\n",
      "         [1.0360]]], device='cuda:0')\n",
      "tensor([[[1.0413],\n",
      "         [8.2270],\n",
      "         [1.0167]]], device='cuda:0')\n",
      "tensor([[[1.0528],\n",
      "         [8.2293],\n",
      "         [1.0216]]], device='cuda:0')\n",
      "tensor([[[1.0588],\n",
      "         [8.2248],\n",
      "         [1.0085]]], device='cuda:0')\n",
      "tensor([[[1.0165],\n",
      "         [8.2953],\n",
      "         [1.0038]]], device='cuda:0')\n",
      "tensor([[[1.0318],\n",
      "         [8.3257],\n",
      "         [1.0200]]], device='cuda:0')\n",
      "tensor([[[1.0283],\n",
      "         [8.2750],\n",
      "         [0.9913]]], device='cuda:0')\n",
      "tensor([[[1.0170],\n",
      "         [8.2037],\n",
      "         [1.0207]]], device='cuda:0')\n",
      "tensor([[[1.0221],\n",
      "         [8.2743],\n",
      "         [1.1706]]], device='cuda:0')\n",
      "tensor([[[1.0299],\n",
      "         [8.3093],\n",
      "         [1.0250]]], device='cuda:0')\n",
      "tensor([[[1.0259],\n",
      "         [8.2898],\n",
      "         [0.9705]]], device='cuda:0')\n",
      "tensor([[[1.0486],\n",
      "         [8.3160],\n",
      "         [0.9846]]], device='cuda:0')\n",
      "tensor([[[1.0193],\n",
      "         [8.1990],\n",
      "         [1.0311]]], device='cuda:0')\n",
      "tensor([[[1.0641],\n",
      "         [8.2646],\n",
      "         [0.9827]]], device='cuda:0')\n",
      "tensor([[[0.9917],\n",
      "         [8.2688],\n",
      "         [1.0059]]], device='cuda:0')\n",
      "tensor([[[0.9872],\n",
      "         [8.2576],\n",
      "         [1.0896]]], device='cuda:0')\n",
      "tensor([[[1.0314],\n",
      "         [8.2748],\n",
      "         [1.0441]]], device='cuda:0')\n",
      "tensor([[[1.0332],\n",
      "         [8.2226],\n",
      "         [1.0339]]], device='cuda:0')\n",
      "tensor([[[0.9918],\n",
      "         [8.2457],\n",
      "         [8.1667]]], device='cuda:0')\n",
      "tensor([[[1.0916],\n",
      "         [8.3021],\n",
      "         [1.0095]]], device='cuda:0')\n",
      "tensor([[[1.0560],\n",
      "         [8.2311],\n",
      "         [0.9767]]], device='cuda:0')\n",
      "tensor([[[1.0307],\n",
      "         [8.2534],\n",
      "         [1.0513]]], device='cuda:0')\n",
      "tensor([[[1.0454],\n",
      "         [8.1984],\n",
      "         [1.0150]]], device='cuda:0')\n",
      "tensor([[[1.0029],\n",
      "         [8.2184],\n",
      "         [1.0183]]], device='cuda:0')\n",
      "tensor([[[1.0169],\n",
      "         [8.2873],\n",
      "         [1.0701]]], device='cuda:0')\n",
      "tensor([[[1.0434],\n",
      "         [8.1779],\n",
      "         [0.9779]]], device='cuda:0')\n",
      "tensor([[[1.0542],\n",
      "         [8.2896],\n",
      "         [1.0237]]], device='cuda:0')\n",
      "tensor([[[1.0334],\n",
      "         [8.2903],\n",
      "         [1.0191]]], device='cuda:0')\n",
      "tensor([[[1.0579],\n",
      "         [8.3590],\n",
      "         [1.0164]]], device='cuda:0')\n",
      "tensor([[[1.0445],\n",
      "         [8.2432],\n",
      "         [0.9705]]], device='cuda:0')\n",
      "tensor([[[1.0141],\n",
      "         [8.3347],\n",
      "         [1.0718]]], device='cuda:0')\n",
      "tensor([[[1.0165],\n",
      "         [8.2957],\n",
      "         [1.0156]]], device='cuda:0')\n",
      "tensor([[[1.0206],\n",
      "         [8.2668],\n",
      "         [1.0232]]], device='cuda:0')\n",
      "tensor([[[1.0258],\n",
      "         [8.2665],\n",
      "         [1.0536]]], device='cuda:0')\n",
      "tensor([[[1.0494],\n",
      "         [8.1447],\n",
      "         [1.0766]]], device='cuda:0')\n",
      "tensor([[[1.0216],\n",
      "         [8.2044],\n",
      "         [1.0699]]], device='cuda:0')\n",
      "tensor([[[1.0316],\n",
      "         [8.2637],\n",
      "         [1.0169]]], device='cuda:0')\n",
      "tensor([[[1.0086],\n",
      "         [8.3150],\n",
      "         [1.0144]]], device='cuda:0')\n",
      "tensor([[[1.0439],\n",
      "         [8.3254],\n",
      "         [1.0418]]], device='cuda:0')\n",
      "tensor([[[1.0145],\n",
      "         [8.2804],\n",
      "         [1.0271]]], device='cuda:0')\n",
      "tensor([[[1.0305],\n",
      "         [8.2158],\n",
      "         [1.0241]]], device='cuda:0')\n",
      "tensor([[[1.0166],\n",
      "         [8.1843],\n",
      "         [1.0515]]], device='cuda:0')\n",
      "tensor([[[1.0135],\n",
      "         [8.2422],\n",
      "         [1.0313]]], device='cuda:0')\n",
      "tensor([[[1.0461],\n",
      "         [8.2639],\n",
      "         [1.0298]]], device='cuda:0')\n",
      "tensor([[[1.0292],\n",
      "         [8.2920],\n",
      "         [1.0007]]], device='cuda:0')\n",
      "tensor([[[1.0474],\n",
      "         [8.2320],\n",
      "         [1.0213]]], device='cuda:0')\n",
      "tensor([[[1.0233],\n",
      "         [8.2707],\n",
      "         [1.0216]]], device='cuda:0')\n",
      "tensor([[[1.0508],\n",
      "         [8.2332],\n",
      "         [1.0052]]], device='cuda:0')\n",
      "tensor([[[1.0475],\n",
      "         [8.2646],\n",
      "         [0.9771]]], device='cuda:0')\n",
      "tensor([[[1.0360],\n",
      "         [8.2187],\n",
      "         [1.0063]]], device='cuda:0')\n",
      "tensor([[[1.0382],\n",
      "         [8.2135],\n",
      "         [0.9971]]], device='cuda:0')\n",
      "tensor([[[1.0296],\n",
      "         [8.2864],\n",
      "         [1.0409]]], device='cuda:0')\n",
      "tensor([[[1.0266],\n",
      "         [8.2311],\n",
      "         [1.0572]]], device='cuda:0')\n",
      "tensor([[[1.0963],\n",
      "         [8.1888],\n",
      "         [0.9814]]], device='cuda:0')\n",
      "tensor([[[1.0258],\n",
      "         [8.2864],\n",
      "         [1.0466]]], device='cuda:0')\n",
      "tensor([[[1.0180],\n",
      "         [8.2582],\n",
      "         [1.0376]]], device='cuda:0')\n",
      "tensor([[[1.0535],\n",
      "         [8.2456],\n",
      "         [0.9889]]], device='cuda:0')\n",
      "tensor([[[0.9923],\n",
      "         [8.2898],\n",
      "         [1.0211]]], device='cuda:0')\n",
      "tensor([[[1.0327],\n",
      "         [8.2826],\n",
      "         [1.0372]]], device='cuda:0')\n",
      "tensor([[[1.0625],\n",
      "         [8.2687],\n",
      "         [0.9715]]], device='cuda:0')\n",
      "tensor([[[1.0367],\n",
      "         [8.3058],\n",
      "         [1.0492]]], device='cuda:0')\n",
      "tensor([[[1.0411],\n",
      "         [8.2912],\n",
      "         [1.0599]]], device='cuda:0')\n",
      "tensor([[[1.0707],\n",
      "         [8.2539],\n",
      "         [1.0257]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[0.9916],\n",
      "         [8.2286],\n",
      "         [1.0310]]], device='cuda:0')\n",
      "tensor([[[1.0439],\n",
      "         [8.3041],\n",
      "         [1.0400]]], device='cuda:0')\n",
      "tensor([[[1.0472],\n",
      "         [8.2450],\n",
      "         [1.0266]]], device='cuda:0')\n",
      "tensor([[[1.0283],\n",
      "         [8.2337],\n",
      "         [1.0596]]], device='cuda:0')\n",
      "tensor([[[1.0164],\n",
      "         [8.3113],\n",
      "         [1.0651]]], device='cuda:0')\n",
      "tensor([[[1.0012],\n",
      "         [8.1935],\n",
      "         [1.0659]]], device='cuda:0')\n",
      "tensor([[[1.0494],\n",
      "         [8.2559],\n",
      "         [1.0413]]], device='cuda:0')\n",
      "tensor([[[1.0476],\n",
      "         [8.2858],\n",
      "         [1.0019]]], device='cuda:0')\n",
      "tensor([[[1.0192],\n",
      "         [8.2505],\n",
      "         [1.0071]]], device='cuda:0')\n",
      "tensor([[[0.9783],\n",
      "         [8.3711],\n",
      "         [1.0662]]], device='cuda:0')\n",
      "tensor([[[1.0239],\n",
      "         [8.1872],\n",
      "         [1.0065]]], device='cuda:0')\n",
      "tensor([[[1.0376],\n",
      "         [8.2552],\n",
      "         [1.0044]]], device='cuda:0')\n",
      "tensor([[[1.0044],\n",
      "         [8.2596],\n",
      "         [1.0935]]], device='cuda:0')\n",
      "tensor([[[0.9968],\n",
      "         [8.2717],\n",
      "         [0.9990]]], device='cuda:0')\n",
      "tensor([[[0.9782],\n",
      "         [8.2717],\n",
      "         [1.0635]]], device='cuda:0')\n",
      "tensor([[[0.9999],\n",
      "         [8.2680],\n",
      "         [1.0740]]], device='cuda:0')\n",
      "tensor([[[1.0177],\n",
      "         [8.3148],\n",
      "         [1.0478]]], device='cuda:0')\n",
      "tensor([[[1.0518],\n",
      "         [8.2530],\n",
      "         [1.0221]]], device='cuda:0')\n",
      "tensor([[[1.0079],\n",
      "         [8.2990],\n",
      "         [1.0861]]], device='cuda:0')\n",
      "tensor([[[0.9983],\n",
      "         [8.1922],\n",
      "         [8.0097]]], device='cuda:0')\n",
      "tensor([[[1.0347],\n",
      "         [8.2400],\n",
      "         [1.0101]]], device='cuda:0')\n",
      "tensor([[[1.0523],\n",
      "         [8.3397],\n",
      "         [0.9637]]], device='cuda:0')\n",
      "tensor([[[0.9818],\n",
      "         [8.2185],\n",
      "         [1.0320]]], device='cuda:0')\n",
      "tensor([[[1.0345],\n",
      "         [8.2863],\n",
      "         [1.0151]]], device='cuda:0')\n",
      "tensor([[[1.0198],\n",
      "         [8.2631],\n",
      "         [1.0823]]], device='cuda:0')\n",
      "tensor([[[1.0332],\n",
      "         [8.2269],\n",
      "         [1.0393]]], device='cuda:0')\n",
      "tensor([[[1.0107],\n",
      "         [8.2673],\n",
      "         [1.0568]]], device='cuda:0')\n",
      "tensor([[[1.0075],\n",
      "         [8.2667],\n",
      "         [1.0573]]], device='cuda:0')\n",
      "tensor([[[1.0106],\n",
      "         [8.2639],\n",
      "         [1.0895]]], device='cuda:0')\n",
      "tensor([[[1.0612],\n",
      "         [8.3089],\n",
      "         [1.0823]]], device='cuda:0')\n",
      "tensor([[[1.0104],\n",
      "         [8.2547],\n",
      "         [0.9870]]], device='cuda:0')\n",
      "tensor([[[0.8386],\n",
      "         [8.1066],\n",
      "         [1.0265]]], device='cuda:0')\n",
      "tensor([[[1.0502],\n",
      "         [8.2175],\n",
      "         [1.0429]]], device='cuda:0')\n",
      "tensor([[[1.0386],\n",
      "         [8.2342],\n",
      "         [1.0740]]], device='cuda:0')\n",
      "tensor([[[1.0196],\n",
      "         [8.2699],\n",
      "         [1.0309]]], device='cuda:0')\n",
      "tensor([[[1.0824],\n",
      "         [8.1976],\n",
      "         [1.0782]]], device='cuda:0')\n",
      "tensor([[[1.0281],\n",
      "         [8.2296],\n",
      "         [1.0244]]], device='cuda:0')\n",
      "tensor([[[1.0419],\n",
      "         [8.2279],\n",
      "         [8.0865]]], device='cuda:0')\n",
      "tensor([[[1.0093],\n",
      "         [8.2864],\n",
      "         [1.0550]]], device='cuda:0')\n",
      "tensor([[[1.0107],\n",
      "         [8.1814],\n",
      "         [1.0588]]], device='cuda:0')\n",
      "tensor([[[0.9972],\n",
      "         [8.2094],\n",
      "         [0.9950]]], device='cuda:0')\n",
      "tensor([[[1.0512],\n",
      "         [8.2672],\n",
      "         [1.0256]]], device='cuda:0')\n",
      "tensor([[[1.0448],\n",
      "         [8.2570],\n",
      "         [1.0215]]], device='cuda:0')\n",
      "tensor([[[1.0250],\n",
      "         [8.2597],\n",
      "         [0.9816]]], device='cuda:0')\n",
      "tensor([[[1.0263],\n",
      "         [8.2774],\n",
      "         [1.0698]]], device='cuda:0')\n",
      "tensor([[[1.0455],\n",
      "         [8.1801],\n",
      "         [1.0063]]], device='cuda:0')\n",
      "tensor([[[1.0155],\n",
      "         [8.2630],\n",
      "         [1.1006]]], device='cuda:0')\n",
      "tensor([[[1.7066],\n",
      "         [6.3001],\n",
      "         [1.4364]]], device='cuda:0')\n",
      "tensor([[[1.0321],\n",
      "         [8.2805],\n",
      "         [1.0258]]], device='cuda:0')\n",
      "tensor([[[1.0071],\n",
      "         [8.2151],\n",
      "         [1.0828]]], device='cuda:0')\n",
      "tensor([[[1.0318],\n",
      "         [8.2840],\n",
      "         [0.9946]]], device='cuda:0')\n",
      "tensor([[[1.0342],\n",
      "         [8.2313],\n",
      "         [1.0614]]], device='cuda:0')\n",
      "tensor([[[1.0540],\n",
      "         [8.2231],\n",
      "         [1.0149]]], device='cuda:0')\n",
      "tensor([[[1.0613],\n",
      "         [8.3091],\n",
      "         [1.0321]]], device='cuda:0')\n",
      "tensor([[[1.0136],\n",
      "         [8.2427],\n",
      "         [8.1905]]], device='cuda:0')\n",
      "tensor([[[1.0300],\n",
      "         [8.2508],\n",
      "         [0.9787]]], device='cuda:0')\n",
      "tensor([[[1.0388],\n",
      "         [8.2414],\n",
      "         [1.0498]]], device='cuda:0')\n",
      "tensor([[[1.0486],\n",
      "         [8.2781],\n",
      "         [1.0514]]], device='cuda:0')\n",
      "tensor([[[1.0611],\n",
      "         [8.2586],\n",
      "         [1.0277]]], device='cuda:0')\n",
      "tensor([[[1.0301],\n",
      "         [8.2552],\n",
      "         [1.0595]]], device='cuda:0')\n",
      "tensor([[[1.0533],\n",
      "         [8.2556],\n",
      "         [1.0533]]], device='cuda:0')\n",
      "tensor([[[1.0171],\n",
      "         [8.2086],\n",
      "         [1.0318]]], device='cuda:0')\n",
      "tensor([[[1.0025],\n",
      "         [8.2794],\n",
      "         [1.0261]]], device='cuda:0')\n",
      "tensor([[[1.0031],\n",
      "         [8.2615],\n",
      "         [1.0358]]], device='cuda:0')\n",
      "tensor([[[1.0395],\n",
      "         [8.2460],\n",
      "         [1.0423]]], device='cuda:0')\n",
      "tensor([[[1.0363],\n",
      "         [8.2069],\n",
      "         [8.1692]]], device='cuda:0')\n",
      "tensor([[[1.0097],\n",
      "         [8.3250],\n",
      "         [1.0532]]], device='cuda:0')\n",
      "tensor([[[1.0516],\n",
      "         [8.3381],\n",
      "         [1.0830]]], device='cuda:0')\n",
      "tensor([[[1.0314],\n",
      "         [8.2901],\n",
      "         [1.0091]]], device='cuda:0')\n",
      "tensor([[[1.0095],\n",
      "         [8.3111],\n",
      "         [1.0612]]], device='cuda:0')\n",
      "tensor([[[1.0229],\n",
      "         [8.2705],\n",
      "         [1.0216]]], device='cuda:0')\n",
      "tensor([[[0.9953],\n",
      "         [8.3056],\n",
      "         [1.0525]]], device='cuda:0')\n",
      "tensor([[[1.0385],\n",
      "         [8.3294],\n",
      "         [0.9836]]], device='cuda:0')\n",
      "tensor([[[1.0829],\n",
      "         [8.3389],\n",
      "         [1.0124]]], device='cuda:0')\n",
      "tensor([[[1.0513],\n",
      "         [8.2977],\n",
      "         [1.0881]]], device='cuda:0')\n",
      "tensor([[[1.0231],\n",
      "         [8.2226],\n",
      "         [1.0352]]], device='cuda:0')\n",
      "tensor([[[1.0372],\n",
      "         [8.3096],\n",
      "         [1.0280]]], device='cuda:0')\n",
      "tensor([[[1.0148],\n",
      "         [8.2994],\n",
      "         [1.0262]]], device='cuda:0')\n",
      "tensor([[[1.0428],\n",
      "         [8.2606],\n",
      "         [1.0524]]], device='cuda:0')\n",
      "tensor([[[1.0354],\n",
      "         [8.2919],\n",
      "         [1.0197]]], device='cuda:0')\n",
      "tensor([[[1.0393],\n",
      "         [8.2846],\n",
      "         [0.9994]]], device='cuda:0')\n",
      "tensor([[[1.0531],\n",
      "         [8.1751],\n",
      "         [1.0292]]], device='cuda:0')\n",
      "tensor([[[1.0342],\n",
      "         [8.2321],\n",
      "         [0.9729]]], device='cuda:0')\n",
      "tensor([[[1.0492],\n",
      "         [8.1800],\n",
      "         [1.0104]]], device='cuda:0')\n",
      "tensor([[[1.0230],\n",
      "         [8.2029],\n",
      "         [1.0644]]], device='cuda:0')\n",
      "tensor([[[1.0414],\n",
      "         [8.2533],\n",
      "         [0.9710]]], device='cuda:0')\n",
      "tensor([[[1.0585],\n",
      "         [8.2576],\n",
      "         [0.9956]]], device='cuda:0')\n",
      "tensor([[[1.0522],\n",
      "         [8.2735],\n",
      "         [0.9764]]], device='cuda:0')\n",
      "tensor([[[1.0365],\n",
      "         [8.2345],\n",
      "         [1.0042]]], device='cuda:0')\n",
      "tensor([[[1.0174],\n",
      "         [8.2446],\n",
      "         [1.0727]]], device='cuda:0')\n",
      "tensor([[[1.0284],\n",
      "         [8.2354],\n",
      "         [1.0115]]], device='cuda:0')\n",
      "tensor([[[1.0177],\n",
      "         [8.2304],\n",
      "         [1.0354]]], device='cuda:0')\n",
      "tensor([[[1.0286],\n",
      "         [8.2438],\n",
      "         [1.0159]]], device='cuda:0')\n",
      "tensor([[[1.0412],\n",
      "         [8.3127],\n",
      "         [1.0075]]], device='cuda:0')\n",
      "tensor([[[1.0336],\n",
      "         [8.3032],\n",
      "         [1.0146]]], device='cuda:0')\n",
      "tensor([[[1.0531],\n",
      "         [8.2934],\n",
      "         [0.9972]]], device='cuda:0')\n",
      "tensor([[[1.0476],\n",
      "         [8.2555],\n",
      "         [0.9642]]], device='cuda:0')\n",
      "tensor([[[0.9879],\n",
      "         [8.2932],\n",
      "         [1.0027]]], device='cuda:0')\n",
      "tensor([[[1.0122],\n",
      "         [8.2754],\n",
      "         [1.1338]]], device='cuda:0')\n",
      "tensor([[[1.0167],\n",
      "         [8.2674],\n",
      "         [1.0500]]], device='cuda:0')\n",
      "tensor([[[1.0281],\n",
      "         [8.2336],\n",
      "         [0.9863]]], device='cuda:0')\n",
      "tensor([[[0.9925],\n",
      "         [8.2806],\n",
      "         [1.0423]]], device='cuda:0')\n",
      "tensor([[[1.0416],\n",
      "         [8.2634],\n",
      "         [0.9992]]], device='cuda:0')\n",
      "tensor([[[0.9969],\n",
      "         [7.7619],\n",
      "         [1.0501]]], device='cuda:0')\n",
      "tensor([[[1.0336],\n",
      "         [8.3145],\n",
      "         [1.0418]]], device='cuda:0')\n",
      "tensor([[[1.0291],\n",
      "         [8.2656],\n",
      "         [1.0292]]], device='cuda:0')\n",
      "tensor([[[1.0163],\n",
      "         [8.1928],\n",
      "         [1.0493]]], device='cuda:0')\n",
      "tensor([[[1.0515],\n",
      "         [8.2701],\n",
      "         [1.0365]]], device='cuda:0')\n",
      "tensor([[[1.0406],\n",
      "         [8.2534],\n",
      "         [1.0249]]], device='cuda:0')\n",
      "tensor([[[1.0296],\n",
      "         [8.2265],\n",
      "         [1.0326]]], device='cuda:0')\n",
      "tensor([[[1.0419],\n",
      "         [8.2998],\n",
      "         [1.0205]]], device='cuda:0')\n",
      "tensor([[[1.0271],\n",
      "         [8.2013],\n",
      "         [1.0389]]], device='cuda:0')\n",
      "tensor([[[1.0473],\n",
      "         [8.2711],\n",
      "         [1.0478]]], device='cuda:0')\n",
      "tensor([[[1.0034],\n",
      "         [8.2054],\n",
      "         [1.0485]]], device='cuda:0')\n",
      "tensor([[[1.0388],\n",
      "         [8.2027],\n",
      "         [1.0300]]], device='cuda:0')\n",
      "tensor([[[1.0221],\n",
      "         [8.2437],\n",
      "         [1.0125]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0124],\n",
      "         [8.2664],\n",
      "         [1.0763]]], device='cuda:0')\n",
      "tensor([[[1.0339],\n",
      "         [8.2538],\n",
      "         [1.0405]]], device='cuda:0')\n",
      "tensor([[[1.0506],\n",
      "         [8.3563],\n",
      "         [1.0240]]], device='cuda:0')\n",
      "tensor([[[1.0764],\n",
      "         [8.3076],\n",
      "         [1.0361]]], device='cuda:0')\n",
      "tensor([[[1.0259],\n",
      "         [8.2470],\n",
      "         [1.0329]]], device='cuda:0')\n",
      "tensor([[[0.9949],\n",
      "         [8.2901],\n",
      "         [1.0030]]], device='cuda:0')\n",
      "tensor([[[1.0193],\n",
      "         [8.2993],\n",
      "         [1.0143]]], device='cuda:0')\n",
      "tensor([[[0.9990],\n",
      "         [8.2065],\n",
      "         [1.1207]]], device='cuda:0')\n",
      "tensor([[[1.0435],\n",
      "         [8.1933],\n",
      "         [1.0628]]], device='cuda:0')\n",
      "tensor([[[1.0688],\n",
      "         [8.2771],\n",
      "         [1.0067]]], device='cuda:0')\n",
      "tensor([[[1.0615],\n",
      "         [8.2720],\n",
      "         [1.0568]]], device='cuda:0')\n",
      "tensor([[[1.0415],\n",
      "         [8.2736],\n",
      "         [1.0168]]], device='cuda:0')\n",
      "tensor([[[1.0771],\n",
      "         [8.3565],\n",
      "         [0.9852]]], device='cuda:0')\n",
      "tensor([[[1.0281],\n",
      "         [8.2669],\n",
      "         [1.0305]]], device='cuda:0')\n",
      "tensor([[[1.0264],\n",
      "         [8.2337],\n",
      "         [1.0860]]], device='cuda:0')\n",
      "tensor([[[0.9992],\n",
      "         [8.2468],\n",
      "         [1.0387]]], device='cuda:0')\n",
      "tensor([[[1.0237],\n",
      "         [8.2534],\n",
      "         [1.0334]]], device='cuda:0')\n",
      "tensor([[[0.9901],\n",
      "         [8.2603],\n",
      "         [0.9843]]], device='cuda:0')\n",
      "tensor([[[1.0172],\n",
      "         [8.2778],\n",
      "         [1.1105]]], device='cuda:0')\n",
      "tensor([[[1.0335],\n",
      "         [8.2962],\n",
      "         [1.0396]]], device='cuda:0')\n",
      "tensor([[[1.0104],\n",
      "         [8.2587],\n",
      "         [1.0600]]], device='cuda:0')\n",
      "tensor([[[1.0080],\n",
      "         [8.2514],\n",
      "         [1.0073]]], device='cuda:0')\n",
      "tensor([[[1.0193],\n",
      "         [8.2691],\n",
      "         [0.9860]]], device='cuda:0')\n",
      "tensor([[[1.0718],\n",
      "         [8.2009],\n",
      "         [1.0390]]], device='cuda:0')\n",
      "tensor([[[1.0600],\n",
      "         [8.2128],\n",
      "         [1.0793]]], device='cuda:0')\n",
      "tensor([[[1.0049],\n",
      "         [8.2596],\n",
      "         [1.0555]]], device='cuda:0')\n",
      "tensor([[[1.0371],\n",
      "         [8.2779],\n",
      "         [1.0467]]], device='cuda:0')\n",
      "tensor([[[0.9953],\n",
      "         [8.2416],\n",
      "         [1.0261]]], device='cuda:0')\n",
      "tensor([[[1.0406],\n",
      "         [8.2892],\n",
      "         [1.0551]]], device='cuda:0')\n",
      "tensor([[[1.0205],\n",
      "         [8.3038],\n",
      "         [1.0244]]], device='cuda:0')\n",
      "tensor([[[0.9986],\n",
      "         [8.2467],\n",
      "         [1.0238]]], device='cuda:0')\n",
      "tensor([[[1.0684],\n",
      "         [8.2887],\n",
      "         [0.9766]]], device='cuda:0')\n",
      "tensor([[[1.0407],\n",
      "         [8.2772],\n",
      "         [0.9801]]], device='cuda:0')\n",
      "tensor([[[1.0455],\n",
      "         [8.2454],\n",
      "         [1.0320]]], device='cuda:0')\n",
      "tensor([[[1.0052],\n",
      "         [8.2629],\n",
      "         [1.0968]]], device='cuda:0')\n",
      "tensor([[[1.0201],\n",
      "         [8.2429],\n",
      "         [0.9874]]], device='cuda:0')\n",
      "tensor([[[1.0467],\n",
      "         [8.2855],\n",
      "         [1.0147]]], device='cuda:0')\n",
      "tensor([[[1.0381],\n",
      "         [8.3087],\n",
      "         [1.0520]]], device='cuda:0')\n",
      "tensor([[[1.0399],\n",
      "         [8.3036],\n",
      "         [1.0514]]], device='cuda:0')\n",
      "tensor([[[1.0496],\n",
      "         [8.2239],\n",
      "         [1.0724]]], device='cuda:0')\n",
      "tensor([[[0.9859],\n",
      "         [8.1947],\n",
      "         [1.0962]]], device='cuda:0')\n",
      "tensor([[[1.0170],\n",
      "         [8.2113],\n",
      "         [0.9873]]], device='cuda:0')\n",
      "tensor([[[1.0429],\n",
      "         [8.2858],\n",
      "         [1.0918]]], device='cuda:0')\n",
      "tensor([[[1.0359],\n",
      "         [8.2447],\n",
      "         [1.0270]]], device='cuda:0')\n",
      "tensor([[[1.0130],\n",
      "         [8.2286],\n",
      "         [1.0544]]], device='cuda:0')\n",
      "tensor([[[1.0039],\n",
      "         [8.2690],\n",
      "         [5.9903]]], device='cuda:0')\n",
      "tensor([[[1.0452],\n",
      "         [8.2388],\n",
      "         [1.0431]]], device='cuda:0')\n",
      "tensor([[[0.9945],\n",
      "         [8.2250],\n",
      "         [1.0599]]], device='cuda:0')\n",
      "tensor([[[1.0506],\n",
      "         [8.2080],\n",
      "         [1.0429]]], device='cuda:0')\n",
      "tensor([[[1.0483],\n",
      "         [8.2619],\n",
      "         [1.0432]]], device='cuda:0')\n",
      "tensor([[[1.0453],\n",
      "         [8.2533],\n",
      "         [1.0195]]], device='cuda:0')\n",
      "tensor([[[1.0408],\n",
      "         [8.2954],\n",
      "         [0.9771]]], device='cuda:0')\n",
      "tensor([[[1.0349],\n",
      "         [8.3090],\n",
      "         [1.0581]]], device='cuda:0')\n",
      "tensor([[[1.0072],\n",
      "         [8.2130],\n",
      "         [1.0274]]], device='cuda:0')\n",
      "tensor([[[1.0473],\n",
      "         [8.2162],\n",
      "         [0.9808]]], device='cuda:0')\n",
      "tensor([[[1.0391],\n",
      "         [8.2989],\n",
      "         [1.0109]]], device='cuda:0')\n",
      "tensor([[[0.9982],\n",
      "         [8.3453],\n",
      "         [1.0709]]], device='cuda:0')\n",
      "tensor([[[1.0383],\n",
      "         [8.2818],\n",
      "         [1.0202]]], device='cuda:0')\n",
      "tensor([[[1.0482],\n",
      "         [8.2506],\n",
      "         [1.0063]]], device='cuda:0')\n",
      "tensor([[[1.0242],\n",
      "         [8.2871],\n",
      "         [1.0512]]], device='cuda:0')\n",
      "tensor([[[1.0310],\n",
      "         [8.2428],\n",
      "         [1.0843]]], device='cuda:0')\n",
      "tensor([[[1.5080],\n",
      "         [6.2637],\n",
      "         [1.3006]]], device='cuda:0')\n",
      "tensor([[[1.0163],\n",
      "         [8.2789],\n",
      "         [1.0525]]], device='cuda:0')\n",
      "tensor([[[1.0239],\n",
      "         [8.3148],\n",
      "         [1.0212]]], device='cuda:0')\n",
      "tensor([[[1.0366],\n",
      "         [8.2262],\n",
      "         [1.0051]]], device='cuda:0')\n",
      "tensor([[[1.0560],\n",
      "         [8.2642],\n",
      "         [0.9791]]], device='cuda:0')\n",
      "tensor([[[1.0218],\n",
      "         [8.2706],\n",
      "         [1.0196]]], device='cuda:0')\n",
      "tensor([[[1.0404],\n",
      "         [8.3609],\n",
      "         [1.0278]]], device='cuda:0')\n",
      "tensor([[[1.0219],\n",
      "         [8.2237],\n",
      "         [1.0550]]], device='cuda:0')\n",
      "tensor([[[1.0220],\n",
      "         [8.2753],\n",
      "         [1.0079]]], device='cuda:0')\n",
      "tensor([[[1.0439],\n",
      "         [8.2761],\n",
      "         [1.0022]]], device='cuda:0')\n",
      "tensor([[[1.0247],\n",
      "         [8.2879],\n",
      "         [1.0242]]], device='cuda:0')\n",
      "tensor([[[1.0557],\n",
      "         [8.1973],\n",
      "         [1.0614]]], device='cuda:0')\n",
      "tensor([[[1.0415],\n",
      "         [8.2346],\n",
      "         [1.0540]]], device='cuda:0')\n",
      "tensor([[[1.0720],\n",
      "         [8.2239],\n",
      "         [0.9939]]], device='cuda:0')\n",
      "tensor([[[1.0442],\n",
      "         [8.2288],\n",
      "         [1.0346]]], device='cuda:0')\n",
      "tensor([[[1.0387],\n",
      "         [8.2543],\n",
      "         [1.0651]]], device='cuda:0')\n",
      "tensor([[[1.0242],\n",
      "         [8.2102],\n",
      "         [1.0106]]], device='cuda:0')\n",
      "tensor([[[1.0458],\n",
      "         [8.3472],\n",
      "         [1.0803]]], device='cuda:0')\n",
      "tensor([[[1.0413],\n",
      "         [8.2738],\n",
      "         [0.9829]]], device='cuda:0')\n",
      "tensor([[[1.0073],\n",
      "         [8.3069],\n",
      "         [0.9769]]], device='cuda:0')\n",
      "tensor([[[1.0451],\n",
      "         [8.2781],\n",
      "         [1.0027]]], device='cuda:0')\n",
      "tensor([[[1.0099],\n",
      "         [8.3081],\n",
      "         [1.0624]]], device='cuda:0')\n",
      "tensor([[[1.0094],\n",
      "         [8.2398],\n",
      "         [1.0560]]], device='cuda:0')\n",
      "tensor([[[1.0360],\n",
      "         [8.2654],\n",
      "         [1.0906]]], device='cuda:0')\n",
      "tensor([[[1.0392],\n",
      "         [8.2396],\n",
      "         [1.0161]]], device='cuda:0')\n",
      "tensor([[[1.0159],\n",
      "         [8.1929],\n",
      "         [1.0190]]], device='cuda:0')\n",
      "tensor([[[1.0475],\n",
      "         [8.2582],\n",
      "         [1.0510]]], device='cuda:0')\n",
      "tensor([[[1.0459],\n",
      "         [8.2595],\n",
      "         [1.0170]]], device='cuda:0')\n",
      "tensor([[[1.0360],\n",
      "         [8.2488],\n",
      "         [1.0637]]], device='cuda:0')\n",
      "tensor([[[1.0631],\n",
      "         [8.1586],\n",
      "         [1.0238]]], device='cuda:0')\n",
      "tensor([[[1.0395],\n",
      "         [8.2006],\n",
      "         [1.0944]]], device='cuda:0')\n",
      "tensor([[[0.9956],\n",
      "         [8.3084],\n",
      "         [1.0543]]], device='cuda:0')\n",
      "tensor([[[1.0818],\n",
      "         [8.2330],\n",
      "         [1.0287]]], device='cuda:0')\n",
      "tensor([[[1.0322],\n",
      "         [8.2382],\n",
      "         [1.0548]]], device='cuda:0')\n",
      "tensor([[[1.0201],\n",
      "         [8.2919],\n",
      "         [1.0005]]], device='cuda:0')\n",
      "tensor([[[1.0273],\n",
      "         [8.2548],\n",
      "         [1.0562]]], device='cuda:0')\n",
      "tensor([[[1.0504],\n",
      "         [8.2288],\n",
      "         [1.0245]]], device='cuda:0')\n",
      "tensor([[[1.0347],\n",
      "         [8.2754],\n",
      "         [1.0406]]], device='cuda:0')\n",
      "tensor([[[1.0553],\n",
      "         [8.1781],\n",
      "         [1.0172]]], device='cuda:0')\n",
      "tensor([[[1.0257],\n",
      "         [8.2557],\n",
      "         [0.9985]]], device='cuda:0')\n",
      "tensor([[[1.0387],\n",
      "         [8.2507],\n",
      "         [1.0525]]], device='cuda:0')\n",
      "tensor([[[1.0559],\n",
      "         [8.2355],\n",
      "         [1.0069]]], device='cuda:0')\n",
      "tensor([[[1.0715],\n",
      "         [8.2414],\n",
      "         [1.0484]]], device='cuda:0')\n",
      "tensor([[[1.0316],\n",
      "         [8.2348],\n",
      "         [1.0444]]], device='cuda:0')\n",
      "tensor([[[1.3634],\n",
      "         [6.1899],\n",
      "         [1.4055]]], device='cuda:0')\n",
      "tensor([[[1.0572],\n",
      "         [8.2544],\n",
      "         [0.9640]]], device='cuda:0')\n",
      "tensor([[[1.0393],\n",
      "         [8.3439],\n",
      "         [1.0047]]], device='cuda:0')\n",
      "tensor([[[1.0305],\n",
      "         [8.2496],\n",
      "         [1.0444]]], device='cuda:0')\n",
      "tensor([[[0.9792],\n",
      "         [8.2767],\n",
      "         [1.0663]]], device='cuda:0')\n",
      "tensor([[[1.0321],\n",
      "         [8.2396],\n",
      "         [1.0431]]], device='cuda:0')\n",
      "tensor([[[1.0139],\n",
      "         [8.2138],\n",
      "         [1.0510]]], device='cuda:0')\n",
      "tensor([[[1.0080],\n",
      "         [8.2815],\n",
      "         [1.0507]]], device='cuda:0')\n",
      "tensor([[[1.0440],\n",
      "         [8.2498],\n",
      "         [1.0305]]], device='cuda:0')\n",
      "tensor([[[1.0503],\n",
      "         [8.2871],\n",
      "         [0.9957]]], device='cuda:0')\n",
      "tensor([[[1.0441],\n",
      "         [8.3283],\n",
      "         [1.0335]]], device='cuda:0')\n",
      "tensor([[[1.0441],\n",
      "         [8.2359],\n",
      "         [1.0389]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0320],\n",
      "         [8.2512],\n",
      "         [0.9970]]], device='cuda:0')\n",
      "tensor([[[1.0284],\n",
      "         [8.1472],\n",
      "         [1.0603]]], device='cuda:0')\n",
      "tensor([[[1.0272],\n",
      "         [8.2607],\n",
      "         [1.0651]]], device='cuda:0')\n",
      "tensor([[[1.0262],\n",
      "         [8.2117],\n",
      "         [1.0288]]], device='cuda:0')\n",
      "tensor([[[1.0130],\n",
      "         [8.2058],\n",
      "         [1.0152]]], device='cuda:0')\n",
      "tensor([[[1.0248],\n",
      "         [8.2466],\n",
      "         [1.0330]]], device='cuda:0')\n",
      "tensor([[[1.0086],\n",
      "         [8.2926],\n",
      "         [1.0305]]], device='cuda:0')\n",
      "tensor([[[1.0196],\n",
      "         [8.2355],\n",
      "         [1.0314]]], device='cuda:0')\n",
      "tensor([[[1.0037],\n",
      "         [8.2795],\n",
      "         [1.0501]]], device='cuda:0')\n",
      "tensor([[[1.0264],\n",
      "         [8.2700],\n",
      "         [1.0565]]], device='cuda:0')\n",
      "tensor([[[1.0548],\n",
      "         [8.3513],\n",
      "         [0.9890]]], device='cuda:0')\n",
      "tensor([[[0.9620],\n",
      "         [7.6385],\n",
      "         [1.0341]]], device='cuda:0')\n",
      "tensor([[[1.0244],\n",
      "         [8.3193],\n",
      "         [1.0690]]], device='cuda:0')\n",
      "tensor([[[1.0311],\n",
      "         [8.2682],\n",
      "         [1.0434]]], device='cuda:0')\n",
      "tensor([[[0.9826],\n",
      "         [8.2523],\n",
      "         [1.0352]]], device='cuda:0')\n",
      "tensor([[[1.0580],\n",
      "         [8.2578],\n",
      "         [1.0156]]], device='cuda:0')\n",
      "tensor([[[1.0601],\n",
      "         [8.2238],\n",
      "         [1.0644]]], device='cuda:0')\n",
      "tensor([[[0.8969],\n",
      "         [8.2264],\n",
      "         [1.0619]]], device='cuda:0')\n",
      "tensor([[[1.0265],\n",
      "         [8.2790],\n",
      "         [1.0132]]], device='cuda:0')\n",
      "tensor([[[ 1.0442],\n",
      "         [ 9.2225],\n",
      "         [-0.0341]]], device='cuda:0')\n",
      "tensor([[[ 1.0307],\n",
      "         [ 9.2486],\n",
      "         [-0.0543]]], device='cuda:0')\n",
      "tensor([[[1.0593],\n",
      "         [9.2088],\n",
      "         [0.1055]]], device='cuda:0')\n",
      "tensor([[[ 1.0213],\n",
      "         [ 1.0294],\n",
      "         [-0.0368]]], device='cuda:0')\n",
      "tensor([[[1.0464e+00],\n",
      "         [9.2223e+00],\n",
      "         [3.4560e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0502],\n",
      "         [ 9.2441],\n",
      "         [-0.0281]]], device='cuda:0')\n",
      "tensor([[[ 1.0350],\n",
      "         [ 9.2387],\n",
      "         [-0.0437]]], device='cuda:0')\n",
      "tensor([[[ 1.0358],\n",
      "         [ 9.2466],\n",
      "         [-0.0122]]], device='cuda:0')\n",
      "tensor([[[1.0743],\n",
      "         [9.2062],\n",
      "         [0.0478]]], device='cuda:0')\n",
      "tensor([[[ 1.0552e+00],\n",
      "         [ 9.1833e+00],\n",
      "         [-6.3739e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0556],\n",
      "         [ 9.2253],\n",
      "         [-0.0603]]], device='cuda:0')\n",
      "tensor([[[1.0649],\n",
      "         [9.2151],\n",
      "         [0.0358]]], device='cuda:0')\n",
      "tensor([[[1.0652],\n",
      "         [9.2427],\n",
      "         [0.0411]]], device='cuda:0')\n",
      "tensor([[[ 1.0446],\n",
      "         [ 9.2392],\n",
      "         [-0.0344]]], device='cuda:0')\n",
      "tensor([[[ 1.0684],\n",
      "         [ 9.2220],\n",
      "         [-0.0122]]], device='cuda:0')\n",
      "tensor([[[ 1.0561e+00],\n",
      "         [ 9.2050e+00],\n",
      "         [-8.6408e-03]]], device='cuda:0')\n",
      "tensor([[[1.0709e+00],\n",
      "         [9.1987e+00],\n",
      "         [4.4316e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0476],\n",
      "         [ 9.2237],\n",
      "         [-0.0475]]], device='cuda:0')\n",
      "tensor([[[ 1.0380],\n",
      "         [ 9.2315],\n",
      "         [-0.0322]]], device='cuda:0')\n",
      "tensor([[[1.1057],\n",
      "         [9.1996],\n",
      "         [0.1813]]], device='cuda:0')\n",
      "tensor([[[ 1.0211],\n",
      "         [ 9.2384],\n",
      "         [-0.0294]]], device='cuda:0')\n",
      "tensor([[[ 1.0538e+00],\n",
      "         [ 9.2525e+00],\n",
      "         [-3.0819e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0294],\n",
      "         [ 9.2307],\n",
      "         [-0.0398]]], device='cuda:0')\n",
      "tensor([[[ 1.0636],\n",
      "         [ 9.2413],\n",
      "         [-0.0259]]], device='cuda:0')\n",
      "tensor([[[1.0737],\n",
      "         [9.2070],\n",
      "         [0.0518]]], device='cuda:0')\n",
      "tensor([[[ 1.0460],\n",
      "         [ 9.2433],\n",
      "         [-0.0129]]], device='cuda:0')\n",
      "tensor([[[1.0636e+00],\n",
      "         [9.2095e+00],\n",
      "         [5.2134e-04]]], device='cuda:0')\n",
      "tensor([[[ 1.0635e+00],\n",
      "         [ 9.2199e+00],\n",
      "         [-8.5978e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0543],\n",
      "         [ 1.0183],\n",
      "         [-0.0378]]], device='cuda:0')\n",
      "tensor([[[1.1151],\n",
      "         [9.1839],\n",
      "         [0.1375]]], device='cuda:0')\n",
      "tensor([[[ 1.0342],\n",
      "         [ 9.2528],\n",
      "         [-0.0222]]], device='cuda:0')\n",
      "tensor([[[ 1.0465],\n",
      "         [ 9.2291],\n",
      "         [-0.0129]]], device='cuda:0')\n",
      "tensor([[[ 1.0486],\n",
      "         [ 9.2119],\n",
      "         [-0.0476]]], device='cuda:0')\n",
      "tensor([[[1.0525e+00],\n",
      "         [9.1883e+00],\n",
      "         [2.8851e-04]]], device='cuda:0')\n",
      "tensor([[[ 1.0935],\n",
      "         [ 9.2532],\n",
      "         [-0.0475]]], device='cuda:0')\n",
      "tensor([[[1.0473],\n",
      "         [9.2093],\n",
      "         [0.0651]]], device='cuda:0')\n",
      "tensor([[[ 1.0731e+00],\n",
      "         [ 9.2117e+00],\n",
      "         [-8.5837e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0619],\n",
      "         [ 9.2290],\n",
      "         [-0.0128]]], device='cuda:0')\n",
      "tensor([[[ 1.0282],\n",
      "         [ 9.2274],\n",
      "         [-0.0105]]], device='cuda:0')\n",
      "tensor([[[1.0544],\n",
      "         [9.1969],\n",
      "         [0.0857]]], device='cuda:0')\n",
      "tensor([[[ 1.0497],\n",
      "         [ 9.2341],\n",
      "         [-0.0144]]], device='cuda:0')\n",
      "tensor([[[ 1.0573],\n",
      "         [ 9.2113],\n",
      "         [-0.0220]]], device='cuda:0')\n",
      "tensor([[[ 1.0406],\n",
      "         [ 9.2212],\n",
      "         [-0.0095]]], device='cuda:0')\n",
      "tensor([[[1.0456],\n",
      "         [9.2235],\n",
      "         [0.0603]]], device='cuda:0')\n",
      "tensor([[[ 1.0599],\n",
      "         [ 9.2415],\n",
      "         [-0.0191]]], device='cuda:0')\n",
      "tensor([[[ 1.0576],\n",
      "         [ 9.2195],\n",
      "         [-0.0618]]], device='cuda:0')\n",
      "tensor([[[ 1.0287],\n",
      "         [ 9.2383],\n",
      "         [-0.0098]]], device='cuda:0')\n",
      "tensor([[[ 1.0605e+00],\n",
      "         [ 9.2194e+00],\n",
      "         [-8.4799e-03]]], device='cuda:0')\n",
      "tensor([[[1.0869],\n",
      "         [9.2034],\n",
      "         [0.0306]]], device='cuda:0')\n",
      "tensor([[[ 1.0475],\n",
      "         [ 9.2180],\n",
      "         [-0.0342]]], device='cuda:0')\n",
      "tensor([[[ 1.0538],\n",
      "         [ 9.2409],\n",
      "         [-0.0257]]], device='cuda:0')\n",
      "tensor([[[ 1.0663e+00],\n",
      "         [ 9.2412e+00],\n",
      "         [-2.5578e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0679e+00],\n",
      "         [ 9.2340e+00],\n",
      "         [-1.1009e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0479],\n",
      "         [ 9.2272],\n",
      "         [-0.0230]]], device='cuda:0')\n",
      "tensor([[[ 1.0557],\n",
      "         [ 9.2171],\n",
      "         [-0.0260]]], device='cuda:0')\n",
      "tensor([[[ 1.0492],\n",
      "         [ 9.2380],\n",
      "         [-0.0094]]], device='cuda:0')\n",
      "tensor([[[ 1.0433],\n",
      "         [ 9.2315],\n",
      "         [-0.0337]]], device='cuda:0')\n",
      "tensor([[[1.0867],\n",
      "         [9.2206],\n",
      "         [0.0306]]], device='cuda:0')\n",
      "tensor([[[1.0531e+00],\n",
      "         [9.2301e+00],\n",
      "         [1.1788e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0554e+00],\n",
      "         [ 9.2412e+00],\n",
      "         [-5.4898e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0309],\n",
      "         [ 9.2110],\n",
      "         [-0.0333]]], device='cuda:0')\n",
      "tensor([[[ 1.0559],\n",
      "         [ 9.2348],\n",
      "         [-0.0220]]], device='cuda:0')\n",
      "tensor([[[ 1.0473],\n",
      "         [ 9.2588],\n",
      "         [-0.0141]]], device='cuda:0')\n",
      "tensor([[[1.0451e+00],\n",
      "         [9.2453e+00],\n",
      "         [5.2881e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0521],\n",
      "         [ 9.2032],\n",
      "         [-0.0165]]], device='cuda:0')\n",
      "tensor([[[ 0.9974],\n",
      "         [ 9.2660],\n",
      "         [-0.0122]]], device='cuda:0')\n",
      "tensor([[[ 1.0442],\n",
      "         [ 9.2534],\n",
      "         [-0.0335]]], device='cuda:0')\n",
      "tensor([[[ 1.0580],\n",
      "         [ 9.2341],\n",
      "         [-0.0627]]], device='cuda:0')\n",
      "tensor([[[ 1.0745],\n",
      "         [ 9.2214],\n",
      "         [-0.0099]]], device='cuda:0')\n",
      "tensor([[[1.0510],\n",
      "         [9.2115],\n",
      "         [0.0917]]], device='cuda:0')\n",
      "tensor([[[ 1.0657e+00],\n",
      "         [ 9.2237e+00],\n",
      "         [-3.9490e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0524],\n",
      "         [ 9.2416],\n",
      "         [-0.0209]]], device='cuda:0')\n",
      "tensor([[[1.0484],\n",
      "         [9.2077],\n",
      "         [0.0745]]], device='cuda:0')\n",
      "tensor([[[ 1.0611],\n",
      "         [ 9.2419],\n",
      "         [-0.0193]]], device='cuda:0')\n",
      "tensor([[[ 1.0572e+00],\n",
      "         [ 9.2139e+00],\n",
      "         [-5.6435e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0516e+00],\n",
      "         [ 9.2270e+00],\n",
      "         [-7.4834e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0464],\n",
      "         [ 9.2524],\n",
      "         [-0.0124]]], device='cuda:0')\n",
      "tensor([[[ 1.0071],\n",
      "         [ 9.1948],\n",
      "         [-0.0252]]], device='cuda:0')\n",
      "tensor([[[ 1.0509],\n",
      "         [ 9.2658],\n",
      "         [-0.0294]]], device='cuda:0')\n",
      "tensor([[[ 1.0454],\n",
      "         [ 9.2382],\n",
      "         [-0.0342]]], device='cuda:0')\n",
      "tensor([[[ 1.0302],\n",
      "         [ 9.2402],\n",
      "         [-0.0104]]], device='cuda:0')\n",
      "tensor([[[1.0833e+00],\n",
      "         [9.2288e+00],\n",
      "         [6.2019e-03]]], device='cuda:0')\n",
      "tensor([[[1.0637],\n",
      "         [9.2173],\n",
      "         [0.1055]]], device='cuda:0')\n",
      "tensor([[[1.0450e+00],\n",
      "         [9.2354e+00],\n",
      "         [5.1379e-03]]], device='cuda:0')\n",
      "tensor([[[1.0480],\n",
      "         [9.2150],\n",
      "         [0.0105]]], device='cuda:0')\n",
      "tensor([[[ 0.9977],\n",
      "         [ 9.2472],\n",
      "         [-0.0144]]], device='cuda:0')\n",
      "tensor([[[ 1.0228],\n",
      "         [ 9.2032],\n",
      "         [-0.0349]]], device='cuda:0')\n",
      "tensor([[[ 1.0676e+00],\n",
      "         [ 9.2343e+00],\n",
      "         [-6.5770e-03]]], device='cuda:0')\n",
      "tensor([[[1.0472],\n",
      "         [9.2147],\n",
      "         [0.0104]]], device='cuda:0')\n",
      "tensor([[[ 1.0561],\n",
      "         [ 9.2277],\n",
      "         [-0.0310]]], device='cuda:0')\n",
      "tensor([[[ 1.0571],\n",
      "         [ 9.2497],\n",
      "         [-0.0461]]], device='cuda:0')\n",
      "tensor([[[ 1.0501e+00],\n",
      "         [ 9.2474e+00],\n",
      "         [-3.7118e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0612],\n",
      "         [ 9.2204],\n",
      "         [-0.0124]]], device='cuda:0')\n",
      "tensor([[[ 1.0458],\n",
      "         [ 9.2466],\n",
      "         [-0.0475]]], device='cuda:0')\n",
      "tensor([[[ 1.0305],\n",
      "         [ 9.2287],\n",
      "         [-0.0394]]], device='cuda:0')\n",
      "tensor([[[ 1.0611],\n",
      "         [ 9.2172],\n",
      "         [-0.0294]]], device='cuda:0')\n",
      "tensor([[[ 1.0587e+00],\n",
      "         [ 9.2275e+00],\n",
      "         [-8.3306e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0464],\n",
      "         [ 9.2400],\n",
      "         [-0.0157]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[1.0468],\n",
      "         [9.2436],\n",
      "         [0.0106]]], device='cuda:0')\n",
      "tensor([[[ 1.0651],\n",
      "         [ 9.2458],\n",
      "         [-0.0342]]], device='cuda:0')\n",
      "tensor([[[ 1.0286],\n",
      "         [ 9.2292],\n",
      "         [-0.0244]]], device='cuda:0')\n",
      "tensor([[[1.1079],\n",
      "         [9.1882],\n",
      "         [0.1848]]], device='cuda:0')\n",
      "tensor([[[1.0438],\n",
      "         [9.2093],\n",
      "         [0.0495]]], device='cuda:0')\n",
      "tensor([[[ 1.0582e+00],\n",
      "         [ 9.2350e+00],\n",
      "         [-8.4888e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0546e+00],\n",
      "         [ 9.2253e+00],\n",
      "         [-5.0637e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0179],\n",
      "         [ 9.2441],\n",
      "         [-0.0285]]], device='cuda:0')\n",
      "tensor([[[ 1.0537],\n",
      "         [ 9.2292],\n",
      "         [-0.0366]]], device='cuda:0')\n",
      "tensor([[[ 1.0438],\n",
      "         [ 9.2493],\n",
      "         [-0.0338]]], device='cuda:0')\n",
      "tensor([[[1.0535],\n",
      "         [9.2347],\n",
      "         [0.0961]]], device='cuda:0')\n",
      "tensor([[[ 1.0228],\n",
      "         [ 9.2574],\n",
      "         [-0.0130]]], device='cuda:0')\n",
      "tensor([[[ 0.9973],\n",
      "         [ 9.2307],\n",
      "         [-0.0120]]], device='cuda:0')\n",
      "tensor([[[ 1.0197],\n",
      "         [ 9.2344],\n",
      "         [-0.0535]]], device='cuda:0')\n",
      "tensor([[[ 1.0501],\n",
      "         [ 9.2283],\n",
      "         [-0.0189]]], device='cuda:0')\n",
      "tensor([[[ 1.0430],\n",
      "         [ 9.2184],\n",
      "         [-0.0300]]], device='cuda:0')\n",
      "tensor([[[ 1.0627e+00],\n",
      "         [ 9.2317e+00],\n",
      "         [-7.7469e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0558e+00],\n",
      "         [ 9.2108e+00],\n",
      "         [-3.8605e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0235],\n",
      "         [ 9.2151],\n",
      "         [-0.0754]]], device='cuda:0')\n",
      "tensor([[[ 1.0866],\n",
      "         [ 9.2329],\n",
      "         [-0.0507]]], device='cuda:0')\n",
      "tensor([[[ 1.0616],\n",
      "         [ 9.2193],\n",
      "         [-0.0129]]], device='cuda:0')\n",
      "tensor([[[1.0454],\n",
      "         [9.1952],\n",
      "         [0.0568]]], device='cuda:0')\n",
      "tensor([[[ 1.0958],\n",
      "         [ 9.2344],\n",
      "         [-0.0484]]], device='cuda:0')\n",
      "tensor([[[1.0579],\n",
      "         [9.1980],\n",
      "         [0.0209]]], device='cuda:0')\n",
      "tensor([[[1.0813e+00],\n",
      "         [9.2284e+00],\n",
      "         [6.5966e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0533],\n",
      "         [ 9.2012],\n",
      "         [-0.0296]]], device='cuda:0')\n",
      "tensor([[[ 1.0709],\n",
      "         [ 9.2083],\n",
      "         [-0.0876]]], device='cuda:0')\n",
      "tensor([[[ 1.0538],\n",
      "         [ 1.0122],\n",
      "         [-0.0354]]], device='cuda:0')\n",
      "tensor([[[ 1.0693],\n",
      "         [ 9.2626],\n",
      "         [-0.0103]]], device='cuda:0')\n",
      "tensor([[[1.0880],\n",
      "         [9.2375],\n",
      "         [0.0313]]], device='cuda:0')\n",
      "tensor([[[1.1063],\n",
      "         [9.2021],\n",
      "         [0.1788]]], device='cuda:0')\n",
      "tensor([[[ 1.0435],\n",
      "         [ 9.2045],\n",
      "         [-0.0098]]], device='cuda:0')\n",
      "tensor([[[ 1.0516],\n",
      "         [ 9.2432],\n",
      "         [-0.0138]]], device='cuda:0')\n",
      "tensor([[[ 1.0547],\n",
      "         [ 9.1976],\n",
      "         [-0.0155]]], device='cuda:0')\n",
      "tensor([[[ 1.0599e+00],\n",
      "         [ 9.2244e+00],\n",
      "         [-8.3638e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0509],\n",
      "         [ 9.2185],\n",
      "         [-0.0227]]], device='cuda:0')\n",
      "tensor([[[ 1.0556],\n",
      "         [ 9.2220],\n",
      "         [-0.0201]]], device='cuda:0')\n",
      "tensor([[[ 1.0345],\n",
      "         [ 9.2205],\n",
      "         [-0.0301]]], device='cuda:0')\n",
      "tensor([[[ 1.0468],\n",
      "         [ 9.2285],\n",
      "         [-0.0472]]], device='cuda:0')\n",
      "tensor([[[ 1.0517],\n",
      "         [ 9.2252],\n",
      "         [-0.0267]]], device='cuda:0')\n",
      "tensor([[[1.0515e+00],\n",
      "         [9.2369e+00],\n",
      "         [1.6299e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0500],\n",
      "         [ 9.2189],\n",
      "         [-0.0122]]], device='cuda:0')\n",
      "tensor([[[ 0.9999],\n",
      "         [ 9.1948],\n",
      "         [-0.0092]]], device='cuda:0')\n",
      "tensor([[[ 1.0214],\n",
      "         [ 9.2085],\n",
      "         [-0.0250]]], device='cuda:0')\n",
      "tensor([[[1.0674],\n",
      "         [9.2494],\n",
      "         [0.0174]]], device='cuda:0')\n",
      "tensor([[[1.1103],\n",
      "         [9.2165],\n",
      "         [0.1689]]], device='cuda:0')\n",
      "tensor([[[ 1.0454],\n",
      "         [ 9.2495],\n",
      "         [-0.0106]]], device='cuda:0')\n",
      "tensor([[[1.1086],\n",
      "         [1.0462],\n",
      "         [0.0032]]], device='cuda:0')\n",
      "tensor([[[ 1.0546],\n",
      "         [ 9.2486],\n",
      "         [-0.0259]]], device='cuda:0')\n",
      "tensor([[[ 1.0499],\n",
      "         [ 9.2286],\n",
      "         [-0.0414]]], device='cuda:0')\n",
      "tensor([[[1.0477],\n",
      "         [9.2292],\n",
      "         [0.0115]]], device='cuda:0')\n",
      "tensor([[[1.0530e+00],\n",
      "         [9.2168e+00],\n",
      "         [1.2377e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0740e+00],\n",
      "         [ 9.2339e+00],\n",
      "         [-7.4199e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0631],\n",
      "         [ 9.2139],\n",
      "         [-0.0122]]], device='cuda:0')\n",
      "tensor([[[ 1.0556],\n",
      "         [ 9.2480],\n",
      "         [-0.0140]]], device='cuda:0')\n",
      "tensor([[[ 1.0505],\n",
      "         [ 9.2543],\n",
      "         [-0.0294]]], device='cuda:0')\n",
      "tensor([[[1.0645],\n",
      "         [9.2092],\n",
      "         [0.0447]]], device='cuda:0')\n",
      "tensor([[[ 1.0591],\n",
      "         [ 9.2200],\n",
      "         [-0.0196]]], device='cuda:0')\n",
      "tensor([[[ 1.0569],\n",
      "         [ 9.2363],\n",
      "         [-0.0228]]], device='cuda:0')\n",
      "tensor([[[ 1.0685e+00],\n",
      "         [ 9.2310e+00],\n",
      "         [-6.8056e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0585e+00],\n",
      "         [ 9.2201e+00],\n",
      "         [-4.1601e-03]]], device='cuda:0')\n",
      "tensor([[[0.9873],\n",
      "         [9.2457],\n",
      "         [0.0776]]], device='cuda:0')\n",
      "tensor([[[ 1.0293],\n",
      "         [ 9.2389],\n",
      "         [-0.0102]]], device='cuda:0')\n",
      "tensor([[[1.0462],\n",
      "         [9.2568],\n",
      "         [0.0123]]], device='cuda:0')\n",
      "tensor([[[ 1.0545],\n",
      "         [ 9.2414],\n",
      "         [-0.0169]]], device='cuda:0')\n",
      "tensor([[[1.1127],\n",
      "         [9.1961],\n",
      "         [0.1515]]], device='cuda:0')\n",
      "tensor([[[ 1.0522],\n",
      "         [ 9.2337],\n",
      "         [-0.0155]]], device='cuda:0')\n",
      "tensor([[[ 1.0355],\n",
      "         [ 9.2380],\n",
      "         [-0.0549]]], device='cuda:0')\n",
      "tensor([[[1.0462],\n",
      "         [9.2250],\n",
      "         [0.0121]]], device='cuda:0')\n",
      "tensor([[[1.0223],\n",
      "         [1.1093],\n",
      "         [0.0594]]], device='cuda:0')\n",
      "tensor([[[ 1.0748],\n",
      "         [ 9.2362],\n",
      "         [-0.0103]]], device='cuda:0')\n",
      "tensor([[[ 1.0338],\n",
      "         [ 9.2313],\n",
      "         [-0.0300]]], device='cuda:0')\n",
      "tensor([[[ 1.0286],\n",
      "         [ 9.2382],\n",
      "         [-0.0539]]], device='cuda:0')\n",
      "tensor([[[ 1.0515],\n",
      "         [ 9.2406],\n",
      "         [-0.0155]]], device='cuda:0')\n",
      "tensor([[[ 1.0563],\n",
      "         [ 9.2326],\n",
      "         [-0.0272]]], device='cuda:0')\n",
      "tensor([[[ 1.0300],\n",
      "         [ 9.2408],\n",
      "         [-0.0103]]], device='cuda:0')\n",
      "tensor([[[ 1.0409],\n",
      "         [ 9.2063],\n",
      "         [-0.0098]]], device='cuda:0')\n",
      "tensor([[[ 1.0336],\n",
      "         [ 9.2274],\n",
      "         [-0.0134]]], device='cuda:0')\n",
      "tensor([[[ 1.0328],\n",
      "         [ 9.2269],\n",
      "         [-0.0300]]], device='cuda:0')\n",
      "tensor([[[ 1.0686],\n",
      "         [ 1.0129],\n",
      "         [-0.0280]]], device='cuda:0')\n",
      "tensor([[[ 1.0665e+00],\n",
      "         [ 9.2277e+00],\n",
      "         [-4.9687e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0549],\n",
      "         [ 9.2186],\n",
      "         [-0.0199]]], device='cuda:0')\n",
      "tensor([[[ 1.0516],\n",
      "         [ 9.2432],\n",
      "         [-0.0138]]], device='cuda:0')\n",
      "tensor([[[ 1.0368],\n",
      "         [ 9.2443],\n",
      "         [-0.0109]]], device='cuda:0')\n",
      "tensor([[[ 1.0187],\n",
      "         [ 9.2190],\n",
      "         [-0.0234]]], device='cuda:0')\n",
      "tensor([[[ 1.0363],\n",
      "         [ 9.2400],\n",
      "         [-0.0111]]], device='cuda:0')\n",
      "tensor([[[ 1.0545],\n",
      "         [ 9.2207],\n",
      "         [-0.0140]]], device='cuda:0')\n",
      "tensor([[[ 1.0459],\n",
      "         [ 9.2414],\n",
      "         [-0.0131]]], device='cuda:0')\n",
      "tensor([[[1.0647],\n",
      "         [9.2377],\n",
      "         [0.0308]]], device='cuda:0')\n",
      "tensor([[[ 1.0554],\n",
      "         [ 9.2479],\n",
      "         [-0.0256]]], device='cuda:0')\n",
      "tensor([[[ 1.0247],\n",
      "         [ 9.2391],\n",
      "         [-0.0136]]], device='cuda:0')\n",
      "tensor([[[ 1.0239],\n",
      "         [ 9.2559],\n",
      "         [-0.0523]]], device='cuda:0')\n",
      "tensor([[[ 1.0495],\n",
      "         [ 9.2481],\n",
      "         [-0.0121]]], device='cuda:0')\n",
      "tensor([[[ 1.0550],\n",
      "         [ 9.2391],\n",
      "         [-0.0190]]], device='cuda:0')\n",
      "tensor([[[ 1.0353],\n",
      "         [ 9.2240],\n",
      "         [-0.0145]]], device='cuda:0')\n",
      "tensor([[[ 1.0470],\n",
      "         [ 9.2511],\n",
      "         [-0.0282]]], device='cuda:0')\n",
      "tensor([[[ 1.0693],\n",
      "         [ 9.2245],\n",
      "         [-0.0411]]], device='cuda:0')\n",
      "tensor([[[ 1.0436],\n",
      "         [ 9.2298],\n",
      "         [-0.0288]]], device='cuda:0')\n",
      "tensor([[[ 1.0199],\n",
      "         [ 9.1983],\n",
      "         [-0.0202]]], device='cuda:0')\n",
      "tensor([[[ 1.0531e+00],\n",
      "         [ 9.2247e+00],\n",
      "         [-1.4200e-04]]], device='cuda:0')\n",
      "tensor([[[1.1437],\n",
      "         [1.0933],\n",
      "         [0.0395]]], device='cuda:0')\n",
      "tensor([[[1.0457],\n",
      "         [9.1918],\n",
      "         [0.0541]]], device='cuda:0')\n",
      "tensor([[[ 1.0605],\n",
      "         [ 9.2668],\n",
      "         [-0.0198]]], device='cuda:0')\n",
      "tensor([[[ 1.0543],\n",
      "         [ 9.2402],\n",
      "         [-0.0370]]], device='cuda:0')\n",
      "tensor([[[ 1.0411e+00],\n",
      "         [ 9.2206e+00],\n",
      "         [-8.5029e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0322],\n",
      "         [ 9.2439],\n",
      "         [-0.0301]]], device='cuda:0')\n",
      "tensor([[[ 1.0369],\n",
      "         [ 9.2534],\n",
      "         [-0.0109]]], device='cuda:0')\n",
      "tensor([[[1.0747e+00],\n",
      "         [9.2174e+00],\n",
      "         [4.8214e-04]]], device='cuda:0')\n",
      "tensor([[[ 1.0243],\n",
      "         [ 9.2282],\n",
      "         [-0.0324]]], device='cuda:0')\n",
      "tensor([[[ 1.0434],\n",
      "         [ 9.2443],\n",
      "         [-0.0101]]], device='cuda:0')\n",
      "tensor([[[ 1.0517],\n",
      "         [ 9.2376],\n",
      "         [-0.0163]]], device='cuda:0')\n",
      "tensor([[[ 1.0434],\n",
      "         [ 9.2183],\n",
      "         [-0.0231]]], device='cuda:0')\n",
      "tensor([[[ 1.0476],\n",
      "         [ 9.2447],\n",
      "         [-0.0160]]], device='cuda:0')\n",
      "tensor([[[ 1.0521],\n",
      "         [ 9.2259],\n",
      "         [-0.0160]]], device='cuda:0')\n",
      "tensor([[[ 1.0898],\n",
      "         [ 9.2120],\n",
      "         [-0.0517]]], device='cuda:0')\n",
      "tensor([[[1.0820e+00],\n",
      "         [9.2236e+00],\n",
      "         [7.0664e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0502e+00],\n",
      "         [ 9.2055e+00],\n",
      "         [-8.2815e-04]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0454],\n",
      "         [ 9.2348],\n",
      "         [-0.0128]]], device='cuda:0')\n",
      "tensor([[[ 1.0228],\n",
      "         [ 9.2193],\n",
      "         [-0.0131]]], device='cuda:0')\n",
      "tensor([[[ 1.0441e+00],\n",
      "         [ 9.2537e+00],\n",
      "         [-5.6170e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0969],\n",
      "         [ 9.2091],\n",
      "         [-0.0482]]], device='cuda:0')\n",
      "tensor([[[ 1.0293],\n",
      "         [ 9.2500],\n",
      "         [-0.0103]]], device='cuda:0')\n",
      "tensor([[[ 1.0191],\n",
      "         [ 9.2078],\n",
      "         [-0.0287]]], device='cuda:0')\n",
      "tensor([[[1.0469],\n",
      "         [9.2191],\n",
      "         [0.0154]]], device='cuda:0')\n",
      "tensor([[[ 1.0605],\n",
      "         [ 9.2245],\n",
      "         [-0.0120]]], device='cuda:0')\n",
      "tensor([[[ 1.0512],\n",
      "         [ 9.2452],\n",
      "         [-0.0298]]], device='cuda:0')\n",
      "tensor([[[ 1.0376],\n",
      "         [ 9.2700],\n",
      "         [-0.0113]]], device='cuda:0')\n",
      "tensor([[[1.0891],\n",
      "         [9.2125],\n",
      "         [0.0302]]], device='cuda:0')\n",
      "tensor([[[ 1.0310],\n",
      "         [ 9.2179],\n",
      "         [-0.0240]]], device='cuda:0')\n",
      "tensor([[[1.0459e+00],\n",
      "         [9.2256e+00],\n",
      "         [2.5262e-03]]], device='cuda:0')\n",
      "tensor([[[1.0582],\n",
      "         [9.2125],\n",
      "         [0.0480]]], device='cuda:0')\n",
      "tensor([[[1.1059],\n",
      "         [9.2031],\n",
      "         [0.1676]]], device='cuda:0')\n",
      "tensor([[[ 1.0342],\n",
      "         [ 9.2408],\n",
      "         [-0.0551]]], device='cuda:0')\n",
      "tensor([[[1.0653e+00],\n",
      "         [9.2351e+00],\n",
      "         [2.7428e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0231],\n",
      "         [ 9.2288],\n",
      "         [-0.0259]]], device='cuda:0')\n",
      "tensor([[[ 9.8660e-01],\n",
      "         [ 9.2279e+00],\n",
      "         [-4.1534e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0552],\n",
      "         [ 9.2494],\n",
      "         [-0.0136]]], device='cuda:0')\n",
      "tensor([[[ 1.0308],\n",
      "         [ 9.2532],\n",
      "         [-0.0107]]], device='cuda:0')\n",
      "tensor([[[ 0.9830],\n",
      "         [ 9.2218],\n",
      "         [-0.0409]]], device='cuda:0')\n",
      "tensor([[[1.0468],\n",
      "         [9.2019],\n",
      "         [0.0169]]], device='cuda:0')\n",
      "tensor([[[ 1.0533],\n",
      "         [ 9.2202],\n",
      "         [-0.0422]]], device='cuda:0')\n",
      "tensor([[[ 1.0636],\n",
      "         [ 9.2413],\n",
      "         [-0.0259]]], device='cuda:0')\n",
      "tensor([[[ 1.0259],\n",
      "         [ 9.2031],\n",
      "         [-0.0339]]], device='cuda:0')\n",
      "tensor([[[ 1.0573e+00],\n",
      "         [ 9.2284e+00],\n",
      "         [-3.5061e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0407],\n",
      "         [ 9.2098],\n",
      "         [-0.0333]]], device='cuda:0')\n",
      "tensor([[[1.0631],\n",
      "         [9.2404],\n",
      "         [0.0379]]], device='cuda:0')\n",
      "tensor([[[ 1.0252],\n",
      "         [ 9.2367],\n",
      "         [-0.0119]]], device='cuda:0')\n",
      "tensor([[[ 1.0518],\n",
      "         [ 9.2393],\n",
      "         [-0.0152]]], device='cuda:0')\n",
      "tensor([[[ 1.0247],\n",
      "         [ 9.2285],\n",
      "         [-0.0336]]], device='cuda:0')\n",
      "tensor([[[ 1.0328],\n",
      "         [ 9.2302],\n",
      "         [-0.0206]]], device='cuda:0')\n",
      "tensor([[[ 1.0637],\n",
      "         [ 9.2115],\n",
      "         [-0.0691]]], device='cuda:0')\n",
      "tensor([[[ 0.9831],\n",
      "         [ 9.2549],\n",
      "         [-0.0420]]], device='cuda:0')\n",
      "tensor([[[ 1.0334],\n",
      "         [ 9.2268],\n",
      "         [-0.0300]]], device='cuda:0')\n",
      "tensor([[[ 1.0224],\n",
      "         [ 9.2099],\n",
      "         [-0.0130]]], device='cuda:0')\n",
      "tensor([[[ 1.0554],\n",
      "         [ 9.2397],\n",
      "         [-0.0263]]], device='cuda:0')\n",
      "tensor([[[ 1.0545],\n",
      "         [ 9.2207],\n",
      "         [-0.0140]]], device='cuda:0')\n",
      "tensor([[[1.0813e+00],\n",
      "         [9.2143e+00],\n",
      "         [6.2373e-03]]], device='cuda:0')\n",
      "tensor([[[1.0599],\n",
      "         [9.2033],\n",
      "         [0.0475]]], device='cuda:0')\n",
      "tensor([[[ 1.0434],\n",
      "         [ 9.2286],\n",
      "         [-0.0441]]], device='cuda:0')\n",
      "tensor([[[ 1.0412],\n",
      "         [ 9.2271],\n",
      "         [-0.0336]]], device='cuda:0')\n",
      "tensor([[[1.0656e+00],\n",
      "         [9.2545e+00],\n",
      "         [4.2343e-03]]], device='cuda:0')\n",
      "tensor([[[1.0436e+00],\n",
      "         [9.2267e+00],\n",
      "         [4.8620e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0715],\n",
      "         [ 9.2030],\n",
      "         [-0.0105]]], device='cuda:0')\n",
      "tensor([[[ 1.0485],\n",
      "         [ 9.2352],\n",
      "         [-0.0168]]], device='cuda:0')\n",
      "tensor([[[1.0685e+00],\n",
      "         [9.2316e+00],\n",
      "         [4.5944e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0537],\n",
      "         [ 9.2657],\n",
      "         [-0.0223]]], device='cuda:0')\n",
      "tensor([[[ 1.0444],\n",
      "         [ 9.2345],\n",
      "         [-0.0468]]], device='cuda:0')\n",
      "tensor([[[ 1.0548e+00],\n",
      "         [ 9.2300e+00],\n",
      "         [-6.6996e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0483],\n",
      "         [ 9.2327],\n",
      "         [-0.0477]]], device='cuda:0')\n",
      "tensor([[[ 1.0448],\n",
      "         [ 9.2435],\n",
      "         [-0.0346]]], device='cuda:0')\n",
      "tensor([[[ 1.0278],\n",
      "         [ 9.2459],\n",
      "         [-0.0299]]], device='cuda:0')\n",
      "tensor([[[ 1.0556],\n",
      "         [ 9.2284],\n",
      "         [-0.0137]]], device='cuda:0')\n",
      "tensor([[[1.0640],\n",
      "         [9.2048],\n",
      "         [0.0332]]], device='cuda:0')\n",
      "tensor([[[1.0688],\n",
      "         [9.2271],\n",
      "         [0.0181]]], device='cuda:0')\n",
      "tensor([[[1.0558],\n",
      "         [9.2156],\n",
      "         [0.0504]]], device='cuda:0')\n",
      "tensor([[[ 1.0578e+00],\n",
      "         [ 9.2254e+00],\n",
      "         [-7.4573e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0347],\n",
      "         [ 9.2174],\n",
      "         [-0.0178]]], device='cuda:0')\n",
      "tensor([[[ 1.0483],\n",
      "         [ 9.2250],\n",
      "         [-0.0227]]], device='cuda:0')\n",
      "tensor([[[ 0.9966],\n",
      "         [ 9.2232],\n",
      "         [-0.0107]]], device='cuda:0')\n",
      "tensor([[[ 1.0290],\n",
      "         [ 9.2320],\n",
      "         [-0.0118]]], device='cuda:0')\n",
      "tensor([[[ 1.0321],\n",
      "         [ 9.2300],\n",
      "         [-0.0130]]], device='cuda:0')\n",
      "tensor([[[1.0665e+00],\n",
      "         [9.2676e+00],\n",
      "         [3.8705e-03]]], device='cuda:0')\n",
      "tensor([[[1.0423],\n",
      "         [9.2146],\n",
      "         [0.0573]]], device='cuda:0')\n",
      "tensor([[[1.0642],\n",
      "         [9.1939],\n",
      "         [0.0383]]], device='cuda:0')\n",
      "tensor([[[ 1.0519],\n",
      "         [ 9.2577],\n",
      "         [-0.0188]]], device='cuda:0')\n",
      "tensor([[[ 1.0491],\n",
      "         [ 9.2343],\n",
      "         [-0.0127]]], device='cuda:0')\n",
      "tensor([[[ 1.1130],\n",
      "         [ 9.2144],\n",
      "         [-0.0462]]], device='cuda:0')\n",
      "tensor([[[ 1.0565e+00],\n",
      "         [ 9.2203e+00],\n",
      "         [-3.1056e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0569e+00],\n",
      "         [ 9.2479e+00],\n",
      "         [-3.6167e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0252],\n",
      "         [ 9.2122],\n",
      "         [-0.0216]]], device='cuda:0')\n",
      "tensor([[[ 1.0184],\n",
      "         [ 9.2207],\n",
      "         [-0.0227]]], device='cuda:0')\n",
      "tensor([[[ 1.0873],\n",
      "         [ 9.2404],\n",
      "         [-0.0496]]], device='cuda:0')\n",
      "tensor([[[1.0466],\n",
      "         [9.2274],\n",
      "         [0.0113]]], device='cuda:0')\n",
      "tensor([[[1.0484],\n",
      "         [9.2077],\n",
      "         [0.0745]]], device='cuda:0')\n",
      "tensor([[[ 1.0576e+00],\n",
      "         [ 9.2287e+00],\n",
      "         [-8.0821e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0710],\n",
      "         [ 9.2293],\n",
      "         [-0.0105]]], device='cuda:0')\n",
      "tensor([[[ 1.0511],\n",
      "         [ 9.2136],\n",
      "         [-0.0165]]], device='cuda:0')\n",
      "tensor([[[1.0525e+00],\n",
      "         [9.2313e+00],\n",
      "         [1.0070e-03]]], device='cuda:0')\n",
      "tensor([[[1.0860],\n",
      "         [9.2131],\n",
      "         [0.0310]]], device='cuda:0')\n",
      "tensor([[[ 1.0451e+00],\n",
      "         [ 9.2120e+00],\n",
      "         [-6.5820e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0463],\n",
      "         [ 9.2143],\n",
      "         [-0.0490]]], device='cuda:0')\n",
      "tensor([[[ 1.0935],\n",
      "         [ 9.2532],\n",
      "         [-0.0475]]], device='cuda:0')\n",
      "tensor([[[1.0805e+00],\n",
      "         [9.2231e+00],\n",
      "         [7.7749e-03]]], device='cuda:0')\n",
      "tensor([[[1.0645],\n",
      "         [9.2191],\n",
      "         [0.0753]]], device='cuda:0')\n",
      "tensor([[[ 1.0326],\n",
      "         [ 9.2368],\n",
      "         [-0.0302]]], device='cuda:0')\n",
      "tensor([[[1.0660],\n",
      "         [9.2044],\n",
      "         [0.1128]]], device='cuda:0')\n",
      "tensor([[[ 1.0558e+00],\n",
      "         [ 9.2342e+00],\n",
      "         [-5.2707e-03]]], device='cuda:0')\n",
      "tensor([[[1.0519],\n",
      "         [9.2154],\n",
      "         [0.0854]]], device='cuda:0')\n",
      "tensor([[[1.0638],\n",
      "         [9.2271],\n",
      "         [0.0352]]], device='cuda:0')\n",
      "tensor([[[ 1.0161],\n",
      "         [ 9.2199],\n",
      "         [-0.0790]]], device='cuda:0')\n",
      "tensor([[[ 1.0578],\n",
      "         [ 9.2101],\n",
      "         [-0.0427]]], device='cuda:0')\n",
      "tensor([[[ 1.0562],\n",
      "         [ 9.2403],\n",
      "         [-0.0368]]], device='cuda:0')\n",
      "tensor([[[1.0671],\n",
      "         [9.2171],\n",
      "         [0.0295]]], device='cuda:0')\n",
      "tensor([[[1.0495],\n",
      "         [9.1933],\n",
      "         [0.0736]]], device='cuda:0')\n",
      "tensor([[[ 1.0495],\n",
      "         [ 9.2340],\n",
      "         [-0.0341]]], device='cuda:0')\n",
      "tensor([[[ 1.0514],\n",
      "         [ 9.2345],\n",
      "         [-0.0190]]], device='cuda:0')\n",
      "tensor([[[1.0500],\n",
      "         [9.2138],\n",
      "         [0.0733]]], device='cuda:0')\n",
      "tensor([[[ 1.0236],\n",
      "         [ 9.2066],\n",
      "         [-0.0258]]], device='cuda:0')\n",
      "tensor([[[ 1.0544],\n",
      "         [ 9.2252],\n",
      "         [-0.0135]]], device='cuda:0')\n",
      "tensor([[[ 1.0300],\n",
      "         [ 9.2129],\n",
      "         [-0.0163]]], device='cuda:0')\n",
      "tensor([[[ 1.0298],\n",
      "         [ 9.2395],\n",
      "         [-0.0395]]], device='cuda:0')\n",
      "tensor([[[1.0425e+00],\n",
      "         [9.2454e+00],\n",
      "         [4.4907e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0610],\n",
      "         [ 9.2213],\n",
      "         [-0.0222]]], device='cuda:0')\n",
      "tensor([[[1.0595],\n",
      "         [9.2173],\n",
      "         [0.0274]]], device='cuda:0')\n",
      "tensor([[[ 1.0855],\n",
      "         [ 9.2314],\n",
      "         [-0.0570]]], device='cuda:0')\n",
      "tensor([[[ 1.0488e+00],\n",
      "         [ 9.2564e+00],\n",
      "         [-5.4927e-03]]], device='cuda:0')\n",
      "tensor([[[1.1071],\n",
      "         [1.0779],\n",
      "         [0.0065]]], device='cuda:0')\n",
      "tensor([[[1.0490],\n",
      "         [9.2068],\n",
      "         [0.0677]]], device='cuda:0')\n",
      "tensor([[[1.0512e+00],\n",
      "         [9.2279e+00],\n",
      "         [1.3063e-03]]], device='cuda:0')\n",
      "tensor([[[1.0768e+00],\n",
      "         [9.2260e+00],\n",
      "         [2.3252e-03]]], device='cuda:0')\n",
      "tensor([[[1.0646],\n",
      "         [9.2237],\n",
      "         [0.0330]]], device='cuda:0')\n",
      "tensor([[[ 1.0228],\n",
      "         [ 9.2094],\n",
      "         [-0.0297]]], device='cuda:0')\n",
      "tensor([[[ 1.0317],\n",
      "         [ 9.2238],\n",
      "         [-0.0131]]], device='cuda:0')\n",
      "tensor([[[ 1.0541],\n",
      "         [ 9.2251],\n",
      "         [-0.0152]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.1295],\n",
      "         [ 9.2016],\n",
      "         [-0.0648]]], device='cuda:0')\n",
      "tensor([[[ 1.0361],\n",
      "         [ 9.2453],\n",
      "         [-0.0115]]], device='cuda:0')\n",
      "tensor([[[ 1.0558],\n",
      "         [ 9.2222],\n",
      "         [-0.0217]]], device='cuda:0')\n",
      "tensor([[[ 1.0792],\n",
      "         [ 1.0107],\n",
      "         [-0.0408]]], device='cuda:0')\n",
      "tensor([[[ 1.0527],\n",
      "         [ 9.2382],\n",
      "         [-0.0142]]], device='cuda:0')\n",
      "tensor([[[1.0680e+00],\n",
      "         [9.2268e+00],\n",
      "         [3.9442e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0451e+00],\n",
      "         [ 9.2120e+00],\n",
      "         [-6.5820e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0526],\n",
      "         [ 9.2223],\n",
      "         [-0.0156]]], device='cuda:0')\n",
      "tensor([[[ 1.0477],\n",
      "         [ 9.2402],\n",
      "         [-0.0119]]], device='cuda:0')\n",
      "tensor([[[ 1.0471],\n",
      "         [ 9.2354],\n",
      "         [-0.0128]]], device='cuda:0')\n",
      "tensor([[[ 1.0300e+00],\n",
      "         [ 9.2280e+00],\n",
      "         [-8.9834e-03]]], device='cuda:0')\n",
      "tensor([[[1.0503e+00],\n",
      "         [9.2125e+00],\n",
      "         [3.1962e-04]]], device='cuda:0')\n",
      "tensor([[[1.0557],\n",
      "         [9.2172],\n",
      "         [0.0507]]], device='cuda:0')\n",
      "tensor([[[ 1.0653],\n",
      "         [ 1.0270],\n",
      "         [-0.0120]]], device='cuda:0')\n",
      "tensor([[[ 1.0572],\n",
      "         [ 1.0091],\n",
      "         [-0.0220]]], device='cuda:0')\n",
      "tensor([[[ 1.0522],\n",
      "         [ 9.2337],\n",
      "         [-0.0155]]], device='cuda:0')\n",
      "tensor([[[ 1.0614],\n",
      "         [ 9.2379],\n",
      "         [-0.0199]]], device='cuda:0')\n",
      "tensor([[[1.0858],\n",
      "         [9.2454],\n",
      "         [0.0312]]], device='cuda:0')\n",
      "tensor([[[ 9.8550e-01],\n",
      "         [ 9.2332e+00],\n",
      "         [-4.6706e-03]]], device='cuda:0')\n",
      "tensor([[[1.0659e+00],\n",
      "         [9.2575e+00],\n",
      "         [3.5818e-03]]], device='cuda:0')\n",
      "tensor([[[1.0633],\n",
      "         [9.2060],\n",
      "         [0.1199]]], device='cuda:0')\n",
      "tensor([[[ 1.0474],\n",
      "         [ 9.2332],\n",
      "         [-0.0269]]], device='cuda:0')\n",
      "tensor([[[ 1.0447],\n",
      "         [ 9.2398],\n",
      "         [-0.0129]]], device='cuda:0')\n",
      "tensor([[[ 1.0924],\n",
      "         [ 9.2453],\n",
      "         [-0.0453]]], device='cuda:0')\n",
      "tensor([[[ 1.0587],\n",
      "         [ 9.2400],\n",
      "         [-0.0190]]], device='cuda:0')\n",
      "tensor([[[1.0693e+00],\n",
      "         [9.2158e+00],\n",
      "         [8.6196e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0451],\n",
      "         [ 9.2390],\n",
      "         [-0.0141]]], device='cuda:0')\n",
      "tensor([[[ 1.0559],\n",
      "         [ 9.2425],\n",
      "         [-0.0258]]], device='cuda:0')\n",
      "tensor([[[1.0561],\n",
      "         [9.2284],\n",
      "         [0.0491]]], device='cuda:0')\n",
      "tensor([[[ 1.0257],\n",
      "         [ 9.2089],\n",
      "         [-0.0332]]], device='cuda:0')\n",
      "tensor([[[ 1.0522],\n",
      "         [ 9.2412],\n",
      "         [-0.0203]]], device='cuda:0')\n",
      "tensor([[[ 1.0406e+00],\n",
      "         [ 9.2136e+00],\n",
      "         [-7.8898e-03]]], device='cuda:0')\n",
      "tensor([[[ 0.9856],\n",
      "         [ 9.2330],\n",
      "         [-0.0101]]], device='cuda:0')\n",
      "tensor([[[ 1.0489],\n",
      "         [ 9.2165],\n",
      "         [-0.0263]]], device='cuda:0')\n",
      "tensor([[[ 1.0573e+00],\n",
      "         [ 9.2303e+00],\n",
      "         [-4.6189e-03]]], device='cuda:0')\n",
      "tensor([[[1.0055],\n",
      "         [9.2298],\n",
      "         [0.0111]]], device='cuda:0')\n",
      "tensor([[[1.0858],\n",
      "         [9.2127],\n",
      "         [0.0310]]], device='cuda:0')\n",
      "tensor([[[1.0480e+00],\n",
      "         [9.2291e+00],\n",
      "         [3.2851e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0549],\n",
      "         [ 9.2186],\n",
      "         [-0.0199]]], device='cuda:0')\n",
      "tensor([[[ 1.0458],\n",
      "         [ 9.2298],\n",
      "         [-0.0118]]], device='cuda:0')\n",
      "tensor([[[ 1.0679],\n",
      "         [ 9.2414],\n",
      "         [-0.0410]]], device='cuda:0')\n",
      "tensor([[[ 1.0567e+00],\n",
      "         [ 9.2344e+00],\n",
      "         [-4.3472e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0160],\n",
      "         [ 9.2208],\n",
      "         [-0.0243]]], device='cuda:0')\n",
      "tensor([[[ 1.0476],\n",
      "         [ 9.2237],\n",
      "         [-0.0475]]], device='cuda:0')\n",
      "tensor([[[ 1.0378],\n",
      "         [ 9.2329],\n",
      "         [-0.0111]]], device='cuda:0')\n",
      "tensor([[[ 1.0272],\n",
      "         [ 9.2140],\n",
      "         [-0.0136]]], device='cuda:0')\n",
      "tensor([[[1.0816],\n",
      "         [1.0675],\n",
      "         [0.0442]]], device='cuda:0')\n",
      "tensor([[[1.0753],\n",
      "         [9.2044],\n",
      "         [0.0552]]], device='cuda:0')\n",
      "tensor([[[ 1.0513],\n",
      "         [ 9.2210],\n",
      "         [-0.0292]]], device='cuda:0')\n",
      "tensor([[[ 1.0484],\n",
      "         [ 9.2555],\n",
      "         [-0.0145]]], device='cuda:0')\n",
      "tensor([[[1.0838],\n",
      "         [1.0955],\n",
      "         [0.0792]]], device='cuda:0')\n",
      "tensor([[[ 1.0475],\n",
      "         [ 9.2392],\n",
      "         [-0.0099]]], device='cuda:0')\n",
      "tensor([[[1.0745],\n",
      "         [9.2148],\n",
      "         [0.0459]]], device='cuda:0')\n",
      "tensor([[[ 1.0901],\n",
      "         [ 9.2366],\n",
      "         [-0.0504]]], device='cuda:0')\n",
      "tensor([[[ 0.9990],\n",
      "         [ 9.2535],\n",
      "         [-0.0131]]], device='cuda:0')\n",
      "tensor([[[ 1.0410],\n",
      "         [ 9.2321],\n",
      "         [-0.0107]]], device='cuda:0')\n",
      "tensor([[[ 1.0557],\n",
      "         [ 9.2330],\n",
      "         [-0.0262]]], device='cuda:0')\n",
      "tensor([[[1.0472e+00],\n",
      "         [9.2305e+00],\n",
      "         [3.1545e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0548],\n",
      "         [ 9.2382],\n",
      "         [-0.0158]]], device='cuda:0')\n",
      "tensor([[[1.0044e+00],\n",
      "         [9.2007e+00],\n",
      "         [4.5282e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0899],\n",
      "         [ 9.2303],\n",
      "         [-0.0497]]], device='cuda:0')\n",
      "tensor([[[ 1.0942],\n",
      "         [ 9.2254],\n",
      "         [-0.0459]]], device='cuda:0')\n",
      "tensor([[[ 1.0563e+00],\n",
      "         [ 9.2178e+00],\n",
      "         [-3.7666e-03]]], device='cuda:0')\n",
      "tensor([[[1.1845],\n",
      "         [1.1224],\n",
      "         [0.1081]]], device='cuda:0')\n",
      "tensor([[[ 1.0575],\n",
      "         [ 9.2351],\n",
      "         [-0.0200]]], device='cuda:0')\n",
      "tensor([[[1.0480e+00],\n",
      "         [9.2453e+00],\n",
      "         [3.2564e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0673e+00],\n",
      "         [ 9.2436e+00],\n",
      "         [-5.5004e-03]]], device='cuda:0')\n",
      "tensor([[[1.0484e+00],\n",
      "         [9.2298e+00],\n",
      "         [2.9879e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0637],\n",
      "         [ 9.2436],\n",
      "         [-0.0347]]], device='cuda:0')\n",
      "tensor([[[ 1.0286],\n",
      "         [ 9.2492],\n",
      "         [-0.0385]]], device='cuda:0')\n",
      "tensor([[[1.0586],\n",
      "         [9.2282],\n",
      "         [0.0201]]], device='cuda:0')\n",
      "tensor([[[ 1.0532],\n",
      "         [ 9.2125],\n",
      "         [-0.0162]]], device='cuda:0')\n",
      "tensor([[[1.0577],\n",
      "         [9.2170],\n",
      "         [0.0210]]], device='cuda:0')\n",
      "tensor([[[ 1.0176],\n",
      "         [ 9.2266],\n",
      "         [-0.0282]]], device='cuda:0')\n",
      "tensor([[[ 1.0596],\n",
      "         [ 9.2430],\n",
      "         [-0.0192]]], device='cuda:0')\n",
      "tensor([[[0.9828],\n",
      "         [9.2054],\n",
      "         [0.0401]]], device='cuda:0')\n",
      "tensor([[[ 1.0335],\n",
      "         [ 9.2243],\n",
      "         [-0.0299]]], device='cuda:0')\n",
      "tensor([[[1.1110],\n",
      "         [9.2144],\n",
      "         [0.1628]]], device='cuda:0')\n",
      "tensor([[[ 1.0420e+00],\n",
      "         [ 9.2200e+00],\n",
      "         [-8.4024e-03]]], device='cuda:0')\n",
      "tensor([[[1.0483e+00],\n",
      "         [9.2423e+00],\n",
      "         [5.6309e-03]]], device='cuda:0')\n",
      "tensor([[[1.0850],\n",
      "         [9.2249],\n",
      "         [0.0319]]], device='cuda:0')\n",
      "tensor([[[ 1.0276],\n",
      "         [ 9.2258],\n",
      "         [-0.0768]]], device='cuda:0')\n",
      "tensor([[[ 1.0801e+00],\n",
      "         [ 9.2269e+00],\n",
      "         [-5.9177e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0657],\n",
      "         [ 9.2297],\n",
      "         [-0.0093]]], device='cuda:0')\n",
      "tensor([[[ 1.0468],\n",
      "         [ 9.2373],\n",
      "         [-0.0469]]], device='cuda:0')\n",
      "tensor([[[ 1.0434],\n",
      "         [ 9.2182],\n",
      "         [-0.0107]]], device='cuda:0')\n",
      "tensor([[[ 1.1488],\n",
      "         [ 9.1462],\n",
      "         [-0.0599]]], device='cuda:0')\n",
      "tensor([[[ 1.0238],\n",
      "         [ 9.2427],\n",
      "         [-0.0529]]], device='cuda:0')\n",
      "tensor([[[1.0439e+00],\n",
      "         [9.2291e+00],\n",
      "         [4.6089e-03]]], device='cuda:0')\n",
      "tensor([[[1.0757],\n",
      "         [9.2108],\n",
      "         [0.0461]]], device='cuda:0')\n",
      "tensor([[[ 1.0225],\n",
      "         [ 9.2209],\n",
      "         [-0.0148]]], device='cuda:0')\n",
      "tensor([[[1.0452],\n",
      "         [9.2040],\n",
      "         [0.0554]]], device='cuda:0')\n",
      "tensor([[[ 1.0546],\n",
      "         [ 9.2337],\n",
      "         [-0.0142]]], device='cuda:0')\n",
      "tensor([[[ 1.0481],\n",
      "         [ 9.2470],\n",
      "         [-0.0274]]], device='cuda:0')\n",
      "tensor([[[ 1.0476],\n",
      "         [ 9.2239],\n",
      "         [-0.0144]]], device='cuda:0')\n",
      "tensor([[[ 1.0449],\n",
      "         [ 9.2428],\n",
      "         [-0.0146]]], device='cuda:0')\n",
      "tensor([[[ 1.0642],\n",
      "         [ 9.2241],\n",
      "         [-0.0124]]], device='cuda:0')\n",
      "tensor([[[ 1.0503],\n",
      "         [ 9.2283],\n",
      "         [-0.0153]]], device='cuda:0')\n",
      "tensor([[[1.0850],\n",
      "         [9.2249],\n",
      "         [0.0319]]], device='cuda:0')\n",
      "tensor([[[ 1.0462],\n",
      "         [ 9.2175],\n",
      "         [-0.0340]]], device='cuda:0')\n",
      "tensor([[[ 0.9999],\n",
      "         [ 9.2292],\n",
      "         [-0.0125]]], device='cuda:0')\n",
      "tensor([[[ 9.8454e-01],\n",
      "         [ 9.2105e+00],\n",
      "         [-3.3309e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0691e+00],\n",
      "         [ 9.2247e+00],\n",
      "         [-8.3614e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0359],\n",
      "         [ 9.2266],\n",
      "         [-0.0440]]], device='cuda:0')\n",
      "tensor([[[ 1.0292],\n",
      "         [ 9.2596],\n",
      "         [-0.0397]]], device='cuda:0')\n",
      "tensor([[[ 1.0231],\n",
      "         [ 9.2406],\n",
      "         [-0.0750]]], device='cuda:0')\n",
      "tensor([[[1.0667e+00],\n",
      "         [9.2336e+00],\n",
      "         [4.6615e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0568],\n",
      "         [ 9.2281],\n",
      "         [-0.0370]]], device='cuda:0')\n",
      "tensor([[[1.0666],\n",
      "         [9.2453],\n",
      "         [0.1159]]], device='cuda:0')\n",
      "tensor([[[ 1.0331],\n",
      "         [ 9.2175],\n",
      "         [-0.0105]]], device='cuda:0')\n",
      "tensor([[[ 1.0327],\n",
      "         [ 9.1958],\n",
      "         [-0.0398]]], device='cuda:0')\n",
      "tensor([[[ 1.0437],\n",
      "         [ 9.2453],\n",
      "         [-0.0329]]], device='cuda:0')\n",
      "tensor([[[1.0749],\n",
      "         [9.2047],\n",
      "         [0.0412]]], device='cuda:0')\n",
      "tensor([[[ 1.0679],\n",
      "         [ 9.2501],\n",
      "         [-0.0406]]], device='cuda:0')\n",
      "tensor([[[ 1.0695],\n",
      "         [ 1.0106],\n",
      "         [-0.0409]]], device='cuda:0')\n",
      "tensor([[[ 1.0683],\n",
      "         [ 9.2228],\n",
      "         [-0.0678]]], device='cuda:0')\n",
      "tensor([[[ 1.0560e+00],\n",
      "         [ 9.2326e+00],\n",
      "         [-7.4752e-03]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 0.9826],\n",
      "         [ 9.2541],\n",
      "         [-0.0403]]], device='cuda:0')\n",
      "tensor([[[ 1.0911],\n",
      "         [ 9.2098],\n",
      "         [-0.0519]]], device='cuda:0')\n",
      "tensor([[[ 1.0493],\n",
      "         [ 9.2475],\n",
      "         [-0.0117]]], device='cuda:0')\n",
      "tensor([[[1.0517e+00],\n",
      "         [9.2349e+00],\n",
      "         [1.0060e-03]]], device='cuda:0')\n",
      "tensor([[[1.0690e+00],\n",
      "         [9.2407e+00],\n",
      "         [4.1352e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0551],\n",
      "         [ 9.2341],\n",
      "         [-0.0371]]], device='cuda:0')\n",
      "tensor([[[ 1.0489],\n",
      "         [ 9.2354],\n",
      "         [-0.0189]]], device='cuda:0')\n",
      "tensor([[[ 1.0687e+00],\n",
      "         [ 9.2058e+00],\n",
      "         [-5.9373e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0537],\n",
      "         [ 9.2641],\n",
      "         [-0.0226]]], device='cuda:0')\n",
      "tensor([[[1.0493],\n",
      "         [9.2636],\n",
      "         [0.0115]]], device='cuda:0')\n",
      "tensor([[[1.0647],\n",
      "         [9.2039],\n",
      "         [0.0340]]], device='cuda:0')\n",
      "tensor([[[ 1.0603e+00],\n",
      "         [ 9.2394e+00],\n",
      "         [-8.6125e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0411],\n",
      "         [ 9.2222],\n",
      "         [-0.0103]]], device='cuda:0')\n",
      "tensor([[[ 1.0442e+00],\n",
      "         [ 9.2157e+00],\n",
      "         [-7.4636e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0252],\n",
      "         [ 9.2351],\n",
      "         [-0.0328]]], device='cuda:0')\n",
      "tensor([[[ 1.0524],\n",
      "         [ 9.2396],\n",
      "         [-0.0296]]], device='cuda:0')\n",
      "tensor([[[ 1.0220],\n",
      "         [ 9.2406],\n",
      "         [-0.0330]]], device='cuda:0')\n",
      "tensor([[[ 1.0537],\n",
      "         [ 9.2529],\n",
      "         [-0.0358]]], device='cuda:0')\n",
      "tensor([[[ 1.0635],\n",
      "         [ 9.2339],\n",
      "         [-0.0228]]], device='cuda:0')\n",
      "tensor([[[1.0636],\n",
      "         [9.2172],\n",
      "         [0.0388]]], device='cuda:0')\n",
      "tensor([[[ 1.0590e+00],\n",
      "         [ 9.2288e+00],\n",
      "         [-6.8252e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0535],\n",
      "         [ 9.2237],\n",
      "         [-0.0226]]], device='cuda:0')\n",
      "tensor([[[ 1.0322],\n",
      "         [ 9.2289],\n",
      "         [-0.0299]]], device='cuda:0')\n",
      "tensor([[[ 1.0215],\n",
      "         [ 9.2499],\n",
      "         [-0.0117]]], device='cuda:0')\n",
      "tensor([[[ 1.0197],\n",
      "         [ 9.1991],\n",
      "         [-0.0340]]], device='cuda:0')\n",
      "tensor([[[ 1.0313],\n",
      "         [ 9.2390],\n",
      "         [-0.0427]]], device='cuda:0')\n",
      "tensor([[[ 1.0301],\n",
      "         [ 9.2281],\n",
      "         [-0.0146]]], device='cuda:0')\n",
      "tensor([[[ 1.0313],\n",
      "         [ 9.2267],\n",
      "         [-0.0108]]], device='cuda:0')\n",
      "tensor([[[ 1.0300],\n",
      "         [ 9.2249],\n",
      "         [-0.0119]]], device='cuda:0')\n",
      "tensor([[[ 1.0565e+00],\n",
      "         [ 9.2348e+00],\n",
      "         [-3.5608e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0529],\n",
      "         [ 9.2349],\n",
      "         [-0.0138]]], device='cuda:0')\n",
      "tensor([[[ 1.0374],\n",
      "         [ 9.2380],\n",
      "         [-0.0440]]], device='cuda:0')\n",
      "tensor([[[1.0310],\n",
      "         [1.0818],\n",
      "         [0.0426]]], device='cuda:0')\n",
      "tensor([[[1.0804e+00],\n",
      "         [9.2045e+00],\n",
      "         [7.3421e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0196],\n",
      "         [ 9.2298],\n",
      "         [-0.0293]]], device='cuda:0')\n",
      "tensor([[[ 1.0569e+00],\n",
      "         [ 9.2364e+00],\n",
      "         [-3.4108e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0560e+00],\n",
      "         [ 9.2326e+00],\n",
      "         [-7.4752e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0299],\n",
      "         [ 9.2322],\n",
      "         [-0.0131]]], device='cuda:0')\n",
      "tensor([[[ 1.0279],\n",
      "         [ 9.2273],\n",
      "         [-0.0293]]], device='cuda:0')\n",
      "tensor([[[ 1.0462],\n",
      "         [ 9.2536],\n",
      "         [-0.0472]]], device='cuda:0')\n",
      "tensor([[[ 1.0185],\n",
      "         [ 9.2545],\n",
      "         [-0.0290]]], device='cuda:0')\n",
      "tensor([[[ 1.0413],\n",
      "         [ 9.2261],\n",
      "         [-0.0142]]], device='cuda:0')\n",
      "tensor([[[ 1.0524],\n",
      "         [ 9.2266],\n",
      "         [-0.0193]]], device='cuda:0')\n",
      "tensor([[[ 1.0356],\n",
      "         [ 9.2570],\n",
      "         [-0.0123]]], device='cuda:0')\n",
      "tensor([[[ 1.0504],\n",
      "         [ 9.2421],\n",
      "         [-0.0205]]], device='cuda:0')\n",
      "tensor([[[1.0474],\n",
      "         [9.2254],\n",
      "         [0.0661]]], device='cuda:0')\n",
      "tensor([[[ 1.0527],\n",
      "         [ 9.2110],\n",
      "         [-0.0193]]], device='cuda:0')\n",
      "tensor([[[1.0646],\n",
      "         [9.2082],\n",
      "         [0.0398]]], device='cuda:0')\n",
      "tensor([[[ 1.0603],\n",
      "         [ 9.2207],\n",
      "         [-0.0120]]], device='cuda:0')\n",
      "tensor([[[ 1.0414],\n",
      "         [ 9.2172],\n",
      "         [-0.0339]]], device='cuda:0')\n",
      "tensor([[[ 0.9993],\n",
      "         [ 9.2377],\n",
      "         [-0.0122]]], device='cuda:0')\n",
      "tensor([[[ 1.0499],\n",
      "         [ 9.2287],\n",
      "         [-0.0134]]], device='cuda:0')\n",
      "tensor([[[1.0693],\n",
      "         [9.2168],\n",
      "         [0.1029]]], device='cuda:0')\n",
      "tensor([[[ 1.0556],\n",
      "         [ 9.2125],\n",
      "         [-0.0203]]], device='cuda:0')\n",
      "tensor([[[ 1.0432],\n",
      "         [ 9.2502],\n",
      "         [-0.0336]]], device='cuda:0')\n",
      "tensor([[[ 1.0450],\n",
      "         [ 9.2252],\n",
      "         [-0.0235]]], device='cuda:0')\n",
      "tensor([[[ 9.8478e-01],\n",
      "         [ 9.2335e+00],\n",
      "         [-3.0801e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0288],\n",
      "         [ 9.2409],\n",
      "         [-0.0398]]], device='cuda:0')\n",
      "tensor([[[ 1.0314],\n",
      "         [ 9.2307],\n",
      "         [-0.0104]]], device='cuda:0')\n",
      "tensor([[[ 1.0026e+00],\n",
      "         [ 9.1990e+00],\n",
      "         [-6.2119e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0562],\n",
      "         [ 9.2206],\n",
      "         [-0.0137]]], device='cuda:0')\n",
      "tensor([[[ 1.0533],\n",
      "         [ 9.2353],\n",
      "         [-0.0258]]], device='cuda:0')\n",
      "tensor([[[ 1.0451],\n",
      "         [ 9.2213],\n",
      "         [-0.0338]]], device='cuda:0')\n",
      "tensor([[[ 1.0431],\n",
      "         [ 9.2285],\n",
      "         [-0.0334]]], device='cuda:0')\n",
      "tensor([[[ 1.0512],\n",
      "         [ 9.2394],\n",
      "         [-0.0188]]], device='cuda:0')\n",
      "tensor([[[1.0668],\n",
      "         [9.2151],\n",
      "         [0.0438]]], device='cuda:0')\n",
      "tensor([[[ 1.0418],\n",
      "         [ 9.2425],\n",
      "         [-0.0302]]], device='cuda:0')\n",
      "tensor([[[ 1.0625],\n",
      "         [ 9.2311],\n",
      "         [-0.0309]]], device='cuda:0')\n",
      "tensor([[[ 1.0177],\n",
      "         [ 9.2494],\n",
      "         [-0.0205]]], device='cuda:0')\n",
      "tensor([[[ 1.0746],\n",
      "         [ 9.2272],\n",
      "         [-0.0095]]], device='cuda:0')\n",
      "tensor([[[ 1.0607],\n",
      "         [ 9.2518],\n",
      "         [-0.0124]]], device='cuda:0')\n",
      "tensor([[[ 1.0392],\n",
      "         [ 9.2324],\n",
      "         [-0.0332]]], device='cuda:0')\n",
      "tensor([[[ 1.0448],\n",
      "         [ 9.2120],\n",
      "         [-0.0120]]], device='cuda:0')\n",
      "tensor([[[1.0699e+00],\n",
      "         [9.2382e+00],\n",
      "         [4.5727e-03]]], device='cuda:0')\n",
      "tensor([[[1.0654],\n",
      "         [9.2138],\n",
      "         [0.0405]]], device='cuda:0')\n",
      "tensor([[[1.0436e+00],\n",
      "         [9.2267e+00],\n",
      "         [4.8620e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0461],\n",
      "         [ 9.2314],\n",
      "         [-0.0132]]], device='cuda:0')\n",
      "tensor([[[ 1.0448],\n",
      "         [ 9.2380],\n",
      "         [-0.0103]]], device='cuda:0')\n",
      "tensor([[[ 1.0358],\n",
      "         [ 9.2466],\n",
      "         [-0.0122]]], device='cuda:0')\n",
      "tensor([[[ 1.0672e+00],\n",
      "         [ 9.2227e+00],\n",
      "         [-7.0199e-03]]], device='cuda:0')\n",
      "tensor([[[1.0689e+00],\n",
      "         [9.2446e+00],\n",
      "         [4.4331e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0539],\n",
      "         [ 9.2402],\n",
      "         [-0.0236]]], device='cuda:0')\n",
      "tensor([[[ 1.0499],\n",
      "         [ 9.2313],\n",
      "         [-0.0129]]], device='cuda:0')\n",
      "tensor([[[ 1.0570],\n",
      "         [ 9.2375],\n",
      "         [-0.0461]]], device='cuda:0')\n",
      "tensor([[[1.1558e+00],\n",
      "         [9.1867e+00],\n",
      "         [7.5645e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0759],\n",
      "         [ 9.2383],\n",
      "         [-0.0094]]], device='cuda:0')\n",
      "tensor([[[ 1.0430],\n",
      "         [ 9.2242],\n",
      "         [-0.0349]]], device='cuda:0')\n",
      "tensor([[[ 1.0517],\n",
      "         [ 9.2389],\n",
      "         [-0.0204]]], device='cuda:0')\n",
      "tensor([[[ 1.0472],\n",
      "         [ 9.2524],\n",
      "         [-0.0116]]], device='cuda:0')\n",
      "tensor([[[ 1.0306],\n",
      "         [ 9.2093],\n",
      "         [-0.0122]]], device='cuda:0')\n",
      "tensor([[[1.0816e+00],\n",
      "         [9.2254e+00],\n",
      "         [4.9631e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0542],\n",
      "         [ 9.2319],\n",
      "         [-0.0158]]], device='cuda:0')\n",
      "tensor([[[ 1.0939],\n",
      "         [ 9.2212],\n",
      "         [-0.0484]]], device='cuda:0')\n",
      "tensor([[[ 1.0412e+00],\n",
      "         [ 9.2148e+00],\n",
      "         [-7.9689e-03]]], device='cuda:0')\n",
      "tensor([[[ 0.9974],\n",
      "         [ 9.2492],\n",
      "         [-0.0122]]], device='cuda:0')\n",
      "tensor([[[ 1.0337],\n",
      "         [ 9.2497],\n",
      "         [-0.0106]]], device='cuda:0')\n",
      "tensor([[[ 1.0533],\n",
      "         [ 9.2347],\n",
      "         [-0.0210]]], device='cuda:0')\n",
      "tensor([[[ 1.0563e+00],\n",
      "         [ 9.2178e+00],\n",
      "         [-3.7666e-03]]], device='cuda:0')\n",
      "tensor([[[ 9.8651e-01],\n",
      "         [ 9.2365e+00],\n",
      "         [-4.6171e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0300],\n",
      "         [ 9.2438],\n",
      "         [-0.0099]]], device='cuda:0')\n",
      "tensor([[[ 1.0272],\n",
      "         [ 9.2189],\n",
      "         [-0.0337]]], device='cuda:0')\n",
      "tensor([[[1.0628],\n",
      "         [9.2085],\n",
      "         [0.0234]]], device='cuda:0')\n",
      "tensor([[[1.0522],\n",
      "         [9.2202],\n",
      "         [0.0954]]], device='cuda:0')\n",
      "tensor([[[ 1.0175],\n",
      "         [ 9.2430],\n",
      "         [-0.0352]]], device='cuda:0')\n",
      "tensor([[[ 1.0549],\n",
      "         [ 9.2658],\n",
      "         [-0.0137]]], device='cuda:0')\n",
      "tensor([[[ 1.0344],\n",
      "         [ 9.2497],\n",
      "         [-0.0229]]], device='cuda:0')\n",
      "tensor([[[ 1.0529],\n",
      "         [ 9.2268],\n",
      "         [-0.0156]]], device='cuda:0')\n",
      "tensor([[[ 1.0519],\n",
      "         [ 9.2582],\n",
      "         [-0.0298]]], device='cuda:0')\n",
      "tensor([[[ 1.0524],\n",
      "         [ 9.2103],\n",
      "         [-0.0429]]], device='cuda:0')\n",
      "tensor([[[ 1.0185],\n",
      "         [ 9.2275],\n",
      "         [-0.0216]]], device='cuda:0')\n",
      "tensor([[[ 1.0369],\n",
      "         [ 9.2508],\n",
      "         [-0.0114]]], device='cuda:0')\n",
      "tensor([[[ 1.0428],\n",
      "         [ 9.2126],\n",
      "         [-0.0344]]], device='cuda:0')\n",
      "tensor([[[ 1.0289],\n",
      "         [ 9.2254],\n",
      "         [-0.0136]]], device='cuda:0')\n",
      "tensor([[[ 1.0554],\n",
      "         [ 9.2369],\n",
      "         [-0.0168]]], device='cuda:0')\n",
      "tensor([[[ 1.0468],\n",
      "         [ 9.2495],\n",
      "         [-0.0094]]], device='cuda:0')\n",
      "tensor([[[ 1.0564],\n",
      "         [ 9.2363],\n",
      "         [-0.0258]]], device='cuda:0')\n",
      "tensor([[[ 1.0489],\n",
      "         [ 9.2165],\n",
      "         [-0.0263]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0703],\n",
      "         [ 9.2452],\n",
      "         [-0.0105]]], device='cuda:0')\n",
      "tensor([[[ 1.0440],\n",
      "         [ 9.2364],\n",
      "         [-0.0327]]], device='cuda:0')\n",
      "tensor([[[1.0616e+00],\n",
      "         [9.2153e+00],\n",
      "         [1.7476e-03]]], device='cuda:0')\n",
      "tensor([[[1.0853],\n",
      "         [9.2204],\n",
      "         [0.0315]]], device='cuda:0')\n",
      "tensor([[[ 1.0567],\n",
      "         [ 9.2263],\n",
      "         [-0.0190]]], device='cuda:0')\n",
      "tensor([[[ 1.0578],\n",
      "         [ 9.2588],\n",
      "         [-0.0469]]], device='cuda:0')\n",
      "tensor([[[ 1.1640],\n",
      "         [ 9.1941],\n",
      "         [-0.0584]]], device='cuda:0')\n",
      "tensor([[[ 1.0962],\n",
      "         [ 9.2276],\n",
      "         [-0.0480]]], device='cuda:0')\n",
      "tensor([[[ 1.0421],\n",
      "         [ 9.2250],\n",
      "         [-0.0343]]], device='cuda:0')\n",
      "tensor([[[ 1.0595],\n",
      "         [ 9.2372],\n",
      "         [-0.0110]]], device='cuda:0')\n",
      "tensor([[[1.0440e+00],\n",
      "         [9.2410e+00],\n",
      "         [5.0909e-03]]], device='cuda:0')\n",
      "tensor([[[1.0554],\n",
      "         [9.2265],\n",
      "         [0.0497]]], device='cuda:0')\n",
      "tensor([[[ 1.0575],\n",
      "         [ 9.2510],\n",
      "         [-0.0634]]], device='cuda:0')\n",
      "tensor([[[ 1.0724e+00],\n",
      "         [ 9.2176e+00],\n",
      "         [-5.1821e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0506],\n",
      "         [ 9.2284],\n",
      "         [-0.0260]]], device='cuda:0')\n",
      "tensor([[[ 1.0437],\n",
      "         [ 9.2248],\n",
      "         [-0.0337]]], device='cuda:0')\n",
      "tensor([[[ 1.0517],\n",
      "         [ 9.2235],\n",
      "         [-0.0403]]], device='cuda:0')\n",
      "tensor([[[1.0424e+00],\n",
      "         [9.2249e+00],\n",
      "         [4.1413e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0529],\n",
      "         [ 9.2253],\n",
      "         [-0.0192]]], device='cuda:0')\n",
      "tensor([[[ 1.0659e+00],\n",
      "         [ 9.2228e+00],\n",
      "         [-1.8116e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0243],\n",
      "         [ 9.2404],\n",
      "         [-0.0115]]], device='cuda:0')\n",
      "tensor([[[ 1.1745e+00],\n",
      "         [ 9.2023e+00],\n",
      "         [-7.0801e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0217],\n",
      "         [ 9.2319],\n",
      "         [-0.0300]]], device='cuda:0')\n",
      "tensor([[[ 1.0693],\n",
      "         [ 9.2272],\n",
      "         [-0.0415]]], device='cuda:0')\n",
      "tensor([[[1.0828e+00],\n",
      "         [9.2245e+00],\n",
      "         [6.4865e-03]]], device='cuda:0')\n",
      "tensor([[[1.1079],\n",
      "         [9.1882],\n",
      "         [0.1848]]], device='cuda:0')\n",
      "tensor([[[1.0560],\n",
      "         [9.2285],\n",
      "         [0.0489]]], device='cuda:0')\n",
      "tensor([[[ 1.0915],\n",
      "         [ 9.2235],\n",
      "         [-0.0526]]], device='cuda:0')\n",
      "tensor([[[1.0495],\n",
      "         [9.1933],\n",
      "         [0.0736]]], device='cuda:0')\n",
      "tensor([[[ 1.0491],\n",
      "         [ 9.2257],\n",
      "         [-0.0262]]], device='cuda:0')\n",
      "tensor([[[1.0474e+00],\n",
      "         [9.2441e+00],\n",
      "         [3.4421e-03]]], device='cuda:0')\n",
      "tensor([[[1.0856],\n",
      "         [9.2234],\n",
      "         [0.0314]]], device='cuda:0')\n",
      "tensor([[[ 1.0311],\n",
      "         [ 9.2313],\n",
      "         [-0.0239]]], device='cuda:0')\n",
      "tensor([[[ 1.0471],\n",
      "         [ 9.2539],\n",
      "         [-0.0129]]], device='cuda:0')\n",
      "tensor([[[ 1.0537],\n",
      "         [ 9.2301],\n",
      "         [-0.0095]]], device='cuda:0')\n",
      "tensor([[[ 1.0374],\n",
      "         [ 9.2314],\n",
      "         [-0.0107]]], device='cuda:0')\n",
      "tensor([[[ 1.0458],\n",
      "         [ 9.2195],\n",
      "         [-0.0349]]], device='cuda:0')\n",
      "tensor([[[ 1.0187],\n",
      "         [ 9.2062],\n",
      "         [-0.0187]]], device='cuda:0')\n",
      "tensor([[[ 1.1714],\n",
      "         [ 9.1897],\n",
      "         [-0.0120]]], device='cuda:0')\n",
      "tensor([[[1.0429e+00],\n",
      "         [9.2235e+00],\n",
      "         [5.4651e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0746],\n",
      "         [ 9.1979],\n",
      "         [-0.0352]]], device='cuda:0')\n",
      "tensor([[[1.0449],\n",
      "         [9.2077],\n",
      "         [0.0652]]], device='cuda:0')\n",
      "tensor([[[1.0533e+00],\n",
      "         [9.2211e+00],\n",
      "         [2.5241e-04]]], device='cuda:0')\n",
      "tensor([[[ 1.0648],\n",
      "         [ 9.2424],\n",
      "         [-0.0344]]], device='cuda:0')\n",
      "tensor([[[1.0806e+00],\n",
      "         [9.2240e+00],\n",
      "         [4.9505e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0575e+00],\n",
      "         [ 9.2219e+00],\n",
      "         [-2.7063e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0580e+00],\n",
      "         [ 9.2215e+00],\n",
      "         [-7.4293e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0590],\n",
      "         [ 9.2184],\n",
      "         [-0.0466]]], device='cuda:0')\n",
      "tensor([[[ 1.0289],\n",
      "         [ 9.2322],\n",
      "         [-0.0102]]], device='cuda:0')\n",
      "tensor([[[ 1.1579e+00],\n",
      "         [ 9.2099e+00],\n",
      "         [-3.0620e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0418],\n",
      "         [ 1.0349],\n",
      "         [-0.0107]]], device='cuda:0')\n",
      "tensor([[[ 1.0324],\n",
      "         [ 9.2505],\n",
      "         [-0.0106]]], device='cuda:0')\n",
      "tensor([[[ 1.0171],\n",
      "         [ 9.2333],\n",
      "         [-0.0222]]], device='cuda:0')\n",
      "tensor([[[ 1.0316],\n",
      "         [ 9.2095],\n",
      "         [-0.0143]]], device='cuda:0')\n",
      "tensor([[[ 1.0614],\n",
      "         [ 9.2349],\n",
      "         [-0.0312]]], device='cuda:0')\n",
      "tensor([[[ 1.0649],\n",
      "         [ 9.2431],\n",
      "         [-0.0348]]], device='cuda:0')\n",
      "tensor([[[1.0533e+00],\n",
      "         [9.1993e+00],\n",
      "         [4.9389e-04]]], device='cuda:0')\n",
      "tensor([[[ 1.0602],\n",
      "         [ 9.2187],\n",
      "         [-0.0202]]], device='cuda:0')\n",
      "tensor([[[ 1.0549],\n",
      "         [ 9.2352],\n",
      "         [-0.0225]]], device='cuda:0')\n",
      "tensor([[[ 1.0565],\n",
      "         [ 9.2618],\n",
      "         [-0.0227]]], device='cuda:0')\n",
      "tensor([[[ 1.0529],\n",
      "         [ 9.2268],\n",
      "         [-0.0159]]], device='cuda:0')\n",
      "tensor([[[ 1.0511],\n",
      "         [ 9.2272],\n",
      "         [-0.0296]]], device='cuda:0')\n",
      "tensor([[[ 1.0622],\n",
      "         [ 9.2181],\n",
      "         [-0.0632]]], device='cuda:0')\n",
      "tensor([[[ 1.0200],\n",
      "         [ 9.2113],\n",
      "         [-0.0290]]], device='cuda:0')\n",
      "tensor([[[ 1.0698],\n",
      "         [ 9.2638],\n",
      "         [-0.0410]]], device='cuda:0')\n",
      "tensor([[[ 1.0523],\n",
      "         [ 9.2626],\n",
      "         [-0.0294]]], device='cuda:0')\n",
      "tensor([[[1.0727],\n",
      "         [9.2288],\n",
      "         [0.0482]]], device='cuda:0')\n",
      "tensor([[[ 1.0199],\n",
      "         [ 9.2176],\n",
      "         [-0.0175]]], device='cuda:0')\n",
      "tensor([[[ 1.0576],\n",
      "         [ 9.2109],\n",
      "         [-0.0223]]], device='cuda:0')\n",
      "tensor([[[ 1.0217],\n",
      "         [ 9.2265],\n",
      "         [-0.0252]]], device='cuda:0')\n",
      "tensor([[[ 1.0581],\n",
      "         [ 9.2519],\n",
      "         [-0.0193]]], device='cuda:0')\n",
      "tensor([[[ 1.0653],\n",
      "         [ 1.0270],\n",
      "         [-0.0120]]], device='cuda:0')\n",
      "tensor([[[ 1.0691],\n",
      "         [ 9.2216],\n",
      "         [-0.0353]]], device='cuda:0')\n",
      "tensor([[[ 1.0326],\n",
      "         [ 9.2368],\n",
      "         [-0.0302]]], device='cuda:0')\n",
      "tensor([[[ 1.0580e+00],\n",
      "         [ 9.2340e+00],\n",
      "         [-3.9610e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0734],\n",
      "         [ 9.2395],\n",
      "         [-0.0125]]], device='cuda:0')\n",
      "tensor([[[ 1.0735],\n",
      "         [ 9.2244],\n",
      "         [-0.0104]]], device='cuda:0')\n",
      "tensor([[[ 1.0384],\n",
      "         [ 9.2389],\n",
      "         [-0.0436]]], device='cuda:0')\n",
      "tensor([[[ 1.0559],\n",
      "         [ 9.2285],\n",
      "         [-0.0268]]], device='cuda:0')\n",
      "tensor([[[ 1.0508],\n",
      "         [ 9.2368],\n",
      "         [-0.0155]]], device='cuda:0')\n",
      "tensor([[[ 1.0201],\n",
      "         [ 9.2233],\n",
      "         [-0.0247]]], device='cuda:0')\n",
      "tensor([[[ 1.0289],\n",
      "         [ 9.2254],\n",
      "         [-0.0136]]], device='cuda:0')\n",
      "tensor([[[ 1.0238],\n",
      "         [ 9.2427],\n",
      "         [-0.0529]]], device='cuda:0')\n",
      "tensor([[[1.0652],\n",
      "         [9.2427],\n",
      "         [0.0411]]], device='cuda:0')\n",
      "tensor([[[1.0573],\n",
      "         [9.2094],\n",
      "         [0.0217]]], device='cuda:0')\n",
      "tensor([[[ 1.0236],\n",
      "         [ 9.2230],\n",
      "         [-0.0358]]], device='cuda:0')\n",
      "tensor([[[1.0698],\n",
      "         [9.2362],\n",
      "         [0.0166]]], device='cuda:0')\n",
      "tensor([[[ 1.0195],\n",
      "         [ 9.2386],\n",
      "         [-0.0252]]], device='cuda:0')\n",
      "tensor([[[ 1.0518],\n",
      "         [ 9.2513],\n",
      "         [-0.0159]]], device='cuda:0')\n",
      "tensor([[[1.0581],\n",
      "         [1.1138],\n",
      "         [0.0760]]], device='cuda:0')\n",
      "tensor([[[ 1.0317],\n",
      "         [ 9.2338],\n",
      "         [-0.0103]]], device='cuda:0')\n",
      "tensor([[[ 9.8419e-01],\n",
      "         [ 9.2301e+00],\n",
      "         [-2.7674e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0588e+00],\n",
      "         [ 9.2351e+00],\n",
      "         [-3.2477e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0645],\n",
      "         [ 9.2261],\n",
      "         [-0.0310]]], device='cuda:0')\n",
      "tensor([[[ 1.0519],\n",
      "         [ 9.2476],\n",
      "         [-0.0185]]], device='cuda:0')\n",
      "tensor([[[ 1.0476],\n",
      "         [ 9.2330],\n",
      "         [-0.0471]]], device='cuda:0')\n",
      "tensor([[[ 1.0526],\n",
      "         [ 9.2205],\n",
      "         [-0.0370]]], device='cuda:0')\n",
      "tensor([[[ 1.0343],\n",
      "         [ 9.2420],\n",
      "         [-0.0179]]], device='cuda:0')\n",
      "tensor([[[ 1.0598],\n",
      "         [ 9.2334],\n",
      "         [-0.0195]]], device='cuda:0')\n",
      "tensor([[[1.0449],\n",
      "         [9.2227],\n",
      "         [0.0586]]], device='cuda:0')\n",
      "tensor([[[ 1.0920],\n",
      "         [ 9.2343],\n",
      "         [-0.0523]]], device='cuda:0')\n",
      "tensor([[[ 1.0550],\n",
      "         [ 9.2364],\n",
      "         [-0.0202]]], device='cuda:0')\n",
      "tensor([[[1.0038e+00],\n",
      "         [9.2101e+00],\n",
      "         [2.9507e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0664],\n",
      "         [ 9.2225],\n",
      "         [-0.0357]]], device='cuda:0')\n",
      "tensor([[[1.0391],\n",
      "         [1.0806],\n",
      "         [0.0323]]], device='cuda:0')\n",
      "tensor([[[ 1.0287],\n",
      "         [ 9.2291],\n",
      "         [-0.0432]]], device='cuda:0')\n",
      "tensor([[[ 1.0527],\n",
      "         [ 9.2374],\n",
      "         [-0.0169]]], device='cuda:0')\n",
      "tensor([[[ 1.0751e+00],\n",
      "         [ 9.2148e+00],\n",
      "         [-3.6402e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0512e+00],\n",
      "         [ 9.2370e+00],\n",
      "         [-8.0943e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0454],\n",
      "         [ 9.2463],\n",
      "         [-0.0462]]], device='cuda:0')\n",
      "tensor([[[1.0726],\n",
      "         [9.2091],\n",
      "         [0.0509]]], device='cuda:0')\n",
      "tensor([[[ 1.0277],\n",
      "         [ 1.0271],\n",
      "         [-0.0155]]], device='cuda:0')\n",
      "tensor([[[1.0471],\n",
      "         [9.2430],\n",
      "         [0.0101]]], device='cuda:0')\n",
      "tensor([[[1.0580],\n",
      "         [9.2089],\n",
      "         [0.0218]]], device='cuda:0')\n",
      "tensor([[[ 1.0614],\n",
      "         [ 9.2450],\n",
      "         [-0.0194]]], device='cuda:0')\n",
      "tensor([[[ 1.0982],\n",
      "         [ 9.2117],\n",
      "         [-0.0488]]], device='cuda:0')\n",
      "tensor([[[ 1.0297],\n",
      "         [ 9.2207],\n",
      "         [-0.0275]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0720e+00],\n",
      "         [ 9.2278e+00],\n",
      "         [-9.2146e-03]]], device='cuda:0')\n",
      "tensor([[[1.0692],\n",
      "         [9.2549],\n",
      "         [0.0165]]], device='cuda:0')\n",
      "tensor([[[ 1.0718e+00],\n",
      "         [ 9.1869e+00],\n",
      "         [-7.0416e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0580],\n",
      "         [ 9.2449],\n",
      "         [-0.0140]]], device='cuda:0')\n",
      "tensor([[[ 0.9865],\n",
      "         [ 9.2539],\n",
      "         [-0.0400]]], device='cuda:0')\n",
      "tensor([[[1.0462],\n",
      "         [9.2027],\n",
      "         [0.0555]]], device='cuda:0')\n",
      "tensor([[[1.0522e+00],\n",
      "         [9.2304e+00],\n",
      "         [1.2599e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0447],\n",
      "         [ 9.2398],\n",
      "         [-0.0129]]], device='cuda:0')\n",
      "tensor([[[ 1.0431],\n",
      "         [ 9.2349],\n",
      "         [-0.0127]]], device='cuda:0')\n",
      "tensor([[[ 1.0291],\n",
      "         [ 9.2222],\n",
      "         [-0.0260]]], device='cuda:0')\n",
      "tensor([[[ 1.0627e+00],\n",
      "         [ 9.2277e+00],\n",
      "         [-8.8086e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0480],\n",
      "         [ 9.2636],\n",
      "         [-0.0117]]], device='cuda:0')\n",
      "tensor([[[ 1.0181],\n",
      "         [ 9.2278],\n",
      "         [-0.0345]]], device='cuda:0')\n",
      "tensor([[[ 1.0615],\n",
      "         [ 9.2302],\n",
      "         [-0.0129]]], device='cuda:0')\n",
      "tensor([[[ 1.0296],\n",
      "         [ 9.2138],\n",
      "         [-0.0103]]], device='cuda:0')\n",
      "tensor([[[ 1.0273],\n",
      "         [ 9.2378],\n",
      "         [-0.0791]]], device='cuda:0')\n",
      "tensor([[[1.0487],\n",
      "         [9.1943],\n",
      "         [0.0637]]], device='cuda:0')\n",
      "tensor([[[ 1.0606e+00],\n",
      "         [ 9.1935e+00],\n",
      "         [-3.9073e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0534],\n",
      "         [ 9.2495],\n",
      "         [-0.0365]]], device='cuda:0')\n",
      "tensor([[[ 1.0659e+00],\n",
      "         [ 9.2228e+00],\n",
      "         [-1.8116e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0540],\n",
      "         [ 9.2444],\n",
      "         [-0.0312]]], device='cuda:0')\n",
      "tensor([[[1.0474],\n",
      "         [9.2254],\n",
      "         [0.0661]]], device='cuda:0')\n",
      "tensor([[[ 1.0409e+00],\n",
      "         [ 9.2292e+00],\n",
      "         [-8.1687e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0486],\n",
      "         [ 9.2627],\n",
      "         [-0.0227]]], device='cuda:0')\n",
      "tensor([[[1.0689e+00],\n",
      "         [9.2446e+00],\n",
      "         [4.4331e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0279],\n",
      "         [ 9.2326],\n",
      "         [-0.0136]]], device='cuda:0')\n",
      "tensor([[[1.0472],\n",
      "         [9.2608],\n",
      "         [0.0114]]], device='cuda:0')\n",
      "tensor([[[ 0.9840],\n",
      "         [ 9.2599],\n",
      "         [-0.0412]]], device='cuda:0')\n",
      "tensor([[[1.0440],\n",
      "         [9.2087],\n",
      "         [0.0690]]], device='cuda:0')\n",
      "tensor([[[ 1.0449],\n",
      "         [ 9.2346],\n",
      "         [-0.0471]]], device='cuda:0')\n",
      "tensor([[[ 1.0006e+00],\n",
      "         [ 9.2124e+00],\n",
      "         [-4.0640e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0543],\n",
      "         [ 9.2407],\n",
      "         [-0.0093]]], device='cuda:0')\n",
      "tensor([[[ 1.0626],\n",
      "         [ 9.2356],\n",
      "         [-0.0203]]], device='cuda:0')\n",
      "tensor([[[ 1.0622],\n",
      "         [ 9.2270],\n",
      "         [-0.0129]]], device='cuda:0')\n",
      "tensor([[[1.0648],\n",
      "         [9.2214],\n",
      "         [0.0401]]], device='cuda:0')\n",
      "tensor([[[1.0633],\n",
      "         [9.2060],\n",
      "         [0.1199]]], device='cuda:0')\n",
      "tensor([[[ 1.0491],\n",
      "         [ 9.2032],\n",
      "         [-0.0106]]], device='cuda:0')\n",
      "tensor([[[ 1.0203],\n",
      "         [ 9.2301],\n",
      "         [-0.0118]]], device='cuda:0')\n",
      "tensor([[[ 1.0607],\n",
      "         [ 9.2275],\n",
      "         [-0.0612]]], device='cuda:0')\n",
      "tensor([[[1.0456],\n",
      "         [9.2387],\n",
      "         [0.0101]]], device='cuda:0')\n",
      "tensor([[[ 1.0170],\n",
      "         [ 9.2338],\n",
      "         [-0.0228]]], device='cuda:0')\n",
      "tensor([[[ 1.0580e+00],\n",
      "         [ 9.2380e+00],\n",
      "         [-6.6361e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0512],\n",
      "         [ 9.2258],\n",
      "         [-0.0476]]], device='cuda:0')\n",
      "tensor([[[1.0619],\n",
      "         [9.2002],\n",
      "         [0.0314]]], device='cuda:0')\n",
      "tensor([[[ 1.0546],\n",
      "         [ 9.2431],\n",
      "         [-0.0201]]], device='cuda:0')\n",
      "tensor([[[ 1.0586],\n",
      "         [ 9.2061],\n",
      "         [-0.0625]]], device='cuda:0')\n",
      "tensor([[[ 1.0331],\n",
      "         [ 9.2542],\n",
      "         [-0.0192]]], device='cuda:0')\n",
      "tensor([[[ 1.0559],\n",
      "         [ 9.2209],\n",
      "         [-0.0269]]], device='cuda:0')\n",
      "tensor([[[1.0464e+00],\n",
      "         [9.2317e+00],\n",
      "         [8.6070e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0587e+00],\n",
      "         [ 9.2368e+00],\n",
      "         [-7.7286e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0733],\n",
      "         [ 9.2146],\n",
      "         [-0.0126]]], device='cuda:0')\n",
      "tensor([[[ 1.0533],\n",
      "         [ 9.2477],\n",
      "         [-0.0189]]], device='cuda:0')\n",
      "tensor([[[ 1.0503],\n",
      "         [ 9.2379],\n",
      "         [-0.0203]]], device='cuda:0')\n",
      "tensor([[[ 1.0701e+00],\n",
      "         [ 9.2280e+00],\n",
      "         [-7.3085e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0605],\n",
      "         [ 9.2209],\n",
      "         [-0.0203]]], device='cuda:0')\n",
      "tensor([[[ 1.0690],\n",
      "         [ 9.2167],\n",
      "         [-0.0414]]], device='cuda:0')\n",
      "tensor([[[1.0491e+00],\n",
      "         [9.2255e+00],\n",
      "         [2.8888e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0940],\n",
      "         [ 9.2143],\n",
      "         [-0.0484]]], device='cuda:0')\n",
      "tensor([[[ 1.0488],\n",
      "         [ 9.2402],\n",
      "         [-0.0199]]], device='cuda:0')\n",
      "tensor([[[ 1.0236],\n",
      "         [ 9.2230],\n",
      "         [-0.0358]]], device='cuda:0')\n",
      "tensor([[[ 1.0541],\n",
      "         [ 9.2489],\n",
      "         [-0.0258]]], device='cuda:0')\n",
      "tensor([[[ 1.0437],\n",
      "         [ 9.2185],\n",
      "         [-0.0105]]], device='cuda:0')\n",
      "tensor([[[ 1.0484],\n",
      "         [ 9.2407],\n",
      "         [-0.0116]]], device='cuda:0')\n",
      "tensor([[[ 1.0182],\n",
      "         [ 9.2316],\n",
      "         [-0.0330]]], device='cuda:0')\n",
      "tensor([[[ 1.0672e+00],\n",
      "         [ 9.2350e+00],\n",
      "         [-7.1927e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0519],\n",
      "         [ 9.2218],\n",
      "         [-0.0138]]], device='cuda:0')\n",
      "tensor([[[ 1.0206],\n",
      "         [ 9.2255],\n",
      "         [-0.0217]]], device='cuda:0')\n",
      "tensor([[[ 1.0475],\n",
      "         [ 9.2279],\n",
      "         [-0.0472]]], device='cuda:0')\n",
      "tensor([[[ 0.9865],\n",
      "         [ 9.2539],\n",
      "         [-0.0400]]], device='cuda:0')\n",
      "tensor([[[ 1.0497],\n",
      "         [ 9.2248],\n",
      "         [-0.0274]]], device='cuda:0')\n",
      "tensor([[[ 1.0468],\n",
      "         [ 9.2523],\n",
      "         [-0.0222]]], device='cuda:0')\n",
      "tensor([[[ 1.0303],\n",
      "         [ 9.2549],\n",
      "         [-0.0101]]], device='cuda:0')\n",
      "tensor([[[ 1.0458e+00],\n",
      "         [ 9.2504e+00],\n",
      "         [-8.8483e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0189],\n",
      "         [ 9.2197],\n",
      "         [-0.0863]]], device='cuda:0')\n",
      "tensor([[[1.0805e+00],\n",
      "         [9.2344e+00],\n",
      "         [4.2086e-03]]], device='cuda:0')\n",
      "tensor([[[1.0651],\n",
      "         [9.2181],\n",
      "         [0.1153]]], device='cuda:0')\n",
      "tensor([[[1.0507],\n",
      "         [9.1705],\n",
      "         [0.0741]]], device='cuda:0')\n",
      "tensor([[[1.0681],\n",
      "         [9.2525],\n",
      "         [0.0175]]], device='cuda:0')\n",
      "tensor([[[ 1.0437],\n",
      "         [ 9.2254],\n",
      "         [-0.0474]]], device='cuda:0')\n",
      "tensor([[[ 1.0400e+00],\n",
      "         [ 9.2336e+00],\n",
      "         [-5.0559e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0280],\n",
      "         [ 9.2530],\n",
      "         [-0.0545]]], device='cuda:0')\n",
      "tensor([[[1.0593],\n",
      "         [9.1954],\n",
      "         [0.0230]]], device='cuda:0')\n",
      "tensor([[[1.0868],\n",
      "         [9.2081],\n",
      "         [0.0316]]], device='cuda:0')\n",
      "tensor([[[ 1.0176],\n",
      "         [ 9.2240],\n",
      "         [-0.0275]]], device='cuda:0')\n",
      "tensor([[[ 1.0454],\n",
      "         [ 9.2191],\n",
      "         [-0.0130]]], device='cuda:0')\n",
      "tensor([[[ 1.0555],\n",
      "         [ 9.2470],\n",
      "         [-0.0368]]], device='cuda:0')\n",
      "tensor([[[ 1.0542e+00],\n",
      "         [ 9.2072e+00],\n",
      "         [-5.2422e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0732],\n",
      "         [ 1.0192],\n",
      "         [-0.0172]]], device='cuda:0')\n",
      "tensor([[[ 1.0011e+00],\n",
      "         [ 9.2228e+00],\n",
      "         [-2.0496e-03]]], device='cuda:0')\n",
      "tensor([[[1.0526e+00],\n",
      "         [9.2489e+00],\n",
      "         [1.4238e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0163],\n",
      "         [ 9.2234],\n",
      "         [-0.0281]]], device='cuda:0')\n",
      "tensor([[[ 1.0579],\n",
      "         [ 9.2575],\n",
      "         [-0.0310]]], device='cuda:0')\n",
      "tensor([[[1.0626],\n",
      "         [9.1895],\n",
      "         [0.1108]]], device='cuda:0')\n",
      "tensor([[[1.0529e+00],\n",
      "         [9.2396e+00],\n",
      "         [1.0526e-03]]], device='cuda:0')\n",
      "tensor([[[1.0702],\n",
      "         [9.1942],\n",
      "         [0.0441]]], device='cuda:0')\n",
      "tensor([[[1.0494e+00],\n",
      "         [9.2482e+00],\n",
      "         [3.1336e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0662e+00],\n",
      "         [ 9.2363e+00],\n",
      "         [-7.4877e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0557e+00],\n",
      "         [ 9.2402e+00],\n",
      "         [-3.7055e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0550],\n",
      "         [ 9.2442],\n",
      "         [-0.0201]]], device='cuda:0')\n",
      "tensor([[[ 1.0436],\n",
      "         [ 9.2287],\n",
      "         [-0.0104]]], device='cuda:0')\n",
      "tensor([[[ 1.0186],\n",
      "         [ 9.2345],\n",
      "         [-0.0737]]], device='cuda:0')\n",
      "tensor([[[ 1.0343],\n",
      "         [ 9.2316],\n",
      "         [-0.0135]]], device='cuda:0')\n",
      "tensor([[[1.0454],\n",
      "         [9.2559],\n",
      "         [0.0122]]], device='cuda:0')\n",
      "tensor([[[ 1.0555],\n",
      "         [ 9.2181],\n",
      "         [-0.0127]]], device='cuda:0')\n",
      "tensor([[[ 1.0628],\n",
      "         [ 9.2191],\n",
      "         [-0.0631]]], device='cuda:0')\n",
      "tensor([[[1.0487e+00],\n",
      "         [9.2273e+00],\n",
      "         [3.6731e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0211],\n",
      "         [ 9.2225],\n",
      "         [-0.0251]]], device='cuda:0')\n",
      "tensor([[[ 1.0556],\n",
      "         [ 9.2253],\n",
      "         [-0.0603]]], device='cuda:0')\n",
      "tensor([[[ 1.0477],\n",
      "         [ 9.2179],\n",
      "         [-0.0478]]], device='cuda:0')\n",
      "tensor([[[ 1.0684],\n",
      "         [ 9.2298],\n",
      "         [-0.0672]]], device='cuda:0')\n",
      "tensor([[[ 1.0498],\n",
      "         [ 9.2380],\n",
      "         [-0.0262]]], device='cuda:0')\n",
      "tensor([[[ 1.0427e+00],\n",
      "         [ 9.2251e+00],\n",
      "         [-4.6250e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0507],\n",
      "         [ 9.2409],\n",
      "         [-0.0125]]], device='cuda:0')\n",
      "tensor([[[1.0505e+00],\n",
      "         [9.2098e+00],\n",
      "         [2.3982e-03]]], device='cuda:0')\n",
      "tensor([[[1.0641],\n",
      "         [9.2241],\n",
      "         [0.0332]]], device='cuda:0')\n",
      "tensor([[[ 1.0719],\n",
      "         [ 9.2236],\n",
      "         [-0.0352]]], device='cuda:0')\n",
      "tensor([[[ 1.0279],\n",
      "         [ 9.2326],\n",
      "         [-0.0136]]], device='cuda:0')\n",
      "tensor([[[ 1.0553],\n",
      "         [ 9.2136],\n",
      "         [-0.0096]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0426],\n",
      "         [ 9.2225],\n",
      "         [-0.0098]]], device='cuda:0')\n",
      "tensor([[[ 1.0528],\n",
      "         [ 9.2344],\n",
      "         [-0.0141]]], device='cuda:0')\n",
      "tensor([[[1.0507],\n",
      "         [9.1705],\n",
      "         [0.0741]]], device='cuda:0')\n",
      "tensor([[[ 1.0286],\n",
      "         [ 9.2492],\n",
      "         [-0.0385]]], device='cuda:0')\n",
      "tensor([[[ 1.0559],\n",
      "         [ 9.2317],\n",
      "         [-0.0198]]], device='cuda:0')\n",
      "tensor([[[ 1.0395],\n",
      "         [ 9.2094],\n",
      "         [-0.0116]]], device='cuda:0')\n",
      "tensor([[[ 1.0641],\n",
      "         [ 9.2263],\n",
      "         [-0.0124]]], device='cuda:0')\n",
      "tensor([[[ 1.0510],\n",
      "         [ 9.2322],\n",
      "         [-0.0201]]], device='cuda:0')\n",
      "tensor([[[ 1.0455],\n",
      "         [ 9.2362],\n",
      "         [-0.0341]]], device='cuda:0')\n",
      "tensor([[[ 1.0445],\n",
      "         [ 9.2312],\n",
      "         [-0.0470]]], device='cuda:0')\n",
      "tensor([[[0.9854],\n",
      "         [9.1972],\n",
      "         [0.0632]]], device='cuda:0')\n",
      "tensor([[[ 1.0495],\n",
      "         [ 9.2610],\n",
      "         [-0.0286]]], device='cuda:0')\n",
      "tensor([[[ 1.0214e+00],\n",
      "         [ 9.2450e+00],\n",
      "         [-7.5905e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0447],\n",
      "         [ 9.2398],\n",
      "         [-0.0129]]], device='cuda:0')\n",
      "tensor([[[1.0847],\n",
      "         [9.2205],\n",
      "         [0.0309]]], device='cuda:0')\n",
      "tensor([[[ 1.0734],\n",
      "         [ 9.2395],\n",
      "         [-0.0125]]], device='cuda:0')\n",
      "tensor([[[ 1.0316],\n",
      "         [ 9.2073],\n",
      "         [-0.0139]]], device='cuda:0')\n",
      "tensor([[[ 1.0402e+00],\n",
      "         [ 9.2304e+00],\n",
      "         [-8.7194e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0612],\n",
      "         [ 9.2505],\n",
      "         [-0.0196]]], device='cuda:0')\n",
      "tensor([[[ 1.0319],\n",
      "         [ 9.2558],\n",
      "         [-0.0298]]], device='cuda:0')\n",
      "tensor([[[ 1.0523],\n",
      "         [ 9.2291],\n",
      "         [-0.0197]]], device='cuda:0')\n",
      "tensor([[[ 1.0529],\n",
      "         [ 9.2386],\n",
      "         [-0.0156]]], device='cuda:0')\n",
      "tensor([[[ 1.1742e+00],\n",
      "         [ 9.1966e+00],\n",
      "         [-2.8715e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0512],\n",
      "         [ 9.2452],\n",
      "         [-0.0298]]], device='cuda:0')\n",
      "tensor([[[1.0647e+00],\n",
      "         [9.2360e+00],\n",
      "         [3.3257e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0521],\n",
      "         [ 9.2129],\n",
      "         [-0.0344]]], device='cuda:0')\n",
      "tensor([[[ 1.0334],\n",
      "         [ 9.2483],\n",
      "         [-0.0106]]], device='cuda:0')\n",
      "tensor([[[ 1.0332],\n",
      "         [ 9.2553],\n",
      "         [-0.0297]]], device='cuda:0')\n",
      "tensor([[[ 1.0494],\n",
      "         [ 9.2528],\n",
      "         [-0.0118]]], device='cuda:0')\n",
      "tensor([[[ 1.0290],\n",
      "         [ 9.2406],\n",
      "         [-0.0546]]], device='cuda:0')\n",
      "tensor([[[ 1.0549],\n",
      "         [ 9.2075],\n",
      "         [-0.0113]]], device='cuda:0')\n",
      "tensor([[[1.0693],\n",
      "         [9.2144],\n",
      "         [0.0167]]], device='cuda:0')\n",
      "tensor([[[ 1.0679],\n",
      "         [ 9.2388],\n",
      "         [-0.0108]]], device='cuda:0')\n",
      "tensor([[[ 1.0526],\n",
      "         [ 9.2215],\n",
      "         [-0.0207]]], device='cuda:0')\n",
      "tensor([[[ 1.0445],\n",
      "         [ 9.2312],\n",
      "         [-0.0470]]], device='cuda:0')\n",
      "tensor([[[ 1.0473],\n",
      "         [ 9.2609],\n",
      "         [-0.0115]]], device='cuda:0')\n",
      "tensor([[[ 1.0553],\n",
      "         [ 9.2394],\n",
      "         [-0.0143]]], device='cuda:0')\n",
      "tensor([[[ 1.0526],\n",
      "         [ 9.2485],\n",
      "         [-0.0195]]], device='cuda:0')\n",
      "tensor([[[ 1.0581],\n",
      "         [ 9.2200],\n",
      "         [-0.0206]]], device='cuda:0')\n",
      "tensor([[[ 1.0464],\n",
      "         [ 9.2407],\n",
      "         [-0.0142]]], device='cuda:0')\n",
      "tensor([[[ 1.0475],\n",
      "         [ 9.2180],\n",
      "         [-0.0342]]], device='cuda:0')\n",
      "tensor([[[1.0663],\n",
      "         [9.2273],\n",
      "         [0.0152]]], device='cuda:0')\n",
      "tensor([[[ 1.0283],\n",
      "         [ 9.2471],\n",
      "         [-0.0179]]], device='cuda:0')\n",
      "tensor([[[ 1.0531],\n",
      "         [ 9.2169],\n",
      "         [-0.0093]]], device='cuda:0')\n",
      "tensor([[[ 1.0182],\n",
      "         [ 9.2380],\n",
      "         [-0.0851]]], device='cuda:0')\n",
      "tensor([[[ 1.0523],\n",
      "         [ 9.2526],\n",
      "         [-0.0223]]], device='cuda:0')\n",
      "tensor([[[ 1.0472],\n",
      "         [ 9.2395],\n",
      "         [-0.0144]]], device='cuda:0')\n",
      "tensor([[[ 1.0590e+00],\n",
      "         [ 9.2200e+00],\n",
      "         [-8.0467e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0591e+00],\n",
      "         [ 9.2274e+00],\n",
      "         [-6.6509e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0873],\n",
      "         [ 9.2404],\n",
      "         [-0.0496]]], device='cuda:0')\n",
      "tensor([[[ 1.0559],\n",
      "         [ 9.2488],\n",
      "         [-0.0461]]], device='cuda:0')\n",
      "tensor([[[ 1.0366],\n",
      "         [ 9.2686],\n",
      "         [-0.0120]]], device='cuda:0')\n",
      "tensor([[[1.1437],\n",
      "         [1.0933],\n",
      "         [0.0395]]], device='cuda:0')\n",
      "tensor([[[1.0500e+00],\n",
      "         [9.2201e+00],\n",
      "         [9.9978e-04]]], device='cuda:0')\n",
      "tensor([[[ 1.0223],\n",
      "         [ 9.2275],\n",
      "         [-0.0180]]], device='cuda:0')\n",
      "tensor([[[ 1.0681],\n",
      "         [ 9.2511],\n",
      "         [-0.0099]]], device='cuda:0')\n",
      "tensor([[[1.0496],\n",
      "         [9.2142],\n",
      "         [0.0777]]], device='cuda:0')\n",
      "tensor([[[ 1.0428],\n",
      "         [ 9.2289],\n",
      "         [-0.0096]]], device='cuda:0')\n",
      "tensor([[[ 1.0289],\n",
      "         [ 9.2222],\n",
      "         [-0.0300]]], device='cuda:0')\n",
      "tensor([[[ 1.0582],\n",
      "         [ 9.2208],\n",
      "         [-0.0204]]], device='cuda:0')\n",
      "tensor([[[ 1.0487],\n",
      "         [ 9.2392],\n",
      "         [-0.0121]]], device='cuda:0')\n",
      "tensor([[[ 1.0218],\n",
      "         [ 9.2184],\n",
      "         [-0.0253]]], device='cuda:0')\n",
      "tensor([[[1.0504e+00],\n",
      "         [9.2313e+00],\n",
      "         [7.4785e-04]]], device='cuda:0')\n",
      "tensor([[[ 1.0434],\n",
      "         [ 9.2270],\n",
      "         [-0.0139]]], device='cuda:0')\n",
      "tensor([[[ 1.0510],\n",
      "         [ 9.2381],\n",
      "         [-0.0203]]], device='cuda:0')\n",
      "tensor([[[1.0471],\n",
      "         [9.2440],\n",
      "         [0.0123]]], device='cuda:0')\n",
      "tensor([[[ 1.1756],\n",
      "         [ 9.1793],\n",
      "         [-0.0143]]], device='cuda:0')\n",
      "tensor([[[ 1.0567],\n",
      "         [ 9.1972],\n",
      "         [-0.0202]]], device='cuda:0')\n",
      "tensor([[[1.0525],\n",
      "         [9.2086],\n",
      "         [0.0790]]], device='cuda:0')\n",
      "tensor([[[ 1.0530],\n",
      "         [ 9.2467],\n",
      "         [-0.0374]]], device='cuda:0')\n",
      "tensor([[[ 1.0614e+00],\n",
      "         [ 9.2094e+00],\n",
      "         [-7.5476e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0318],\n",
      "         [ 9.2169],\n",
      "         [-0.0100]]], device='cuda:0')\n",
      "tensor([[[ 1.0282],\n",
      "         [ 9.2349],\n",
      "         [-0.0102]]], device='cuda:0')\n",
      "tensor([[[ 1.0457],\n",
      "         [ 9.2340],\n",
      "         [-0.0109]]], device='cuda:0')\n",
      "tensor([[[ 1.0523],\n",
      "         [ 9.2279],\n",
      "         [-0.0159]]], device='cuda:0')\n",
      "tensor([[[ 1.0017e+00],\n",
      "         [ 9.1972e+00],\n",
      "         [-2.7907e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0688],\n",
      "         [ 9.2421],\n",
      "         [-0.0349]]], device='cuda:0')\n",
      "tensor([[[ 1.0542],\n",
      "         [ 9.2234],\n",
      "         [-0.0267]]], device='cuda:0')\n",
      "tensor([[[ 1.0447e+00],\n",
      "         [ 9.2335e+00],\n",
      "         [-7.2304e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0615],\n",
      "         [ 9.2213],\n",
      "         [-0.0311]]], device='cuda:0')\n",
      "tensor([[[ 1.0554],\n",
      "         [ 9.2390],\n",
      "         [-0.0369]]], device='cuda:0')\n",
      "tensor([[[ 1.0792],\n",
      "         [ 1.0107],\n",
      "         [-0.0408]]], device='cuda:0')\n",
      "tensor([[[ 1.0377],\n",
      "         [ 9.2452],\n",
      "         [-0.0110]]], device='cuda:0')\n",
      "tensor([[[ 1.0432],\n",
      "         [ 9.2300],\n",
      "         [-0.0104]]], device='cuda:0')\n",
      "tensor([[[ 1.0006e+00],\n",
      "         [ 9.2262e+00],\n",
      "         [-4.2659e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0320],\n",
      "         [ 9.2269],\n",
      "         [-0.0427]]], device='cuda:0')\n",
      "tensor([[[ 1.0512],\n",
      "         [ 9.2461],\n",
      "         [-0.0207]]], device='cuda:0')\n",
      "tensor([[[ 1.0238],\n",
      "         [ 9.2175],\n",
      "         [-0.0333]]], device='cuda:0')\n",
      "tensor([[[ 1.0458],\n",
      "         [ 9.2181],\n",
      "         [-0.0480]]], device='cuda:0')\n",
      "tensor([[[ 1.0300],\n",
      "         [ 9.2215],\n",
      "         [-0.0398]]], device='cuda:0')\n",
      "tensor([[[ 1.0615],\n",
      "         [ 9.2302],\n",
      "         [-0.0129]]], device='cuda:0')\n",
      "tensor([[[ 1.0314],\n",
      "         [ 9.2471],\n",
      "         [-0.0427]]], device='cuda:0')\n",
      "tensor([[[ 1.0500],\n",
      "         [ 9.2390],\n",
      "         [-0.0419]]], device='cuda:0')\n",
      "tensor([[[ 1.0458],\n",
      "         [ 9.2466],\n",
      "         [-0.0475]]], device='cuda:0')\n",
      "tensor([[[ 1.0701],\n",
      "         [ 9.2319],\n",
      "         [-0.0414]]], device='cuda:0')\n",
      "tensor([[[1.0448],\n",
      "         [9.2392],\n",
      "         [0.0105]]], device='cuda:0')\n",
      "tensor([[[ 1.0456],\n",
      "         [ 9.2315],\n",
      "         [-0.0336]]], device='cuda:0')\n",
      "tensor([[[1.1034],\n",
      "         [9.1997],\n",
      "         [0.1730]]], device='cuda:0')\n",
      "tensor([[[ 1.0510],\n",
      "         [ 9.2260],\n",
      "         [-0.0203]]], device='cuda:0')\n",
      "tensor([[[0.9943],\n",
      "         [9.2169],\n",
      "         [0.0786]]], device='cuda:0')\n",
      "tensor([[[ 1.0591],\n",
      "         [ 9.2288],\n",
      "         [-0.0189]]], device='cuda:0')\n",
      "tensor([[[0.9943],\n",
      "         [9.2169],\n",
      "         [0.0786]]], device='cuda:0')\n",
      "tensor([[[ 1.0547],\n",
      "         [ 9.2663],\n",
      "         [-0.0225]]], device='cuda:0')\n",
      "tensor([[[ 1.0578e+00],\n",
      "         [ 9.2191e+00],\n",
      "         [-4.7217e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0692],\n",
      "         [ 9.2343],\n",
      "         [-0.0104]]], device='cuda:0')\n",
      "tensor([[[ 1.0534],\n",
      "         [ 9.2196],\n",
      "         [-0.0171]]], device='cuda:0')\n",
      "tensor([[[ 1.0940],\n",
      "         [ 9.2236],\n",
      "         [-0.0480]]], device='cuda:0')\n",
      "tensor([[[ 1.0569],\n",
      "         [ 9.2274],\n",
      "         [-0.0138]]], device='cuda:0')\n",
      "tensor([[[ 1.0519],\n",
      "         [ 9.2173],\n",
      "         [-0.0262]]], device='cuda:0')\n",
      "tensor([[[1.0807e+00],\n",
      "         [9.2126e+00],\n",
      "         [5.6930e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0513],\n",
      "         [ 9.2138],\n",
      "         [-0.0172]]], device='cuda:0')\n",
      "tensor([[[ 1.0488e+00],\n",
      "         [ 9.2564e+00],\n",
      "         [-5.4927e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0591],\n",
      "         [ 9.2515],\n",
      "         [-0.0203]]], device='cuda:0')\n",
      "tensor([[[ 1.0595],\n",
      "         [ 9.2224],\n",
      "         [-0.0623]]], device='cuda:0')\n",
      "tensor([[[1.0646],\n",
      "         [9.2082],\n",
      "         [0.0398]]], device='cuda:0')\n",
      "tensor([[[ 1.0568],\n",
      "         [ 9.2263],\n",
      "         [-0.0217]]], device='cuda:0')\n",
      "tensor([[[ 1.0216],\n",
      "         [ 9.2446],\n",
      "         [-0.0730]]], device='cuda:0')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[ 1.0557],\n",
      "         [ 9.2345],\n",
      "         [-0.0140]]], device='cuda:0')\n",
      "tensor([[[ 1.0575],\n",
      "         [ 9.2251],\n",
      "         [-0.0309]]], device='cuda:0')\n",
      "tensor([[[1.0489e+00],\n",
      "         [9.2490e+00],\n",
      "         [2.7108e-03]]], device='cuda:0')\n",
      "tensor([[[1.0718],\n",
      "         [9.2169],\n",
      "         [0.0473]]], device='cuda:0')\n",
      "tensor([[[ 1.0562],\n",
      "         [ 9.2373],\n",
      "         [-0.0169]]], device='cuda:0')\n",
      "tensor([[[ 1.0593],\n",
      "         [ 9.1944],\n",
      "         [-0.0290]]], device='cuda:0')\n",
      "tensor([[[ 9.8493e-01],\n",
      "         [ 9.2216e+00],\n",
      "         [-3.5274e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0001],\n",
      "         [ 9.2229],\n",
      "         [-0.0130]]], device='cuda:0')\n",
      "tensor([[[1.0636],\n",
      "         [9.2195],\n",
      "         [0.0340]]], device='cuda:0')\n",
      "tensor([[[ 1.0290],\n",
      "         [ 9.2415],\n",
      "         [-0.0102]]], device='cuda:0')\n",
      "tensor([[[ 1.0289],\n",
      "         [ 9.2568],\n",
      "         [-0.0396]]], device='cuda:0')\n",
      "tensor([[[1.0580],\n",
      "         [9.2089],\n",
      "         [0.0218]]], device='cuda:0')\n",
      "tensor([[[1.0515e+00],\n",
      "         [9.2101e+00],\n",
      "         [1.2166e-03]]], device='cuda:0')\n",
      "tensor([[[1.0489],\n",
      "         [9.2134],\n",
      "         [0.0686]]], device='cuda:0')\n",
      "tensor([[[ 1.0574e+00],\n",
      "         [ 9.2230e+00],\n",
      "         [-3.8303e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0502e+00],\n",
      "         [ 9.2316e+00],\n",
      "         [-3.8786e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0049e+00],\n",
      "         [ 9.2291e+00],\n",
      "         [-6.5102e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0460],\n",
      "         [ 9.2341],\n",
      "         [-0.0342]]], device='cuda:0')\n",
      "tensor([[[ 1.0674e+00],\n",
      "         [ 9.2220e+00],\n",
      "         [-4.2640e-03]]], device='cuda:0')\n",
      "tensor([[[1.0454],\n",
      "         [9.2559],\n",
      "         [0.0122]]], device='cuda:0')\n",
      "tensor([[[ 1.0580e+00],\n",
      "         [ 9.2228e+00],\n",
      "         [-2.2915e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0569],\n",
      "         [ 9.2166],\n",
      "         [-0.0264]]], device='cuda:0')\n",
      "tensor([[[ 1.0363],\n",
      "         [ 9.2400],\n",
      "         [-0.0111]]], device='cuda:0')\n",
      "tensor([[[ 1.0253],\n",
      "         [ 9.2252],\n",
      "         [-0.0266]]], device='cuda:0')\n",
      "tensor([[[1.0670],\n",
      "         [9.2214],\n",
      "         [0.1004]]], device='cuda:0')\n",
      "tensor([[[ 1.0221],\n",
      "         [ 9.2367],\n",
      "         [-0.0720]]], device='cuda:0')\n",
      "tensor([[[ 1.0289],\n",
      "         [ 9.2625],\n",
      "         [-0.0100]]], device='cuda:0')\n",
      "tensor([[[ 1.0257],\n",
      "         [ 9.2312],\n",
      "         [-0.0179]]], device='cuda:0')\n",
      "tensor([[[ 1.0593],\n",
      "         [ 9.2325],\n",
      "         [-0.0645]]], device='cuda:0')\n",
      "tensor([[[ 1.0217],\n",
      "         [ 9.2241],\n",
      "         [-0.0256]]], device='cuda:0')\n",
      "tensor([[[1.0445],\n",
      "         [9.2385],\n",
      "         [0.0591]]], device='cuda:0')\n",
      "tensor([[[ 1.0505],\n",
      "         [ 9.2275],\n",
      "         [-0.0202]]], device='cuda:0')\n",
      "tensor([[[ 1.0575],\n",
      "         [ 9.2416],\n",
      "         [-0.0227]]], device='cuda:0')\n",
      "tensor([[[1.1052],\n",
      "         [1.0896],\n",
      "         [0.0230]]], device='cuda:0')\n",
      "tensor([[[ 1.0449],\n",
      "         [ 9.2547],\n",
      "         [-0.0345]]], device='cuda:0')\n",
      "tensor([[[ 1.0302],\n",
      "         [ 9.2519],\n",
      "         [-0.0397]]], device='cuda:0')\n",
      "tensor([[[ 1.0885],\n",
      "         [ 9.2413],\n",
      "         [-0.0519]]], device='cuda:0')\n",
      "tensor([[[ 1.0408e+00],\n",
      "         [ 9.2029e+00],\n",
      "         [-8.5536e-03]]], device='cuda:0')\n",
      "tensor([[[1.0856],\n",
      "         [9.2225],\n",
      "         [0.0321]]], device='cuda:0')\n",
      "tensor([[[ 1.0705],\n",
      "         [ 9.2440],\n",
      "         [-0.0411]]], device='cuda:0')\n",
      "tensor([[[ 1.0642e+00],\n",
      "         [ 9.2173e+00],\n",
      "         [-8.5956e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0397],\n",
      "         [ 9.2354],\n",
      "         [-0.0290]]], device='cuda:0')\n",
      "tensor([[[1.0471],\n",
      "         [9.2136],\n",
      "         [0.0633]]], device='cuda:0')\n",
      "tensor([[[ 1.0476],\n",
      "         [ 9.2277],\n",
      "         [-0.0473]]], device='cuda:0')\n",
      "tensor([[[1.0545],\n",
      "         [9.2318],\n",
      "         [0.0942]]], device='cuda:0')\n",
      "tensor([[[ 1.0568],\n",
      "         [ 9.2481],\n",
      "         [-0.0224]]], device='cuda:0')\n",
      "tensor([[[ 1.0404],\n",
      "         [ 9.2583],\n",
      "         [-0.0112]]], device='cuda:0')\n",
      "tensor([[[ 1.0732],\n",
      "         [ 1.0192],\n",
      "         [-0.0172]]], device='cuda:0')\n",
      "tensor([[[ 1.0515],\n",
      "         [ 9.2389],\n",
      "         [-0.0138]]], device='cuda:0')\n",
      "tensor([[[ 1.0449],\n",
      "         [ 9.2346],\n",
      "         [-0.0471]]], device='cuda:0')\n",
      "tensor([[[ 1.0457],\n",
      "         [ 9.2316],\n",
      "         [-0.0142]]], device='cuda:0')\n",
      "tensor([[[ 1.0216],\n",
      "         [ 9.2144],\n",
      "         [-0.0329]]], device='cuda:0')\n",
      "tensor([[[ 1.0670],\n",
      "         [ 9.2221],\n",
      "         [-0.0686]]], device='cuda:0')\n",
      "tensor([[[ 1.0267],\n",
      "         [ 9.2279],\n",
      "         [-0.0099]]], device='cuda:0')\n",
      "tensor([[[1.0441e+00],\n",
      "         [9.2225e+00],\n",
      "         [5.3168e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0521],\n",
      "         [ 9.2370],\n",
      "         [-0.0169]]], device='cuda:0')\n",
      "tensor([[[ 1.0305],\n",
      "         [ 9.2415],\n",
      "         [-0.0395]]], device='cuda:0')\n",
      "tensor([[[1.1585e+00],\n",
      "         [9.2187e+00],\n",
      "         [8.0956e-04]]], device='cuda:0')\n",
      "tensor([[[1.1039],\n",
      "         [9.1842],\n",
      "         [0.1639]]], device='cuda:0')\n",
      "tensor([[[ 1.0402],\n",
      "         [ 9.2184],\n",
      "         [-0.0100]]], device='cuda:0')\n",
      "tensor([[[ 1.0395],\n",
      "         [ 9.2348],\n",
      "         [-0.0113]]], device='cuda:0')\n",
      "tensor([[[ 1.0252],\n",
      "         [ 9.2235],\n",
      "         [-0.0225]]], device='cuda:0')\n",
      "tensor([[[ 1.0544],\n",
      "         [ 9.2386],\n",
      "         [-0.0195]]], device='cuda:0')\n",
      "tensor([[[ 1.0198],\n",
      "         [ 9.2359],\n",
      "         [-0.0165]]], device='cuda:0')\n",
      "tensor([[[1.0794],\n",
      "         [9.2273],\n",
      "         [0.0163]]], device='cuda:0')\n",
      "tensor([[[ 1.0462],\n",
      "         [ 9.2177],\n",
      "         [-0.0478]]], device='cuda:0')\n",
      "tensor([[[ 1.0578e+00],\n",
      "         [ 9.2191e+00],\n",
      "         [-4.7217e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0542],\n",
      "         [ 9.2219],\n",
      "         [-0.0171]]], device='cuda:0')\n",
      "tensor([[[ 1.0527],\n",
      "         [ 9.2382],\n",
      "         [-0.0142]]], device='cuda:0')\n",
      "tensor([[[ 1.0437],\n",
      "         [ 9.2360],\n",
      "         [-0.0342]]], device='cuda:0')\n",
      "tensor([[[ 1.0334],\n",
      "         [ 9.2365],\n",
      "         [-0.0183]]], device='cuda:0')\n",
      "tensor([[[1.0492e+00],\n",
      "         [9.2311e+00],\n",
      "         [1.5874e-04]]], device='cuda:0')\n",
      "tensor([[[ 1.0524],\n",
      "         [ 9.2176],\n",
      "         [-0.0210]]], device='cuda:0')\n",
      "tensor([[[ 1.0306],\n",
      "         [ 9.2333],\n",
      "         [-0.0104]]], device='cuda:0')\n",
      "tensor([[[ 1.0696],\n",
      "         [ 9.2289],\n",
      "         [-0.0413]]], device='cuda:0')\n",
      "tensor([[[ 1.0599],\n",
      "         [ 9.2320],\n",
      "         [-0.0309]]], device='cuda:0')\n",
      "tensor([[[1.0635],\n",
      "         [9.2165],\n",
      "         [0.0973]]], device='cuda:0')\n",
      "tensor([[[1.0677e+00],\n",
      "         [9.2451e+00],\n",
      "         [5.0538e-04]]], device='cuda:0')\n",
      "tensor([[[1.0458],\n",
      "         [9.1954],\n",
      "         [0.0579]]], device='cuda:0')\n",
      "tensor([[[ 1.0742],\n",
      "         [ 9.2318],\n",
      "         [-0.0353]]], device='cuda:0')\n",
      "tensor([[[ 1.0550e+00],\n",
      "         [ 9.2411e+00],\n",
      "         [-3.1040e-03]]], device='cuda:0')\n",
      "tensor([[[ 1.0686e+00],\n",
      "         [ 9.2477e+00],\n",
      "         [-6.8898e-03]]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "outputs_list=[]\n",
    "model.eval()\n",
    "for step, batch in enumerate(validation_dataloader):\n",
    "    with torch.no_grad():\n",
    "        output=model(inputs_embeds=batch[0].to(device), \n",
    "                        token_type_ids=None, \n",
    "                        attention_mask=None, \n",
    "                        labels=batch[1].to(device))\n",
    "    outputs_list.append(output[1].tolist())\n",
    "    print(output[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[[9.205392837524414], [1.0228509902954102], [-0.07902952283620834]]]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero_1=0\n",
    "one_1=0\n",
    "zero_2=0\n",
    "one_2=0\n",
    "nine_2=0\n",
    "one_3=0\n",
    "nine_3=0\n",
    "for i in range(1000):\n",
    "    zero_1+=outputs_list[i][0][0][0]\n",
    "    one_1+=outputs_list[i][0][1][0]\n",
    "zero_11=zero_1/(zero_1+one_1)\n",
    "one_11=one_1/(zero_1+one_1)\n",
    "for i in range(1000,2000):\n",
    "    zero_2+=outputs_list[i][0][0][0]\n",
    "    one_2+=outputs_list[i][0][1][0]\n",
    "    nine_2+=outputs_list[i][0][2][0]\n",
    "zero_22=zero_2/(zero_2+one_2+nine_2)\n",
    "one_22=one_2/(zero_2+one_2+nine_2)\n",
    "nine_22=nine_2/(zero_2+one_2+nine_2)\n",
    "for i in range(2000,3000):\n",
    "    one_3+=outputs_list[i][0][0][0]\n",
    "    nine_3+=outputs_list[i][0][1][0]\n",
    "one_33=one_3/(one_3+nine_3)\n",
    "nine_33=nine_3/(one_3+nine_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_33+nine_33"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "N = 3\n",
    "menMeans = (zero_11, zero_22,0)\n",
    "womenMeans = (one_11, one_22, one_33)\n",
    "men1Means = (0,0.1,nine_33)\n",
    "stack3=(one_11,zero_22+one_22,one_33)\n",
    "\n",
    "ind = np.arange(N)   \n",
    "width = 0.6     \n",
    "\n",
    "p1 = plt.bar(ind, menMeans, width)\n",
    "p2 = plt.bar(ind, womenMeans, width,\n",
    "             bottom=menMeans)\n",
    "p3 = plt.bar(ind, men1Means, width,\n",
    "             bottom=stack3)\n",
    "\n",
    "plt.xlabel('Assortment set')\n",
    "plt.ylabel('Choice probability')\n",
    "plt.title('Scores by group and gender')\n",
    "plt.xticks(ind, ('[0,1]', '[0,1,9]', '[1,9]'))\n",
    "plt.yticks(np.arange(0, 1.1, 0.1))\n",
    "plt.legend((p1[0], p2[0],p3[0]), ('0', '1','9'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8913890516640102"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "N = 3\n",
    "zero_ = (0.9, 0.1,0)\n",
    "one_ = (0.1, 0.8, 0.1)\n",
    "nine_ = (0,0.1,0.9)\n",
    "stack3=(1,0.9,0.1)\n",
    "\n",
    "ind = np.arange(N)    \n",
    "width = 0.5    \n",
    "\n",
    "p1 = plt.bar(ind, zero_, width)\n",
    "p2 = plt.bar(ind, one_, width,\n",
    "             bottom=zero_)\n",
    "p3 = plt.bar(ind, nine_, width,\n",
    "             bottom=stack3)\n",
    "\n",
    "plt.xlabel('Assortment set')\n",
    "plt.ylabel('Choice probability')\n",
    "plt.title('Target Probability Distribution ')\n",
    "plt.xticks(ind, ('[0,1]', '[0,1,9]', '[1,9]'))\n",
    "plt.yticks(np.arange(0, 1.2, 0.1))\n",
    "plt.legend((p1[0], p2[0],p3[0]), ('0', '1','9'))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "TAPED.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
